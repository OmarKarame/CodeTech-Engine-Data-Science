message,sha,diff
DOC: Updated the toolchain roadmap.,cf5fa56c459f89c4932c8885e2a2417266088994,"diff --git a/doc/source/dev/distributing.rst b/doc/source/dev/distributing.rst
index 07995c02018d..d1efa548a718 100644
--- a/doc/source/dev/distributing.rst
+++ b/doc/source/dev/distributing.rst
@@ -1,3 +1,5 @@
+.. _distributing-a-release:
+
 Distributing
 ============
 
@@ -60,6 +62,7 @@ compiler rather than a Python package that pip_ is allowed to upgrade.
 
 Issues with dependency handling
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
 There are some serious issues with how Python packaging tools handle
 dependencies reported by projects.  Because SciPy gets regular bug reports
 about this, we go in a bit of detail here.
diff --git a/doc/source/dev/toolchain.rst b/doc/source/dev/toolchain.rst
index 7ac6b0e18e3a..cae55cb59135 100644
--- a/doc/source/dev/toolchain.rst
+++ b/doc/source/dev/toolchain.rst
@@ -1,141 +1,196 @@
 Toolchain and Roadmap
 =====================
-SciPy requires several tools in order to be built.
+
+The use of the SciPy library requires (or optionally depends upon) several
+other libraries in order to operate, the main dependency being Python and NumPy.
+It requires a larger collection of libraries and tools in order to build the library,
+or to build the documentation.
+
+Of course, the tooling and libraries are themselves not static.  This document aims to provide a
+guide as to how SciPy's use of these dynamic dependencies will proceed over time.
+
+SciPy aims to be compatible with a number of releases of its dependent libraries and tools.
+Forcing the user base to other components for upgrade for every release would greatly
+diminish the value of SciPy.  However, maintaining backwards compatibility
+with very old tooling/libraries imposes limitations on which newer functionalities and capabilities
+can be incorporated.  SciPy takes a somewhat conservative approach, maintaining compatibility with
+several major releases of Python and NumPy on the major platforms. (That may in of itself impose
+further restrictions.  See the C Compilers section for an example.)
+
 
 - First and foremost, SciPy is a Python project hence it requires a Python environment.
 - The LAPACK and OpenBLAS numerical libraries need to be installed.
 - Compilers for C, C++, Cython and Fortran code are needed.
 - The Python environment needs the ``NumPy`` package to be installed.
 - Testing requires the ``pytest`` Python package.
-- Building the documentation requires Sphinx and ``numpydoc``.
+- Building the documentation requires the ``matplotlib``, Sphinx and ``numpydoc`` packages, as well as a LaTeX installation.
 
 The tooling used to build CPython has some implications for the tooling used in building SciPy.
+It also has implications for the documentation in docstrings.
+
+
+Building SciPy
+--------------
 
 Python Versions
----------------
+^^^^^^^^^^^^^^^
 
-SciPy is compatible with several versions of Python, and some
-specific decisions are still under consideration, especially
-with regard to future changes.
+SciPy is compatible with several versions of Python.  Python 2.7 support was dropped for SciPy
+releases numbered 1.3 and above but is still available in Release 1.2.x.
+which is a long-term support release. [1]_, [2]_.
 
-================  =================================================
+================  =======================================================================
  Date             Pythons supported
-================  =================================================
- <= 2018           Py2.7, Py3.5 - Py3.7
- 2019              Py3.5 - (but Py2.7-specific code not removed)
- 2020              Py3.?- (removal of Py2.7-specific code permitted)
-================  =================================================
+================  =======================================================================
+ 2018              Py2.7, Py3.4+ (SciPy 1.2.x is the last release to support Python 2.7)
+ 2019              Py3.5+ (but Py2.7-specific code not removed)
+ 2020              Py3.5+ (removal of Py2.7-specific code permitted)
+================  =======================================================================
+
 
 
 C Compilers
------------
+^^^^^^^^^^^
+
 SciPy is compatible with most modern C compilers.  However CPython on Windows is
-built with specific versions of the Microsoft Visual C++ compiler [1]_, as is the
+built with specific versions of the Microsoft Visual C++ compiler [3]_, as is the
 corresponding build of SciPy.  This has implications for the C language standards
 that can be supported.
 
 ===================   ==============   ===================
 CPython               MS Visual C++    C Standard
 ===================   ==============   ===================
-3.5, 3.6                14.0           C90 & most of C99
-3.3, 3.4                10.0           C90 & some of C99
 2.7, 3.0, 3.1, 3.2       9.0           C90
+3.3, 3.4                10.0           C90 & some of C99
+3.5, 3.6                14.0           C90 & most of C99
 ===================   ==============   ===================
 
 
-C Language Standards
---------------------
+
+C and C++ Language Standards
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+
 C and C++ language standards for SciPy are generally guidelines
 rather than official decisions. This is particularly true of
 attempting to predict adoption timelines for newer standards.
 
-================  =========================================
+================  ===========================================
  Date              C Standard
-================  =========================================
+================  ===========================================
  <= 2018           C90
- 2019              C90 for old code, may allow C99 for new
+ 2019              C90 for old code, may consider C99 for new
  2020              C99
- No decision       C11
- No decision       C17, C18
-================  =========================================
-
-Some C99 features would be useful for scientific programming, in particular better support of
-IEEE 754 [2]_.  Experience has shown that not all features are supported equally well across
-all platforms. SciPy has a small include file ``scipy/_lib/_c99compat.h`` which provides
-access to a few functions.  Use in conjunction with ``<numpy/npy_math.h>``.
-
-================================  ========================================================
- Feature                           Workaround
-================================  ========================================================
- isnan(), isinf(), isfinite()      Use sc_isnan(), sc_isinf(), sc_isfinite()
- NAN                               Use NPY_NAN (*almost* equivalent)
- inline functions                  Make static functions and place in an include .h file
- mid-block variable declarations   Declare variables at the top of block
-================================  ========================================================
+ ?                 C11
+ ?                 C17, C18
+================  ===========================================
+
+C99 has been a standard for 20 years, but experience has shown that
+not all features are supported equally well across all platforms.
+C18 is a bug fix for C11, so C11 may be skipped entirely.
 
 For C++, we currently suggest that anything beyond C++11 is going to be impossible
-for a very long time because of ecosystem support restrictions.
+for a very long time because of ecosystem support restrictions. See [4]_.
+
+.. note::
+
+    Developer Note: Some C99 features would be useful for scientific programming, in particular better support of
+    IEEE 754 [5]_.  SciPy has a small include file ``scipy/_lib/_c99compat.h`` which provides
+    access to a few functions.  Use in conjunction with ``<numpy/npy_math.h>``.
+
+    ===================================   ========================================================
+     Feature                               Workaround
+    ===================================   ========================================================
+     `isnan()`, `isinf()`, `isfinite()`   Use `sc_isnan()`, `sc_isinf()`, `sc_isfinite()`
+     `NAN`                                Use `NPY_NAN` (*almost* equivalent)
+     inline functions                     Make static functions and place in an include .h file
+     mid-block variable declarations      Declare variables at the top of the block
+    ===================================   ========================================================
+
 
 Fortran Compilers
------------------
+^^^^^^^^^^^^^^^^^
+
+Generally, any well-maintained compiler is likely suitable and can be used to build SciPy.
 
-Generally, any well-maintained compiler is likely suitable. gfortran >= 4.8.0,
-ifort, or flang can be used to build SciPy.
+- gfortran >= 4.8.0
+- ifort
+- flang
 
 Cython Compiler
----------------
+^^^^^^^^^^^^^^^
 
-SciPy always requires a recent Cython compiler. As of v1.2.0, the minumum version is 0.29.0
+SciPy always requires a recent Cython compiler. As of v1.2.0, the minumum version is 0.29.0.
 
 NumPy
------
+^^^^^
+
 SciPy depends on NumPy but releases of SciPy are not tied to releases of NumPy.
 SciPy attempts to be compatible with at least the 4 previous releases of NumPy.
 In particular, SciPy can not rely on features of just the latest NumPy, but needs to be
-written using what is common in all of those 4 releases.
+written using what is common in all of those 4 releases. [1]_, [6]_.
 
 ========  ========================    ===========================
- Python     minimum Numpy version     maximum Numpy version
+ Python    Minimum Numpy version       Maximum Numpy version
 ========  ========================    ===========================
 3.7         1.13.1                     >= 1.16.x
 3.6         1.12.1                     >= 1.16.x
 3.5         1.9.3                      >= 1.16.x
-2.7         1.8.2                      >= 1.16.x
+2.7         1.8.2                      1.16.x
 ========  ========================    ===========================
 
 
-
 Other Libraries
----------------
+^^^^^^^^^^^^^^^
 
 - LAPACK: >= 3.4.1
 - OpenBLAS: A recent version
 
 
+Testing and Benchmarking
+--------------------------
+
+A Recent version of:
+
+- pytest https://docs.pytest.org/en/latest/
+- asv (airspeed velocity)  https://asv.readthedocs.io/
+- mpmath http://mpmath.org
+
+
 Building the Documentation
 --------------------------
 
-- Sphinx: whatever recent versions work. >= 1.6.6.
+- Sphinx: whatever recent versions work. >= 2.0.
 - numpydoc: whatever recent versions work. >=  0.8.0.
 - matplotlib: generally suggest >= 2.0
+- LaTeX: A recent distibution.
 
-Testing and Benchmarking
-------------------------
-Recent version of:
 
-- pytest https://docs.pytest.org/en/latest/
-- asv (airspeed velocity)  https://asv.readthedocs.io/
+.. note::
+
+    Developer Note: The version of ``matplotlib`` required has
+    implications for the examples in Python docstrings.
+    Examples must be able to be executed both in the environment used to build the documentation,
+    as well as any supported version of ``matplotlib`` that a user may use with this release of SciPy.
+
 
 Packaging
 ---------
-Recent version of:
 
-- wheel
-- multibuild
+A Recent version of:
+
+- setuptools
+- wheel  https://pythonwheels.com
+- multibuild  https://github.com/matthew-brett/multibuild
 
+:ref:`making-a-release` and :ref:`distributing-a-release` contain information on
+making and distributing a SciPy release.
 
 References
 ----------
 
-.. [1] https://blogs.msdn.microsoft.com/vcblog/2013/07/19/c99-library-support-in-visual-studio-2013/
-.. [2] https://en.wikipedia.org/wiki/IEEE_754-1985
+.. [1] https://docs.scipy.org/doc/scipy/reference/release.1.2.0.html
+.. [2] https://python3statement.org
+.. [3] https://blogs.msdn.microsoft.com/vcblog/2013/07/19/c99-library-support-in-visual-studio-2013/
+.. [4] https://en.cppreference.com/w/cpp/compiler_support
+.. [5] https://en.wikipedia.org/wiki/IEEE_754-1985
+.. [6] https://docs.scipy.org/doc/numpy/release.html
"
MAINT: reviewer adjustments in PR 9500,473e2d76565f34eb12768dc6b7753a10c300893b,"diff --git a/doc/source/dev/toolchain.rst b/doc/source/dev/toolchain.rst
index 89fbc9c33a17..7ac6b0e18e3a 100644
--- a/doc/source/dev/toolchain.rst
+++ b/doc/source/dev/toolchain.rst
@@ -14,9 +14,9 @@ The tooling used to build CPython has some implications for the tooling used in
 Python Versions
 ---------------
 
-SciPy is compatible with several versions of Python.
-[*NOTE: The level of support and dates is currently under discussion.
-This table shows what it could look like.*]
+SciPy is compatible with several versions of Python, and some
+specific decisions are still under consideration, especially
+with regard to future changes.
 
 ================  =================================================
  Date             Pythons supported
@@ -45,8 +45,9 @@ CPython               MS Visual C++    C Standard
 
 C Language Standards
 --------------------
-[*NOTE: I'm unaware of any official SciPy decisions on the support of C standards.
-This table shows what it could look like.*]
+C and C++ language standards for SciPy are generally guidelines
+rather than official decisions. This is particularly true of
+attempting to predict adoption timelines for newer standards.
 
 ================  =========================================
  Date              C Standard
@@ -72,20 +73,24 @@ access to a few functions.  Use in conjunction with ``<numpy/npy_math.h>``.
  mid-block variable declarations   Declare variables at the top of block
 ================================  ========================================================
 
+For C++, we currently suggest that anything beyond C++11 is going to be impossible
+for a very long time because of ecosystem support restrictions.
+
 Fortran Compilers
 -----------------
 
-[*What is the requirement on a Fortran compiler*]
+Generally, any well-maintained compiler is likely suitable. gfortran >= 4.8.0,
+ifort, or flang can be used to build SciPy.
 
 Cython Compiler
 ---------------
 
-SciPy always requires a recent Cython compiler. As of v1.12.0, the minumum version is 0.28.5? 0.29?
+SciPy always requires a recent Cython compiler. As of v1.2.0, the minumum version is 0.29.0
 
-Numpy
+NumPy
 -----
 SciPy depends on NumPy but releases of SciPy are not tied to releases of NumPy.
-SciPy attempts to be compatible with the 4 previous releases of NumPy.
+SciPy attempts to be compatible with at least the 4 previous releases of NumPy.
 In particular, SciPy can not rely on features of just the latest NumPy, but needs to be
 written using what is common in all of those 4 releases.
 
@@ -112,7 +117,7 @@ Building the Documentation
 
 - Sphinx: whatever recent versions work. >= 1.6.6.
 - numpydoc: whatever recent versions work. >=  0.8.0.
-- matplotlib: ?
+- matplotlib: generally suggest >= 2.0
 
 Testing and Benchmarking
 ------------------------
"
DOC: List C++ as a distinct compiler from C.,06f15b1e189cbd8228cd605d0dacdb70b9d8b3f5,"diff --git a/doc/source/dev/toolchain.rst b/doc/source/dev/toolchain.rst
index 460ccbca6feb..89fbc9c33a17 100644
--- a/doc/source/dev/toolchain.rst
+++ b/doc/source/dev/toolchain.rst
@@ -4,7 +4,7 @@ SciPy requires several tools in order to be built.
 
 - First and foremost, SciPy is a Python project hence it requires a Python environment.
 - The LAPACK and OpenBLAS numerical libraries need to be installed.
-- Compilers for C, Cython and Fortran code are needed.
+- Compilers for C, C++, Cython and Fortran code are needed.
 - The Python environment needs the ``NumPy`` package to be installed.
 - Testing requires the ``pytest`` Python package.
 - Building the documentation requires Sphinx and ``numpydoc``.
@@ -37,8 +37,8 @@ that can be supported.
 ===================   ==============   ===================
 CPython               MS Visual C++    C Standard
 ===================   ==============   ===================
-3.5, 3.6                14.0           C90 + most of C99
-3.3, 3.4                10.0           C90 + some of C99
+3.5, 3.6                14.0           C90 & most of C99
+3.3, 3.4                10.0           C90 & some of C99
 2.7, 3.0, 3.1, 3.2       9.0           C90
 ===================   ==============   ===================
 
@@ -60,7 +60,7 @@ This table shows what it could look like.*]
 
 Some C99 features would be useful for scientific programming, in particular better support of
 IEEE 754 [2]_.  Experience has shown that not all features are supported equally well across
-all platforms, SciPy has a small include file ``scipy/_lib/_c99compat.h`` which provides
+all platforms. SciPy has a small include file ``scipy/_lib/_c99compat.h`` which provides
 access to a few functions.  Use in conjunction with ``<numpy/npy_math.h>``.
 
 ================================  ========================================================
"
"DOC: WIP Document the toolchain and its roadmap.

Added some documentation for the toolchain needed to build/test/document
SciPy.  In particular, document the roadmap for the Python and C language
standards, with a little rationale.",651c83d43263bc51d44872c0bdf47a17f89a70a2,"diff --git a/doc/source/dev/index.rst b/doc/source/dev/index.rst
index d9b9d0ce679c..8d8a2a3feeba 100644
--- a/doc/source/dev/index.rst
+++ b/doc/source/dev/index.rst
@@ -12,6 +12,8 @@ SciPy Developer Guide
 
 .. include:: versioning.rst
 
+.. include:: toolchain.rst
+
 .. include:: deprecations.rst
 
 .. include:: distributing.rst
diff --git a/doc/source/dev/toolchain.rst b/doc/source/dev/toolchain.rst
new file mode 100644
index 000000000000..460ccbca6feb
--- /dev/null
+++ b/doc/source/dev/toolchain.rst
@@ -0,0 +1,136 @@
+Toolchain and Roadmap
+=====================
+SciPy requires several tools in order to be built.
+
+- First and foremost, SciPy is a Python project hence it requires a Python environment.
+- The LAPACK and OpenBLAS numerical libraries need to be installed.
+- Compilers for C, Cython and Fortran code are needed.
+- The Python environment needs the ``NumPy`` package to be installed.
+- Testing requires the ``pytest`` Python package.
+- Building the documentation requires Sphinx and ``numpydoc``.
+
+The tooling used to build CPython has some implications for the tooling used in building SciPy.
+
+Python Versions
+---------------
+
+SciPy is compatible with several versions of Python.
+[*NOTE: The level of support and dates is currently under discussion.
+This table shows what it could look like.*]
+
+================  =================================================
+ Date             Pythons supported
+================  =================================================
+ <= 2018           Py2.7, Py3.5 - Py3.7
+ 2019              Py3.5 - (but Py2.7-specific code not removed)
+ 2020              Py3.?- (removal of Py2.7-specific code permitted)
+================  =================================================
+
+
+C Compilers
+-----------
+SciPy is compatible with most modern C compilers.  However CPython on Windows is
+built with specific versions of the Microsoft Visual C++ compiler [1]_, as is the
+corresponding build of SciPy.  This has implications for the C language standards
+that can be supported.
+
+===================   ==============   ===================
+CPython               MS Visual C++    C Standard
+===================   ==============   ===================
+3.5, 3.6                14.0           C90 + most of C99
+3.3, 3.4                10.0           C90 + some of C99
+2.7, 3.0, 3.1, 3.2       9.0           C90
+===================   ==============   ===================
+
+
+C Language Standards
+--------------------
+[*NOTE: I'm unaware of any official SciPy decisions on the support of C standards.
+This table shows what it could look like.*]
+
+================  =========================================
+ Date              C Standard
+================  =========================================
+ <= 2018           C90
+ 2019              C90 for old code, may allow C99 for new
+ 2020              C99
+ No decision       C11
+ No decision       C17, C18
+================  =========================================
+
+Some C99 features would be useful for scientific programming, in particular better support of
+IEEE 754 [2]_.  Experience has shown that not all features are supported equally well across
+all platforms, SciPy has a small include file ``scipy/_lib/_c99compat.h`` which provides
+access to a few functions.  Use in conjunction with ``<numpy/npy_math.h>``.
+
+================================  ========================================================
+ Feature                           Workaround
+================================  ========================================================
+ isnan(), isinf(), isfinite()      Use sc_isnan(), sc_isinf(), sc_isfinite()
+ NAN                               Use NPY_NAN (*almost* equivalent)
+ inline functions                  Make static functions and place in an include .h file
+ mid-block variable declarations   Declare variables at the top of block
+================================  ========================================================
+
+Fortran Compilers
+-----------------
+
+[*What is the requirement on a Fortran compiler*]
+
+Cython Compiler
+---------------
+
+SciPy always requires a recent Cython compiler. As of v1.12.0, the minumum version is 0.28.5? 0.29?
+
+Numpy
+-----
+SciPy depends on NumPy but releases of SciPy are not tied to releases of NumPy.
+SciPy attempts to be compatible with the 4 previous releases of NumPy.
+In particular, SciPy can not rely on features of just the latest NumPy, but needs to be
+written using what is common in all of those 4 releases.
+
+========  ========================    ===========================
+ Python     minimum Numpy version     maximum Numpy version
+========  ========================    ===========================
+3.7         1.13.1                     >= 1.16.x
+3.6         1.12.1                     >= 1.16.x
+3.5         1.9.3                      >= 1.16.x
+2.7         1.8.2                      >= 1.16.x
+========  ========================    ===========================
+
+
+
+Other Libraries
+---------------
+
+- LAPACK: >= 3.4.1
+- OpenBLAS: A recent version
+
+
+Building the Documentation
+--------------------------
+
+- Sphinx: whatever recent versions work. >= 1.6.6.
+- numpydoc: whatever recent versions work. >=  0.8.0.
+- matplotlib: ?
+
+Testing and Benchmarking
+------------------------
+Recent version of:
+
+- pytest https://docs.pytest.org/en/latest/
+- asv (airspeed velocity)  https://asv.readthedocs.io/
+
+Packaging
+---------
+Recent version of:
+
+- wheel
+- multibuild
+
+
+References
+----------
+
+.. [1] https://blogs.msdn.microsoft.com/vcblog/2013/07/19/c99-library-support-in-visual-studio-2013/
+.. [2] https://en.wikipedia.org/wiki/IEEE_754-1985
"
"DOC: Replace undefined `k` in `interpolate.splev` docstring

Closes #10068",335f4caec1084cf11ed8c32f5cd8e2a7e6a9b30c,"diff --git a/scipy/interpolate/fitpack.py b/scipy/interpolate/fitpack.py
index f224e258a7e1..ea45a3754487 100644
--- a/scipy/interpolate/fitpack.py
+++ b/scipy/interpolate/fitpack.py
@@ -310,7 +310,7 @@ def splev(x, tck, der=0, ext=0):
         of the spline. (Also see Notes.)
     der : int, optional
         The order of derivative of the spline to compute (must be less than
-        or equal to k).
+        or equal to the degree of the spline).
     ext : int, optional
         Controls the value returned for elements of ``x`` not in the
         interval defined by the knot sequence.
"
"BUG: optimize: fix curve_fit for mixed float32/float64 input

curve_fit sometimes fails if xdata and ydata dtypes differ
(one is float32, and the other is float64), or both are float32.

Thus always cast them to float64.

fixes gh-9581, fixes gh-7117",0856552fe10ab9d27e96221e78a5d757cfb2649b,"diff --git a/scipy/optimize/minpack.py b/scipy/optimize/minpack.py
index 5d15fd724480..b39cf9f74fce 100644
--- a/scipy/optimize/minpack.py
+++ b/scipy/optimize/minpack.py
@@ -720,6 +720,10 @@ def curve_fit(f, xdata, ydata, p0=None, sigma=None, absolute_sigma=False,
     if ydata.size == 0:
         raise ValueError(""`ydata` must not be empty!"")
 
+    # optimization may produce garbage for float32 inputs, cast them to float64
+    xdata = xdata.astype(float)
+    ydata = ydata.astype(float)
+
     # Determine type of sigma
     if sigma is not None:
         sigma = np.asarray(sigma)
diff --git a/scipy/optimize/tests/test_minpack.py b/scipy/optimize/tests/test_minpack.py
index 1dec03184093..e1b28196affa 100644
--- a/scipy/optimize/tests/test_minpack.py
+++ b/scipy/optimize/tests/test_minpack.py
@@ -3,6 +3,8 @@
 """"""
 from __future__ import division, print_function, absolute_import
 
+import warnings
+
 from numpy.testing import (assert_, assert_almost_equal, assert_array_equal,
                            assert_array_almost_equal, assert_allclose)
 from pytest import raises as assert_raises
@@ -720,6 +722,55 @@ def jac(x, a, b):
                 assert_allclose(popt1, popt2, atol=1e-14)
                 assert_allclose(pcov1, pcov2, atol=1e-14)
 
+    def test_dtypes(self):
+        # regression test for gh-9581: curve_fit fails if x and y dtypes differ
+        x = np.arange(-3, 5)
+        y = 1.5*x + 3.0 + 0.5*np.sin(x)
+
+        def func(x, a, b):
+            return a*x + b
+
+        for method in ['lm', 'trf', 'dogbox']:
+            for dtx in [np.float32, np.float64]:
+                for dty in [np.float32, np.float64]:
+                    x = x.astype(dtx)
+                    y = y.astype(dty)
+
+                with warnings.catch_warnings():
+                    warnings.simplefilter(""error"", OptimizeWarning)
+                    p, cov = curve_fit(func, x, y, method=method)
+
+                    assert np.isfinite(cov).all()
+                    assert not np.allclose(p, 1)   # curve_fit's initial value
+
+    def test_dtypes2(self):
+        # regression test for gh-7117: curve_fit fails if
+        # both inputs are float32
+        def hyperbola(x, s_1, s_2, o_x, o_y, c):
+            b_2 = (s_1 + s_2) / 2
+            b_1 = (s_2 - s_1) / 2
+            return o_y + b_1*(x-o_x) + b_2*np.sqrt((x-o_x)**2 + c**2/4)
+
+        min_fit = np.array([-3.0, 0.0, -2.0, -10.0, 0.0])
+        max_fit = np.array([0.0, 3.0, 3.0, 0.0, 10.0])
+        guess = np.array([-2.5/3.0, 4/3.0, 1.0, -4.0, 0.5])
+
+        params = [-2, .4, -1, -5, 9.5]
+        xdata = np.array([-32, -16, -8, 4, 4, 8, 16, 32])
+        ydata = hyperbola(xdata, *params)
+
+        # run optimization twice, with xdata being float32 and float64
+        popt_64, _ = curve_fit(f=hyperbola, xdata=xdata, ydata=ydata, p0=guess,
+                               bounds=(min_fit, max_fit))
+
+        xdata = xdata.astype(np.float32)
+        ydata = hyperbola(xdata, *params)
+
+        popt_32, _ = curve_fit(f=hyperbola, xdata=xdata, ydata=ydata, p0=guess,
+                               bounds=(min_fit, max_fit))
+
+        assert_allclose(popt_32, popt_64, atol=2e-5)
+
 
 class TestFixedPoint(object):
 
"
"Merge pull request #10026 from mdhaber/sparse_cholesky

ENH: optimize: use SuiteSparse in linprog interior-point when available",f858f8afa52b034efe381286fb05aa95664153c6,"diff --git a/scipy/optimize/_linprog_ip.py b/scipy/optimize/_linprog_ip.py
index e593f9dd2629..03f8fc9f29f7 100644
--- a/scipy/optimize/_linprog_ip.py
+++ b/scipy/optimize/_linprog_ip.py
@@ -26,31 +26,53 @@
 from scipy.linalg import LinAlgError
 from .optimize import OptimizeWarning, OptimizeResult, _check_unknown_options
 from ._linprog_util import _postsolve
-
-
-def _get_solver(sparse=False, lstsq=False, sym_pos=True, cholesky=True):
+has_umfpack = True
+has_cholmod = True
+try:
+    from sksparse.cholmod import cholesky as cholmod
+except ImportError:
+    has_cholmod = False
+try:
+    import scikits.umfpack  # test whether to use factorized
+except ImportError:
+    has_umfpack = False
+
+
+def _get_solver(M, sparse=False, lstsq=False, sym_pos=True,
+                cholesky=True, permc_spec='MMD_AT_PLUS_A'):
     """"""
     Given solver options, return a handle to the appropriate linear system
     solver.
 
     Parameters
     ----------
-    sparse : bool
+    M : 2D array
+        As defined in [4] Equation 8.31
+    sparse : bool (default = False)
         True if the system to be solved is sparse. This is typically set
         True when the original ``A_ub`` and ``A_eq`` arrays are sparse.
-    lstsq : bool
+    lstsq : bool (default = False)
         True if the system is ill-conditioned and/or (nearly) singular and
         thus a more robust least-squares solver is desired. This is sometimes
         needed as the solution is approached.
-    sym_pos : bool
+    sym_pos : bool (default = True)
         True if the system matrix is symmetric positive definite
         Sometimes this needs to be set false as the solution is approached,
         even when the system should be symmetric positive definite, due to
         numerical difficulties.
-    cholesky : bool
+    cholesky : bool (default = True)
         True if the system is to be solved by Cholesky, rather than LU,
         decomposition. This is typically faster unless the problem is very
         small or prone to numerical difficulties.
+    permc_spec : str (default = 'MMD_AT_PLUS_A')
+        Sparsity preservation strategy used by SuperLU. Acceptable values are:
+
+        - ``NATURAL``: natural ordering.
+        - ``MMD_ATA``: minimum degree ordering on the structure of A^T A.
+        - ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.
+        - ``COLAMD``: approximate minimum degree column ordering.
+
+        See SuperLU documentation.
 
     Returns
     -------
@@ -58,28 +80,41 @@ def _get_solver(sparse=False, lstsq=False, sym_pos=True, cholesky=True):
         Handle to the appropriate solver function
 
     """"""
-    if sparse:
-        if lstsq or not(sym_pos):
-            def solve(M, r, sym_pos=False):
-                return sps.linalg.lsqr(M, r)[0]
-        else:
-            # this is not currently used; it is replaced by splu solve
-            # TODO: expose use of this as an option
-            def solve(M, r):
-                return sps.linalg.spsolve(M, r, permc_spec=""MMD_AT_PLUS_A"")
+    try:
+        if sparse:
+            if lstsq:
+                def solve(r, sym_pos=False):
+                    return sps.linalg.lsqr(M, r)[0]
+            elif cholesky:
+                solve = cholmod(M)
+            else:
+                if has_umfpack and sym_pos:
+                    solve = sps.linalg.factorized(M)
+                else:  # factorized doesn't pass permc_spec
+                    solve = sps.linalg.splu(M, permc_spec=permc_spec).solve
 
-    else:
-        if lstsq:  # sometimes necessary as solution is approached
-            def solve(M, r):
-                return sp.linalg.lstsq(M, r)[0]
-        elif cholesky:
-            solve = sp.linalg.cho_solve
         else:
-            # this seems to cache the matrix factorization, so solving
-            # with multiple right hand sides is much faster
-            def solve(M, r, sym_pos=sym_pos):
-                return sp.linalg.solve(M, r, sym_pos=sym_pos)
-
+            if lstsq:  # sometimes necessary as solution is approached
+                def solve(r):
+                    return sp.linalg.lstsq(M, r)[0]
+            elif cholesky:
+                L = sp.linalg.cho_factor(M)
+
+                def solve(r):
+                    return sp.linalg.cho_solve(L, r)
+            else:
+                # this seems to cache the matrix factorization, so solving
+                # with multiple right hand sides is much faster
+                def solve(r, sym_pos=sym_pos):
+                    return sp.linalg.solve(M, r, sym_pos=sym_pos)
+    # There are many things that can go wrong here, and it's hard to say
+    # what all of them are. It doesn't really matter: if the matrix can't be
+    # factorized, return None. get_solver will be called again with different
+    # inputs, and a new routine will try to factorize the matrix.
+    except KeyboardInterrupt:
+        raise
+    except Exception:
+        return None
     return solve
 
 
@@ -166,12 +201,10 @@ def _get_delta(
            2000. 197-232.
 
     """"""
-
     if A.shape[0] == 0:
         # If there are no constraints, some solvers fail (understandably)
         # rather than returning empty solution. This gets the job done.
         sparse, lstsq, sym_pos, cholesky = False, False, True, False
-    solve = _get_solver(sparse, lstsq, sym_pos, cholesky)
     n_x = len(x)
 
     # [4] Equation 8.8
@@ -182,32 +215,12 @@ def _get_delta(
 
     #  Assemble M from [4] Equation 8.31
     Dinv = x / z
-    splu = False
-    if sparse and not lstsq:
-        # sparse requires Dinv to be diag matrix
+
+    if sparse:
         M = A.dot(sps.diags(Dinv, 0, format=""csc"").dot(A.T))
-        try:
-            # TODO: should use linalg.factorized instead, but I don't have
-            #       umfpack and therefore cannot test its performance
-            solve = sps.linalg.splu(M, permc_spec=permc_spec).solve
-            splu = True
-        except Exception:
-            lstsq = True
-            solve = _get_solver(sparse, lstsq, sym_pos, cholesky)
     else:
-        # dense does not; use broadcasting
         M = A.dot(Dinv.reshape(-1, 1) * A.T)
-
-    # For some small problems, calling sp.linalg.solve w/ sym_pos = True
-    # may be faster. I am pretty certain it caches the factorization for
-    # multiple uses and checks the incoming matrix to see if it's the same as
-    # the one it already factorized. (I can't explain the speed otherwise.)
-    if cholesky:
-        try:
-            L = sp.linalg.cho_factor(M)
-        except Exception:
-            cholesky = False
-            solve = _get_solver(sparse, lstsq, sym_pos, cholesky)
+    solve = _get_solver(M, sparse, lstsq, sym_pos, cholesky, permc_spec)
 
     # pc: ""predictor-corrector"" [4] Section 4.1
     # In development this option could be turned off
@@ -256,53 +269,59 @@ def _get_delta(
         # 3. scipy.linalg.solve w/ sym_pos = False, and if all else fails
         # 4. scipy.linalg.lstsq
         # For sparse systems, the order is:
-        # 1. scipy.sparse.linalg.splu
-        # 2. scipy.sparse.linalg.lsqr
-        # TODO: if umfpack is installed, use factorized instead of splu.
-        #       Can't do that now because factorized doesn't pass permc_spec
-        #       to splu if umfpack isn't installed. Also, umfpack not tested.
+        # 1. sksparse.cholmod.cholesky (if available)
+        # 2. scipy.sparse.linalg.factorized (if umfpack available)
+        # 3. scipy.sparse.linalg.splu
+        # 4. scipy.sparse.linalg.lsqr
         solved = False
         while(not solved):
             try:
-                solve_this = L if cholesky else M
                 # [4] Equation 8.28
-                p, q = _sym_solve(Dinv, solve_this, A, c, b, solve, splu)
+                p, q = _sym_solve(Dinv, A, c, b, solve)
                 # [4] Equation 8.29
-                u, v = _sym_solve(Dinv, solve_this, A, rhatd -
-                                  (1 / x) * rhatxs, rhatp, solve, splu)
+                u, v = _sym_solve(Dinv, A, rhatd -
+                                  (1 / x) * rhatxs, rhatp, solve)
                 if np.any(np.isnan(p)) or np.any(np.isnan(q)):
                     raise LinAlgError
                 solved = True
-            except (LinAlgError, ValueError) as e:
+            except (LinAlgError, ValueError, TypeError) as e:
                 # Usually this doesn't happen. If it does, it happens when
                 # there are redundant constraints or when approaching the
                 # solution. If so, change solver.
-                cholesky = False
-                if not lstsq:
-                    if sym_pos:
-                        warn(
-                            ""Solving system with option 'sym_pos':True ""
-                            ""failed. It is normal for this to happen ""
-                            ""occasionally, especially as the solution is ""
-                            ""approached. However, if you see this frequently, ""
-                            ""consider setting option 'sym_pos' to False."",
-                            OptimizeWarning)
-                        sym_pos = False
-                    else:
-                        warn(
-                            ""Solving system with option 'sym_pos':False ""
-                            ""failed. This may happen occasionally, ""
-                            ""especially as the solution is ""
-                            ""approached. However, if you see this frequently, ""
-                            ""your problem may be numerically challenging. ""
-                            ""If you cannot improve the formulation, consider ""
-                            ""setting 'lstsq' to True. Consider also setting ""
-                            ""`presolve` to True, if it is not already."",
-                            OptimizeWarning)
-                        lstsq = True
+                if cholesky:
+                    cholesky = False
+                    warn(
+                        ""Solving system with option 'cholesky':True ""
+                        ""failed. It is normal for this to happen ""
+                        ""occasionally, especially as the solution is ""
+                        ""approached. However, if you see this frequently, ""
+                        ""consider setting option 'cholesky' to False."",
+                        OptimizeWarning, stacklevel=5)
+                elif sym_pos:
+                    sym_pos = False
+                    warn(
+                        ""Solving system with option 'sym_pos':True ""
+                        ""failed. It is normal for this to happen ""
+                        ""occasionally, especially as the solution is ""
+                        ""approached. However, if you see this frequently, ""
+                        ""consider setting option 'sym_pos' to False."",
+                        OptimizeWarning, stacklevel=5)
+                elif not lstsq:
+                    lstsq = True
+                    warn(
+                        ""Solving system with option 'sym_pos':False ""
+                        ""failed. This may happen occasionally, ""
+                        ""especially as the solution is ""
+                        ""approached. However, if you see this frequently, ""
+                        ""your problem may be numerically challenging. ""
+                        ""If you cannot improve the formulation, consider ""
+                        ""setting 'lstsq' to True. Consider also setting ""
+                        ""`presolve` to True, if it is not already."",
+                        OptimizeWarning, stacklevel=5)
                 else:
                     raise e
-                solve = _get_solver(sparse, lstsq, sym_pos)
+                solve = _get_solver(M, sparse, lstsq, sym_pos,
+                                    cholesky, permc_spec)
         # [4] Results after 8.29
         d_tau = ((rhatg + 1 / tau * rhattk - (-c.dot(u) + b.dot(v))) /
                  (1 / tau * kappa + (-c.dot(p) + b.dot(q))))
@@ -325,7 +344,7 @@ def _get_delta(
     return d_x, d_y, d_z, d_tau, d_kappa
 
 
-def _sym_solve(Dinv, M, A, r1, r2, solve, splu=False):
+def _sym_solve(Dinv, A, r1, r2, solve):
     """"""
     An implementation of [4] equation 8.31 and 8.32
 
@@ -339,10 +358,7 @@ def _sym_solve(Dinv, M, A, r1, r2, solve, splu=False):
     """"""
     # [4] 8.31
     r = r2 + A.dot(Dinv * r1)
-    if splu:
-        v = solve(r)
-    else:
-        v = solve(M, r)
+    v = solve(r)
     # [4] 8.32
     u = Dinv * (A.T.dot(v) - r1)
     return u, v
@@ -896,7 +912,7 @@ def _linprog_ip(
     cholesky : bool (default = True)
         Set to ``True`` if the normal equations are to be solved by explicit
         Cholesky decomposition followed by explicit forward/backward
-        substitution. This is typically faster for moderate, dense problems
+        substitution. This is typically faster for problems
         that are numerically well-behaved.
     pc : bool (default = True)
         Leave ``True`` if the predictor-corrector method of Mehrota is to be
@@ -907,7 +923,8 @@ def _linprog_ip(
         depends on the problem.
     permc_spec : str (default = 'MMD_AT_PLUS_A')
         (Has effect only with ``sparse = True``, ``lstsq = False``, ``sym_pos =
-        True``.) A matrix is factorized in each iteration of the algorithm.
+        True``, and no SuiteSparse.)
+        A matrix is factorized in each iteration of the algorithm.
         This option specifies how to permute the columns of the matrix for
         sparsity preservation. Acceptable values are:
 
@@ -942,7 +959,7 @@ def _linprog_ip(
     Notes
     -----
     This method implements the algorithm outlined in [4]_ with ideas from [8]_
-    and a structure inspired by the simpler methods of [6]_ and [4]_.
+    and a structure inspired by the simpler methods of [6]_.
 
     The primal-dual path following method begins with initial 'guesses' of
     the primal and dual variables of the standard form problem and iteratively
@@ -969,33 +986,38 @@ def _linprog_ip(
     matrices involved are symmetric positive definite, so Cholesky
     decomposition can be used rather than the more expensive LU factorization.
 
-    With the default ``cholesky=True``, this is accomplished using
-    ``scipy.linalg.cho_factor`` followed by forward/backward substitutions
-    via ``scipy.linalg.cho_solve``. With ``cholesky=False`` and
-    ``sym_pos=True``, Cholesky decomposition is performed instead by
-    ``scipy.linalg.solve``. Based on speed tests, this also appears to retain
-    the Cholesky decomposition of the matrix for later use, which is beneficial
-    as the same system is solved four times with different right hand sides
-    in each iteration of the algorithm.
-
-    In problems with redundancy (e.g. if presolve is turned off with option
-    ``presolve=False``) or if the matrices become ill-conditioned (e.g. as the
-    solution is approached and some decision variables approach zero),
-    Cholesky decomposition can fail. Should this occur, successively more
-    robust solvers (``scipy.linalg.solve`` with ``sym_pos=False`` then
-    ``scipy.linalg.lstsq``) are tried, at the cost of computational efficiency.
-    These solvers can be used from the outset by setting the options
-    ``sym_pos=False`` and ``lstsq=True``, respectively.
-
-    Note that with the option ``sparse=True``, the normal equations are solved
-    using ``scipy.sparse.linalg.spsolve``. Unfortunately, this uses the more
-    expensive LU decomposition from the outset, but for large, sparse problems,
-    the use of sparse linear algebra techniques improves the solve speed
-    despite the use of LU rather than Cholesky decomposition. A simple
-    improvement would be to use the sparse Cholesky decomposition of
-    ``CHOLMOD`` via ``scikit-sparse`` when available.
-
-    Other potential improvements for combatting issues associated with dense
+    With default options, the solver used to perform the factorization depends
+    on third-party software availability and the conditioning of the problem.
+
+    For dense problems, solvers are tried in the following order:
+
+    1. ``scipy.linalg.cho_factor`` (if scikit-sparse and SuiteSparse are installed)
+
+    2. ``scipy.linalg.solve`` with option ``sym_pos=True``
+
+    3. ``scipy.linalg.solve`` with option ``sym_pos=False``
+
+    4. ``scipy.linalg.lstsq``
+
+    For sparse problems:
+
+    1. ``sksparse.cholmod.cholesky`` (if scikit-sparse and SuiteSparse are installed)
+
+    2. ``scipy.sparse.linalg.factorized`` (if scikits.umfpack and SuiteSparse are installed)
+
+    3. ``scipy.sparse.linalg.splu`` (which uses SuperLU distributed with SciPy)
+
+    4. ``scipy.sparse.linalg.lsqr``
+
+    If the solver fails for any reason, successively more robust (but slower)
+    solvers are attempted in the order indicated. Attempting, failing, and
+    re-starting factorization can be time consuming, so if the problem is
+    numerically challenging, options can be set to  bypass solvers that are
+    failing. Setting ``cholesky=False`` skips to solver 2,
+    ``sym_pos=False`` skips to solver 3, and ``lstsq=True`` skips
+    to solver 4 for both sparse and dense problems.
+
+    Potential improvements for combatting issues associated with dense
     columns in otherwise sparse problems are outlined in [4]_ Section 5.3 and
     [10]_ Section 4.1-4.2; the latter also discusses the alleviation of
     accuracy issues associated with the substitution approach to free
@@ -1072,36 +1094,30 @@ def _linprog_ip(
     _check_unknown_options(unknown_options)
 
     # These should be warnings, not errors
+    if (cholesky or cholesky is None) and sparse and not has_cholmod:
+        if cholesky:
+            warn(""Sparse cholesky is only available with scikit-sparse. ""
+                 ""Setting `cholesky = False`"",
+                 OptimizeWarning, stacklevel=3)
+        cholesky = False
+
     if sparse and lstsq:
-        warn(""Invalid option combination 'sparse':True ""
-             ""and 'lstsq':True; Sparse least squares is not recommended."",
-             OptimizeWarning)
-
-    if sparse and not sym_pos:
-        warn(""Invalid option combination 'sparse':True ""
-             ""and 'sym_pos':False; the effect is the same as sparse least ""
-             ""squares, which is not recommended."",
-             OptimizeWarning)
-
-    if sparse and cholesky:
-        # Cholesky decomposition is not available for sparse problems
-        warn(""Invalid option combination 'sparse':True ""
-             ""and 'cholesky':True; sparse Colesky decomposition is not ""
-             ""available."",
-             OptimizeWarning)
+        warn(""Option combination 'sparse':True and 'lstsq':True ""
+             ""is not recommended."",
+             OptimizeWarning, stacklevel=3)
 
     if lstsq and cholesky:
         warn(""Invalid option combination 'lstsq':True ""
              ""and 'cholesky':True; option 'cholesky' has no effect when ""
              ""'lstsq' is set True."",
-             OptimizeWarning)
+             OptimizeWarning, stacklevel=3)
 
     valid_permc_spec = ('NATURAL', 'MMD_ATA', 'MMD_AT_PLUS_A', 'COLAMD')
     if permc_spec.upper() not in valid_permc_spec:
         warn(""Invalid permc_spec option: '"" + str(permc_spec) + ""'. ""
              ""Acceptable values are 'NATURAL', 'MMD_ATA', 'MMD_AT_PLUS_A', ""
              ""and 'COLAMD'. Reverting to default."",
-             OptimizeWarning)
+             OptimizeWarning, stacklevel=3)
         permc_spec = 'MMD_AT_PLUS_A'
 
     # This can be an error
@@ -1111,7 +1127,7 @@ def _linprog_ip(
             ""and 'cholesky':True: Cholesky decomposition is only possible ""
             ""for symmetric positive definite matrices."")
 
-    cholesky = cholesky is None and sym_pos and not sparse and not lstsq
+    cholesky = cholesky or (cholesky is None and sym_pos and not lstsq)
 
     x, status, message, iteration = _ip_hsd(A, b, c, c0, alpha0, beta,
                                             maxiter, disp, tol, sparse,
diff --git a/scipy/optimize/tests/test_linprog.py b/scipy/optimize/tests/test_linprog.py
index 3173b4107092..304821896b5e 100644
--- a/scipy/optimize/tests/test_linprog.py
+++ b/scipy/optimize/tests/test_linprog.py
@@ -11,6 +11,11 @@
 from scipy._lib._numpy_compat import _assert_warns, suppress_warnings
 from scipy.sparse.linalg import MatrixRankWarning
 from scipy.linalg import LinAlgWarning
+try:
+    from scikits.umfpack import UmfpackWarning
+    has_umfpack = True
+except ImportError:
+    has_umfpack = False
 
 import pytest
 
@@ -823,6 +828,9 @@ def test_network_flow_limited_capacity(self):
         b_eq = [-4, 0, 0, 4]
 
         with suppress_warnings() as sup:
+            # this is an UmfpackWarning but I had trouble importing it
+            if has_umfpack:
+                sup.filter(UmfpackWarning)
             sup.filter(RuntimeWarning, ""scipy.linalg.solve\nIll..."")
             sup.filter(OptimizeWarning, ""A_eq does not appear..."")
             sup.filter(OptimizeWarning, ""Solving system with option..."")
@@ -1051,6 +1059,8 @@ def test_bug_6690(self):
             ])
 
         with suppress_warnings() as sup:
+            sup.filter(OptimizeWarning,
+                       ""Solving system with option 'cholesky'"")
             sup.filter(OptimizeWarning, ""Solving system with option 'sym_pos'"")
             sup.filter(RuntimeWarning, ""invalid value encountered"")
             sup.filter(LinAlgWarning)
@@ -1166,6 +1176,8 @@ def test_bug_8174_2(self):
         b_eq = np.array([[100], [0], [0], [0], [0]])
 
         with suppress_warnings() as sup:
+            if has_umfpack:
+                sup.filter(UmfpackWarning)
             sup.filter(OptimizeWarning, ""A_eq does not appear..."")
             res = linprog(c, A_ub, b_ub, A_eq, b_eq, bounds,
                           method=self.method, options=self.options)
@@ -1189,7 +1201,7 @@ def test_bug_8561(self):
         _assert_success(res, desired_x=[0, 0, 19, 16/3, 29/3])
 
     def test_bug_8662(self):
-        # linprog simplex used to report inncorrect optimal results
+        # linprog simplex used to report incorrect optimal results
         # https://github.com/scipy/scipy/issues/8662
         c = [-10, 10, 6, 3]
         A_ub = [[8, -8, -4, 6],
@@ -1201,6 +1213,8 @@ def test_bug_8662(self):
         desired_fun = 36.0000000000
 
         with suppress_warnings() as sup:
+            if has_umfpack:
+                sup.filter(UmfpackWarning)
             sup.filter(RuntimeWarning, ""invalid value encountered"")
             sup.filter(LinAlgWarning)
             res1 = linprog(c, A_ub, b_ub, A_eq, b_eq, bounds,
@@ -1212,6 +1226,8 @@ def test_bug_8662(self):
         bounds[2] = (None, None)
 
         with suppress_warnings() as sup:
+            if has_umfpack:
+                sup.filter(UmfpackWarning)
             sup.filter(RuntimeWarning, ""invalid value encountered"")
             sup.filter(LinAlgWarning)
             res2 = linprog(c, A_ub, b_ub, A_eq, b_eq, bounds,
@@ -1401,6 +1417,8 @@ def test_magic_square_sparse_no_presolve(self):
         bounds = (0, 1)
 
         with suppress_warnings() as sup:
+            if has_umfpack:
+                sup.filter(UmfpackWarning)
             sup.filter(MatrixRankWarning, ""Matrix is exactly singular"")
             sup.filter(OptimizeWarning, ""Solving system with option..."")
 
@@ -1468,6 +1486,7 @@ def test_alternate_initial_point(self):
         with suppress_warnings() as sup:
             sup.filter(RuntimeWarning, ""scipy.linalg.solve\nIll..."")
             sup.filter(OptimizeWarning, ""Solving system with option..."")
+            sup.filter(LinAlgWarning, ""Ill-conditioned matrix..."")
             res = linprog(c, A_ub=A, b_ub=b, method=self.method,
                           options={""ip"": True, ""disp"": True})
             # ip code is independent of sparse/dense
"
"Merge pull request #10052 from mikofski/patch-1

don't set flag to ""converged"" if max iter exceeded",6e2753a8ab9a66080fa2225ce0b7f45f249f68a4,"diff --git a/scipy/optimize/tests/test_zeros.py b/scipy/optimize/tests/test_zeros.py
index b53b843bf316..22431a894503 100644
--- a/scipy/optimize/tests/test_zeros.py
+++ b/scipy/optimize/tests/test_zeros.py
@@ -661,3 +661,24 @@ def fpp_array(x):
         f, x0_array, fprime=fp, fprime2=fpp_array, full_output=True
     )
     assert result.converged.all()
+
+
+@pytest.mark.parametrize(
+    ""maximum_iterations,flag_expected"",
+    [(10, zeros.CONVERR), (100, zeros.CONVERGED)])
+def test_gh9254_flag_if_maxiter_exceeded(maximum_iterations, flag_expected):
+    """"""
+    Test that if the maximum iterations is exceeded that the flag is not
+    converged.
+    """"""
+    result = zeros.brentq(
+        lambda x: ((1.2*x - 2.3)*x + 3.4)*x - 4.5,
+        -30, 30, (), 1e-6, 1e-6, maximum_iterations,
+        full_output=True, disp=False)
+    assert result[1].flag == flag_expected
+    if flag_expected == zeros.CONVERR:
+        # didn't converge because exceeded maximum iterations
+        assert result[1].iterations == maximum_iterations
+    elif flag_expected == zeros.CONVERGED:
+        # converged before maximum iterations
+        assert result[1].iterations < maximum_iterations
diff --git a/scipy/optimize/zeros.c b/scipy/optimize/zeros.c
index 97b14825dfa1..5ebf3ef1f8df 100644
--- a/scipy/optimize/zeros.c
+++ b/scipy/optimize/zeros.c
@@ -116,7 +116,7 @@ call_solver(solver_type solver, PyObject *self, PyObject *args)
         return NULL;
     }
 
-    if (solver_stats.error_num != 0) {
+    if (solver_stats.error_num != CONVERGED) {
         if (solver_stats.error_num == SIGNERR) {
             PyErr_SetString(PyExc_ValueError,
                     ""f(a) and f(b) must have different signs"");
@@ -129,11 +129,14 @@ call_solver(solver_type solver, PyObject *self, PyObject *args)
                         ""Failed to converge after %d iterations."",
                         solver_stats.iterations);
                 PyErr_SetString(PyExc_RuntimeError, msg);
-                flag = 1;
                 return NULL;
             }
+            flag = CONVERR;
         }
     }
+    else {
+        flag = CONVERGED;
+    }
     if (fulloutput) {
         return Py_BuildValue(""diii"",
                 zero, solver_stats.funcalls, solver_stats.iterations, flag);
"
STY: keep LEFT BRACE on same line after ELSE,18c49d4f4dbb9d9c855a0fce491a76527816a7a1,"diff --git a/scipy/optimize/zeros.c b/scipy/optimize/zeros.c
index 80488a7325ee..5ebf3ef1f8df 100644
--- a/scipy/optimize/zeros.c
+++ b/scipy/optimize/zeros.c
@@ -134,8 +134,7 @@ call_solver(solver_type solver, PyObject *self, PyObject *args)
             flag = CONVERR;
         }
     }
-    else
-    {
+    else {
         flag = CONVERGED;
     }
     if (fulloutput) {
"
"MAINT: Complete missing entries in lapack.py

and put them in alphabetical order",33bfa4fc5dbd0ce85f187cf36139eaff9ba99003,"diff --git a/scipy/linalg/lapack.py b/scipy/linalg/lapack.py
index 3f7e3100cc48..aed26797a175 100644
--- a/scipy/linalg/lapack.py
+++ b/scipy/linalg/lapack.py
@@ -69,6 +69,11 @@
    cgebal
    zgebal
 
+   sgecon
+   dgecon
+   cgecon
+   zgecon
+
    sgees
    dgees
    cgees
@@ -99,15 +104,15 @@
    cgehrd_lwork
    zgehrd_lwork
 
-   sgelss
-   dgelss
-   cgelss
-   zgelss
+   sgels
+   dgels
+   cgels
+   zgels
 
-   sgelss_lwork
-   dgelss_lwork
-   cgelss_lwork
-   zgelss_lwork
+   sgels_lwork
+   dgels_lwork
+   cgels_lwork
+   zgels_lwork
 
    sgelsd
    dgelsd
@@ -119,6 +124,16 @@
    cgelsd_lwork
    zgelsd_lwork
 
+   sgelss
+   dgelss
+   cgelss
+   zgelss
+
+   sgelss_lwork
+   dgelss_lwork
+   cgelss_lwork
+   zgelss_lwork
+
    sgelsy
    dgelsy
    cgelsy
@@ -154,6 +169,11 @@
    cgesdd_lwork
    zgesdd_lwork
 
+   sgesv
+   dgesv
+   cgesv
+   zgesv
+
    sgesvd
    dgesvd
    cgesvd
@@ -164,71 +184,11 @@
    cgesvd_lwork
    zgesvd_lwork
 
-   sgesv
-   dgesv
-   cgesv
-   zgesv
-
    sgesvx
    dgesvx
    cgesvx
    zgesvx
 
-   sgecon
-   dgecon
-   cgecon
-   zgecon
-
-   ssysv
-   dsysv
-   csysv
-   zsysv
-
-   ssysv_lwork
-   dsysv_lwork
-   csysv_lwork
-   zsysv_lwork
-
-   ssysvx
-   dsysvx
-   csysvx
-   zsysvx
-
-   ssysvx_lwork
-   dsysvx_lwork
-   csysvx_lwork
-   zsysvx_lwork
-
-   ssygst
-   dsygst
-
-   ssytrd
-   dsytrd
-
-   ssytrd_lwork
-   dsytrd_lwork
-
-   chetrd
-   zhetrd
-
-   chetrd_lwork
-   zhetrd_lwork
-
-   chesv
-   zhesv
-
-   chesv_lwork
-   zhesv_lwork
-
-   chesvx
-   zhesvx
-
-   chesvx_lwork
-   zhesvx_lwork
-
-   chegst
-   zhegst
-
    sgetrf
    dgetrf
    cgetrf
@@ -259,12 +219,30 @@
    cggev
    zggev
 
+   sgglse
+   dgglse
+   cgglse
+   zgglse
+
+   sgglse_lwork
+   dgglse_lwork
+   cgglse_lwork
+   zgglse_lwork
+
+   sgtsv
+   dgtsv
+   cgtsv
+   zgtsv
+
    chbevd
    zhbevd
 
    chbevx
    zhbevx
 
+   checon
+   zhecon
+
    cheev
    zheev
 
@@ -274,6 +252,9 @@
    cheevr
    zheevr
 
+   chegst
+   zhegst
+
    chegv
    zhegv
 
@@ -283,6 +264,41 @@
    chegvx
    zhegvx
 
+   chesv
+   zhesv
+
+   chesv_lwork
+   zhesv_lwork
+
+   chesvx
+   zhesvx
+
+   chesvx_lwork
+   zhesvx_lwork
+
+   chetrd
+   zhetrd
+
+   chetrd_lwork
+   zhetrd_lwork
+
+   chetrf
+   zhetrf
+
+   chetrf_lwork
+   zhetrf_lwork
+
+   chfrk
+   zhfrk
+
+   slamch
+   dlamch
+
+   slange
+   dlange
+   clange
+   zlange
+
    slarf
    dlarf
    clarf
@@ -311,6 +327,26 @@
    clauum
    zlauum
 
+   sorghr
+   dorghr
+   sorghr_lwork
+   dorghr_lwork
+
+   sorgqr
+   dorgqr
+
+   sorgrq
+   dorgrq
+
+   sormqr
+   dormqr
+
+   sormrz
+   dormrz
+
+   sormrz_lwork
+   dormrz_lwork
+
    spbsv
    dpbsv
    cpbsv
@@ -326,6 +362,26 @@
    cpbtrs
    zpbtrs
 
+   spftrf
+   dpftrf
+   cpftrf
+   zpftrf
+
+   spftri
+   dpftri
+   cpftri
+   zpftri
+
+   spftrs
+   dpftrs
+   cpftrs
+   zpftrs
+
+   spocon
+   dpocon
+   cpocon
+   zpocon
+
    sposv
    dposv
    cposv
@@ -336,11 +392,6 @@
    cposvx
    zposvx
 
-   spocon
-   dpocon
-   cpocon
-   zpocon
-
    spotrf
    dpotrf
    cpotrf
@@ -356,86 +407,13 @@
    cpotrs
    zpotrs
 
-   crot
-   zrot
-
-   strsyl
-   dtrsyl
-   ctrsyl
-   ztrsyl
-
-   strtri
-   dtrtri
-   ctrtri
-   ztrtri
-
-   strtrs
-   dtrtrs
-   ctrtrs
-   ztrtrs
-
-   spftrf
-   dpftrf
-   cpftrf
-   zpftrf
-
-   spftri
-   dpftri
-   cpftri
-   zpftri
-
-   spftrs
-   dpftrs
-   cpftrs
-   zpftrs
-
-   cunghr
-   zunghr
-
-   cungqr
-   zungqr
-
-   cungrq
-   zungrq
-
-   cunmqr
-   zunmqr
-
-   cunmrz
-   zunmrz
-
-   cunmrz_lwork
-   zunmrz_lwork
-
-   sgtsv
-   dgtsv
-   cgtsv
-   zgtsv
-
    sptsv
    dptsv
    cptsv
    zptsv
 
-   slamch
-   dlamch
-
-   sorghr
-   dorghr
-   sorgqr
-   dorgqr
-
-   sorgrq
-   dorgrq
-
-   sormqr
-   dormqr
-
-   sormrz
-   dormrz
-
-   sormrz_lwork
-   dormrz_lwork
+   crot
+   zrot
 
    ssbev
    dsbev
@@ -446,21 +424,37 @@
    ssbevx
    dsbevx
 
+   ssfrk
+   dsfrk
+
    sstebz
    dstebz
 
+   sstein
+   dstein
+
    sstemr
    dstemr
 
+   sstemr_lwork
+   dstemr_lwork
+
    ssterf
    dsterf
 
-   sstein
-   dstein
-
    sstev
    dstev
 
+   ssycon
+   dsycon
+   csycon
+   zsycon
+
+   ssyconv
+   dsyconv
+   csyconv
+   zsyconv
+
    ssyev
    dsyev
 
@@ -470,6 +464,9 @@
    ssyevr
    dsyevr
 
+   ssygst
+   dsygst
+
    ssygv
    dsygv
 
@@ -479,22 +476,52 @@
    ssygvx
    dsygvx
 
-   ssfrk
-   dsfrk
+   ssysv
+   dsysv
+   csysv
+   zsysv
 
-   chfrk
-   zhfrk
+   ssysv_lwork
+   dsysv_lwork
+   csysv_lwork
+   zsysv_lwork
+
+   ssysvx
+   dsysvx
+   csysvx
+   zsysvx
+
+   ssysvx_lwork
+   dsysvx_lwork
+   csysvx_lwork
+   zsysvx_lwork
+
+   ssytf2
+   dsytf2
+   csytf2
+   zsytf2
+
+   ssytrd
+   dsytrd
+
+   ssytrd_lwork
+   dsytrd_lwork
+
+   ssytrf
+   dsytrf
+   csytrf
+   zsytrf
+
+   ssytrf_lwork
+   dsytrf_lwork
+   csytrf_lwork
+   zsytrf_lwork
 
    stfsm
    dtfsm
    ctfsm
    ztfsm
 
-   stpttf
-   dtpttf
-   ctpttf
-   ztpttf
-
    stfttp
    dtfttp
    ctfttp
@@ -505,26 +532,46 @@
    ctfttr
    ztfttr
 
-   strttf
-   dtrttf
-   ctrttf
-   ztrttf
+   stgsen
+   dtgsen
+   ctgsen
+   ztgsen
+
+   stpttf
+   dtpttf
+   ctpttf
+   ztpttf
 
    stpttr
    dtpttr
    ctpttr
    ztpttr
 
+   strsyl
+   dtrsyl
+   ctrsyl
+   ztrsyl
+
+   strtri
+   dtrtri
+   ctrtri
+   ztrtri
+
+   strtrs
+   dtrtrs
+   ctrtrs
+   ztrtrs
+
+   strttf
+   dtrttf
+   ctrttf
+   ztrttf
+
    strttp
    dtrttp
    ctrttp
    ztrttp
 
-   stfsm
-   dtfsm
-   ctfsm
-   dtfsm
-
    stzrzf
    dtzrzf
    ctzrzf
@@ -535,10 +582,26 @@
    ctzrzf_lwork
    ztzrzf_lwork
 
-   slange
-   dlange
-   clange
-   zlange
+   cunghr
+   zunghr
+
+   cunghr_lwork
+   zunghr_lwork
+
+   cungqr
+   zungqr
+
+   cungrq
+   zungrq
+
+   cunmqr
+   zunmqr
+
+   cunmrz
+   zunmrz
+
+   cunmrz_lwork
+   zunmrz_lwork
 
    ilaver
 
@@ -548,16 +611,8 @@
 #
 
 from __future__ import division, print_function, absolute_import
-
-__all__ = ['get_lapack_funcs']
-
 import numpy as _np
-
 from .blas import _get_funcs
-
-# Backward compatibility:
-from .blas import find_best_blas_type as find_best_lapack_type
-
 from scipy.linalg import _flapack
 try:
     from scipy.linalg import _clapack
@@ -565,6 +620,7 @@
     _clapack = None
 
 # Backward compatibility
+from .blas import find_best_blas_type as find_best_lapack_type
 from scipy._lib._util import DeprecatedImport as _DeprecatedImport
 clapack = _DeprecatedImport(""scipy.linalg.blas.clapack"", ""scipy.linalg.lapack"")
 flapack = _DeprecatedImport(""scipy.linalg.blas.flapack"", ""scipy.linalg.lapack"")
@@ -574,6 +630,8 @@
 from scipy.linalg._flapack import *
 del empty_module
 
+__all__ = ['get_lapack_funcs']
+
 _dep_message = """"""The `*gegv` family of routines has been deprecated in
 LAPACK 3.6.0 in favor of the `*ggev` family of routines.
 The corresponding wrappers will be removed from SciPy in
"
ENH: Add wrappers for ?syconv routines,709f1c78a3e40e161151463bccdaec34f949b892,"diff --git a/scipy/linalg/flapack_sym_herm.pyf.src b/scipy/linalg/flapack_sym_herm.pyf.src
index c892c348c963..f996237ea696 100644
--- a/scipy/linalg/flapack_sym_herm.pyf.src
+++ b/scipy/linalg/flapack_sym_herm.pyf.src
@@ -370,6 +370,25 @@ end subroutine <prefix2c>heevd
 
   end subroutine <c,z,c,z><sy,\0,he,\2>con
 
+
+  subroutine <prefix>syconv(lower,way,n,a,lda,ipiv,e,info)
+  ! ?SYCONV converts A given by ???TRF into L and D and vice-versa.
+  ! Get Non-diag elements of D (returned in workspace) and apply or reverse permutation done in TRF.
+
+    callstatement (*f2py_func)((lower?""L"":""U""),(way?""R"":""C""),&n,a,&lda,ipiv,e,&info)
+    callprotoargument char*,char*,int*,<ctype>*,int*,int*,<ctype>*,int*
+
+    integer optional,intent(in),check(lower==0||lower==1) :: lower = 0
+    integer optional,intent(in),check(way==0||way==1) :: way = 0
+    integer depend(a),intent(hide):: n = shape(a,0)
+    <ftype> dimension(n,n),check(shape(a,0)==shape(a,1)),intent(in,out,copy,out=a):: a
+    integer intent(hide),depend(a) :: lda = max(shape(a,0),1)
+    integer intent(in),dimension(n),depend(n) :: ipiv
+    <ftype> intent(out),dimension(n),depend(n):: e
+    integer intent(out) :: info
+  
+  end subroutine <prefix>syconv
+
   subroutine <prefix2c>hegst(n,a,lda,b,ldb,info,itype,lower)
 
     ! c, info = hegst(a,b)
diff --git a/scipy/linalg/tests/test_lapack.py b/scipy/linalg/tests/test_lapack.py
index a4a88257c2e8..902aa12012c9 100644
--- a/scipy/linalg/tests/test_lapack.py
+++ b/scipy/linalg/tests/test_lapack.py
@@ -19,10 +19,10 @@
 from numpy import (eye, ones, zeros, zeros_like, triu, tril, tril_indices,
                    triu_indices)
 
-from numpy.random import rand, seed
+from numpy.random import rand, randint, seed
 
 from scipy.linalg import _flapack as flapack
-from scipy.linalg import inv, svd, cholesky, solve
+from scipy.linalg import inv, svd, cholesky, solve, ldl
 from scipy.linalg.lapack import _compute_lwork
 
 try:
@@ -1243,3 +1243,36 @@ def test_sfrk_hfrk():
         A_out, _ = tfttr(n, Afp_out)
         assert_array_almost_equal(A_out, triu(-C.dot(C.conj().T) + 2*A),
                                   decimal=4 if ind % 2 == 0 else 6)
+
+
+def test_syconv():
+    """"""
+    Test for going back and forth between the returned format of he/sytrf to
+    L and D factors/permutations.
+    """"""
+    seed(1234)
+    for ind, dtype in enumerate(DTYPES):
+        n = 10
+
+        if ind > 1:
+            A = (randint(-30, 30, (n, n)) +
+                 randint(-30, 30, (n, n))*1j).astype(dtype)
+
+            A = A + A.conj().T
+        else:
+            A = randint(-30, 30, (n, n)).astype(dtype)
+            A = A + A.T + n*eye(n)
+
+        tol = 100*np.spacing(dtype(1.0).real)
+        syconv, trf = get_lapack_funcs(('syconv', 'sytrf'), dtype=dtype)
+
+        L, D, perm = ldl(A, lower=1, hermitian=False)
+        ldu, ipiv, info = trf(A, lower=1)
+        a, e, info = syconv(ldu, ipiv, lower=1)
+        assert_allclose(tril(a, -1,), tril(L[perm, :], -1), atol=tol, rtol=0.)
+
+        # Test also upper
+        U, D, perm = ldl(A, lower=0, hermitian=False)
+        ldu, ipiv, info = trf(A, lower=0)
+        a, e, info = syconv(ldu, ipiv, lower=0)
+        assert_allclose(triu(a, 1), triu(U[perm, :], 1), atol=tol, rtol=0.)
"
TST:MAINT: use pytest parametrize,bbd0a8793dcf8b61e7248c10c77ee10bcb50a4a0,"diff --git a/scipy/optimize/tests/test_zeros.py b/scipy/optimize/tests/test_zeros.py
index 0488b7547db5..22431a894503 100644
--- a/scipy/optimize/tests/test_zeros.py
+++ b/scipy/optimize/tests/test_zeros.py
@@ -663,22 +663,22 @@ def fpp_array(x):
     assert result.converged.all()
 
 
-def test_gh9254_flag_if_maxiter_exceeded():
+@pytest.mark.parametrize(
+    ""maximum_iterations,flag_expected"",
+    [(10, zeros.CONVERR), (100, zeros.CONVERGED)])
+def test_gh9254_flag_if_maxiter_exceeded(maximum_iterations, flag_expected):
     """"""
     Test that if the maximum iterations is exceeded that the flag is not
     converged.
     """"""
-    maximum_iterations = 10
-    r = zeros.brentq(
+    result = zeros.brentq(
         lambda x: ((1.2*x - 2.3)*x + 3.4)*x - 4.5,
         -30, 30, (), 1e-6, 1e-6, maximum_iterations,
         full_output=True, disp=False)
-    assert r[1].flag == zeros.CONVERR
-    assert r[1].iterations == maximum_iterations
-    more_maximum_iterations = 100
-    r = zeros.brentq(
-        lambda x: ((1.2*x - 2.3)*x + 3.4)*x - 4.5,
-        -30, 30, (), 1e-6, 1e-6, more_maximum_iterations,
-        full_output=True, disp=False)
-    assert r[1].flag == zeros.CONVERGED
-    assert r[1].iterations < more_maximum_iterations
+    assert result[1].flag == flag_expected
+    if flag_expected == zeros.CONVERR:
+        # didn't converge because exceeded maximum iterations
+        assert result[1].iterations == maximum_iterations
+    elif flag_expected == zeros.CONVERGED:
+        # converged before maximum iterations
+        assert result[1].iterations < maximum_iterations
"
"TST: add test for failure flag is maxiter

* also fix flag reset outside if statement so need else if converged
* also add test to see that else shows converged still true if converged
 before max iterations exceeded",b664b1d550b3fadb260e1c88345ab41b2484dee4,"diff --git a/scipy/optimize/tests/test_zeros.py b/scipy/optimize/tests/test_zeros.py
index b53b843bf316..0488b7547db5 100644
--- a/scipy/optimize/tests/test_zeros.py
+++ b/scipy/optimize/tests/test_zeros.py
@@ -661,3 +661,24 @@ def fpp_array(x):
         f, x0_array, fprime=fp, fprime2=fpp_array, full_output=True
     )
     assert result.converged.all()
+
+
+def test_gh9254_flag_if_maxiter_exceeded():
+    """"""
+    Test that if the maximum iterations is exceeded that the flag is not
+    converged.
+    """"""
+    maximum_iterations = 10
+    r = zeros.brentq(
+        lambda x: ((1.2*x - 2.3)*x + 3.4)*x - 4.5,
+        -30, 30, (), 1e-6, 1e-6, maximum_iterations,
+        full_output=True, disp=False)
+    assert r[1].flag == zeros.CONVERR
+    assert r[1].iterations == maximum_iterations
+    more_maximum_iterations = 100
+    r = zeros.brentq(
+        lambda x: ((1.2*x - 2.3)*x + 3.4)*x - 4.5,
+        -30, 30, (), 1e-6, 1e-6, more_maximum_iterations,
+        full_output=True, disp=False)
+    assert r[1].flag == zeros.CONVERGED
+    assert r[1].iterations < more_maximum_iterations
diff --git a/scipy/optimize/zeros.c b/scipy/optimize/zeros.c
index 70bd32985f54..80488a7325ee 100644
--- a/scipy/optimize/zeros.c
+++ b/scipy/optimize/zeros.c
@@ -134,7 +134,10 @@ call_solver(solver_type solver, PyObject *self, PyObject *args)
             flag = CONVERR;
         }
     }
-    flag = CONVERGED;
+    else
+    {
+        flag = CONVERGED;
+    }
     if (fulloutput) {
         return Py_BuildValue(""diii"",
                 zero, solver_stats.funcalls, solver_stats.iterations, flag);
"
"don't set flag to ""converged"" if max iter exceeded

* be consistent with underlying functions `brentq`, ``bisection`, `ridder` that return `error_num` of `CONVERR` when maximum iteration exceeded, not ""converged""
* be consistent with Newton and TOMS also return `_CONVERR` if maximum iterations exceeded instead of ""converged""
* closes #9254
* use macro `CONVERGED` to be explicit in test for non-convergence
* remove unused line `flag = 1;` before `return NULL` which raises an exception, so flag never used
* set `flag = CONVERR` to be consistent with underlying functions in `Zeros/` and Newton and TOMS
* explicitly set `flag = CONVERGED` if test for non-convergence fails, meaning successful convergence",63f2950ccd6c8bc0255d8ec4999de766d390ee34,"diff --git a/scipy/optimize/zeros.c b/scipy/optimize/zeros.c
index 97b14825dfa1..70bd32985f54 100644
--- a/scipy/optimize/zeros.c
+++ b/scipy/optimize/zeros.c
@@ -116,7 +116,7 @@ call_solver(solver_type solver, PyObject *self, PyObject *args)
         return NULL;
     }
 
-    if (solver_stats.error_num != 0) {
+    if (solver_stats.error_num != CONVERGED) {
         if (solver_stats.error_num == SIGNERR) {
             PyErr_SetString(PyExc_ValueError,
                     ""f(a) and f(b) must have different signs"");
@@ -129,11 +129,12 @@ call_solver(solver_type solver, PyObject *self, PyObject *args)
                         ""Failed to converge after %d iterations."",
                         solver_stats.iterations);
                 PyErr_SetString(PyExc_RuntimeError, msg);
-                flag = 1;
                 return NULL;
             }
+            flag = CONVERR;
         }
     }
+    flag = CONVERGED;
     if (fulloutput) {
         return Py_BuildValue(""diii"",
                 zero, solver_stats.funcalls, solver_stats.iterations, flag);
"
"Merge pull request #10021 from nmayorov/hermite_spline

ENH: Introduce CubicHermiteSpline",de2c981ea6ff84a05f22d146706915f6c55acc4b,"diff --git a/scipy/interpolate/__init__.py b/scipy/interpolate/__init__.py
index 67855de7fbdb..b6e870d3d7d5 100644
--- a/scipy/interpolate/__init__.py
+++ b/scipy/interpolate/__init__.py
@@ -22,10 +22,11 @@
    interp1d
    BarycentricInterpolator
    KroghInterpolator
-   PchipInterpolator
    barycentric_interpolate
    krogh_interpolate
    pchip_interpolate
+   CubicHermiteSpline
+   PchipInterpolator
    Akima1DInterpolator
    CubicSpline
    PPoly
diff --git a/scipy/interpolate/_cubic.py b/scipy/interpolate/_cubic.py
index c335045a1847..657fed39dd36 100644
--- a/scipy/interpolate/_cubic.py
+++ b/scipy/interpolate/_cubic.py
@@ -12,11 +12,153 @@
 from scipy.linalg import solve_banded, solve
 
 
-__all__ = [""PchipInterpolator"", ""pchip_interpolate"",
+__all__ = [""CubicHermiteSpline"", ""PchipInterpolator"", ""pchip_interpolate"",
            ""Akima1DInterpolator"", ""CubicSpline""]
 
 
-class PchipInterpolator(BPoly):
+def prepare_input(x, y, axis, dydx=None):
+    """"""Prepare input for cubic spline interpolators.
+
+    All data are converted to numpy arrays and checked for correctness.
+    Axes equal to `axis` of arrays `y` and `dydx` are rolled to be the 0-th
+    axis. The value of `axis` is converted to lie in
+    [0, number of dimensions of `y`).
+    """"""
+
+    x, y = map(np.asarray, (x, y))
+
+    if np.issubdtype(x.dtype, np.complexfloating):
+        raise ValueError(""`x` must contain real values."")
+
+    if np.issubdtype(y.dtype, np.complexfloating):
+        dtype = complex
+    else:
+        dtype = float
+
+    if dydx is not None:
+        dydx = np.asarray(dydx)
+        if y.shape != dydx.shape:
+            raise ValueError(""The shapes of `y` and `dydx` must be identical."")
+        if np.issubdtype(dydx.dtype, np.complexfloating):
+            dtype = complex
+        dydx = dydx.astype(dtype, copy=False)
+
+    y = y.astype(dtype, copy=False)
+    axis = axis % y.ndim
+    if x.ndim != 1:
+        raise ValueError(""`x` must be 1-dimensional."")
+    if x.shape[0] < 2:
+        raise ValueError(""`x` must contain at least 2 elements."")
+    if x.shape[0] != y.shape[axis]:
+        raise ValueError(""The length of `y` along `axis`={0} doesn't ""
+                         ""match the length of `x`"".format(axis))
+
+    if not np.all(np.isfinite(x)):
+        raise ValueError(""`x` must contain only finite values."")
+    if not np.all(np.isfinite(y)):
+        raise ValueError(""`y` must contain only finite values."")
+
+    if dydx is not None and not np.all(np.isfinite(dydx)):
+        raise ValueError(""`dydx` must contain only finite values."")
+
+    dx = np.diff(x)
+    if np.any(dx <= 0):
+        raise ValueError(""`x` must be strictly increasing sequence."")
+
+    y = np.rollaxis(y, axis)
+    if dydx is not None:
+        dydx = np.rollaxis(dydx, axis)
+
+    return x, dx, y, axis, dydx
+
+
+class CubicHermiteSpline(PPoly):
+    """"""Piecewise-cubic interpolator matching values and first derivatives.
+
+    The result is represented as a `PPoly` instance.
+
+    Parameters
+    ----------
+    x : array_like, shape (n,)
+        1-d array containing values of the independent variable.
+        Values must be real, finite and in strictly increasing order.
+    y : array_like
+        Array containing values of the dependent variable. It can have
+        arbitrary number of dimensions, but the length along ``axis``
+        (see below) must match the length of ``x``. Values must be finite.
+    dydx : array_like
+        Array containing derivatives of the dependent variable. It can have
+        arbitrary number of dimensions, but the length along ``axis``
+        (see below) must match the length of ``x``. Values must be finite.
+    axis : int, optional
+        Axis along which `y` is assumed to be varying. Meaning that for
+        ``x[i]`` the corresponding values are ``np.take(y, i, axis=axis)``.
+        Default is 0.
+    extrapolate : {bool, 'periodic', None}, optional
+        If bool, determines whether to extrapolate to out-of-bounds points
+        based on first and last intervals, or to return NaNs. If 'periodic',
+        periodic extrapolation is used. If None (default), it is set to True.
+
+    Attributes
+    ----------
+    x : ndarray, shape (n,)
+        Breakpoints. The same ``x`` which was passed to the constructor.
+    c : ndarray, shape (4, n-1, ...)
+        Coefficients of the polynomials on each segment. The trailing
+        dimensions match the dimensions of `y`, excluding ``axis``.
+        For example, if `y` is 1-d, then ``c[k, i]`` is a coefficient for
+        ``(x-x[i])**(3-k)`` on the segment between ``x[i]`` and ``x[i+1]``.
+    axis : int
+        Interpolation axis. The same axis which was passed to the
+        constructor.
+
+    Methods
+    -------
+    __call__
+    derivative
+    antiderivative
+    integrate
+    roots
+
+    See Also
+    --------
+    Akima1DInterpolator
+    PchipInterpolator
+    CubicSpline
+    PPoly
+
+    Notes
+    -----
+    If you want to create a higher-order spline matching higher-order
+    derivatives, use `BPoly.from_derivatives`.
+
+    References
+    ----------
+    .. [1] `Cubic Hermite spline
+            <https://en.wikipedia.org/wiki/Cubic_Hermite_spline>`_
+            on Wikipedia.
+    """"""
+    def __init__(self, x, y, dydx, axis=0, extrapolate=None):
+        if extrapolate is None:
+            extrapolate = True
+
+        x, dx, y, axis, dydx = prepare_input(x, y, axis, dydx)
+
+        dxr = dx.reshape([dx.shape[0]] + [1] * (y.ndim - 1))
+        slope = np.diff(y, axis=0) / dxr
+        t = (dydx[:-1] + dydx[1:] - 2 * slope) / dxr
+
+        c = np.empty((4, len(x) - 1) + y.shape[1:], dtype=t.dtype)
+        c[0] = t / dxr
+        c[1] = (slope - dydx[:-1]) / dxr - t
+        c[2] = dydx[:-1]
+        c[3] = y[:-1]
+
+        super(CubicHermiteSpline, self).__init__(c, x, extrapolate=extrapolate)
+        self.axis = axis
+
+
+class PchipInterpolator(CubicHermiteSpline):
     r""""""PCHIP 1-d monotonic cubic interpolation.
 
     ``x`` and ``y`` are arrays of values used to approximate some function f,
@@ -48,9 +190,10 @@ class PchipInterpolator(BPoly):
 
     See Also
     --------
+    CubicHermiteSpline
     Akima1DInterpolator
     CubicSpline
-    BPoly
+    PPoly
 
     Notes
     -----
@@ -89,28 +232,13 @@ class PchipInterpolator(BPoly):
 
     """"""
     def __init__(self, x, y, axis=0, extrapolate=None):
-        x = _asarray_validated(x, check_finite=False, as_inexact=True)
-        y = _asarray_validated(y, check_finite=False, as_inexact=True)
-
-        axis = axis % y.ndim
-
+        x, _, y, axis, _ = prepare_input(x, y, axis)
         xp = x.reshape((x.shape[0],) + (1,)*(y.ndim-1))
-        yp = np.rollaxis(y, axis)
-
-        dk = self._find_derivatives(xp, yp)
-        data = np.hstack((yp[:, None, ...], dk[:, None, ...]))
-
-        _b = BPoly.from_derivatives(x, data, orders=None)
-        super(PchipInterpolator, self).__init__(_b.c, _b.x,
+        dk = self._find_derivatives(xp, y)
+        super(PchipInterpolator, self).__init__(x, y, dk, axis=0,
                                                 extrapolate=extrapolate)
         self.axis = axis
 
-    def roots(self):
-        """"""
-        Return the roots of the interpolated function.
-        """"""
-        return (PPoly.from_bernstein_basis(self)).roots()
-
     @staticmethod
     def _edge_case(h0, h1, m0, m1):
         # one-sided three-point estimate for the derivative
@@ -222,7 +350,7 @@ def pchip_interpolate(xi, yi, x, der=0, axis=0):
         return [P.derivative(nu)(x) for nu in der]
 
 
-class Akima1DInterpolator(PPoly):
+class Akima1DInterpolator(CubicHermiteSpline):
     """"""
     Akima interpolator
 
@@ -274,24 +402,9 @@ class Akima1DInterpolator(PPoly):
     def __init__(self, x, y, axis=0):
         # Original implementation in MATLAB by N. Shamsundar (BSD licensed), see
         # https://www.mathworks.com/matlabcentral/fileexchange/1814-akima-interpolation
-        x, y = map(np.asarray, (x, y))
-        axis = axis % y.ndim
-
-        if np.any(np.diff(x) < 0.):
-            raise ValueError(""x must be strictly ascending"")
-        if x.ndim != 1:
-            raise ValueError(""x must be 1-dimensional"")
-        if x.size < 2:
-            raise ValueError(""at least 2 breakpoints are needed"")
-        if x.size != y.shape[axis]:
-            raise ValueError(""x.shape must equal y.shape[%s]"" % axis)
-
-        # move interpolation axis to front
-        y = np.rollaxis(y, axis)
-
+        x, dx, y, axis, _ = prepare_input(x, y, axis)
         # determine slopes between breakpoints
         m = np.empty((x.size + 3, ) + y.shape[1:])
-        dx = np.diff(x)
         dx = dx[(slice(None), ) + (None, ) * (y.ndim - 1)]
         m[2:-2] = np.diff(y, axis=0) / dx
 
@@ -316,17 +429,9 @@ def __init__(self, x, y, axis=0):
         # Set the slope at breakpoint
         t[ind] = (f1[ind] * m[(x_ind + 1,) + y_ind] +
                   f2[ind] * m[(x_ind + 2,) + y_ind]) / f12[ind]
-        # calculate the higher order coefficients
-        c = (3. * m[2:-2] - 2. * t[:-1] - t[1:]) / dx
-        d = (t[:-1] + t[1:] - 2. * m[2:-2]) / dx ** 2
-
-        coeff = np.zeros((4, x.size - 1) + y.shape[1:])
-        coeff[3] = y[:-1]
-        coeff[2] = t[:-1]
-        coeff[1] = c
-        coeff[0] = d
 
-        super(Akima1DInterpolator, self).__init__(coeff, x, extrapolate=False)
+        super(Akima1DInterpolator, self).__init__(x, y, t, axis=0,
+                                                  extrapolate=False)
         self.axis = axis
 
     def extend(self, c, x, right=True):
@@ -346,7 +451,7 @@ def from_bernstein_basis(cls, bp, extrapolate=None):
                                   ""an Akima interpolator."")
 
 
-class CubicSpline(PPoly):
+class CubicSpline(CubicHermiteSpline):
     """"""Cubic spline data interpolator.
 
     Interpolate data with a piecewise cubic polynomial which is twice
@@ -511,37 +616,8 @@ class CubicSpline(PPoly):
     .. [2] Carl de Boor, ""A Practical Guide to Splines"", Springer-Verlag, 1978.
     """"""
     def __init__(self, x, y, axis=0, bc_type='not-a-knot', extrapolate=None):
-        x, y = map(np.asarray, (x, y))
-
-        if np.issubdtype(x.dtype, np.complexfloating):
-            raise ValueError(""`x` must contain real values."")
-
-        if np.issubdtype(y.dtype, np.complexfloating):
-            dtype = complex
-        else:
-            dtype = float
-        y = y.astype(dtype, copy=False)
-
-        axis = axis % y.ndim
-        if x.ndim != 1:
-            raise ValueError(""`x` must be 1-dimensional."")
-        if x.shape[0] < 2:
-            raise ValueError(""`x` must contain at least 2 elements."")
-        if x.shape[0] != y.shape[axis]:
-            raise ValueError(""The length of `y` along `axis`={0} doesn't ""
-                             ""match the length of `x`"".format(axis))
-
-        if not np.all(np.isfinite(x)):
-            raise ValueError(""`x` must contain only finite values."")
-        if not np.all(np.isfinite(y)):
-            raise ValueError(""`y` must contain only finite values."")
-
-        dx = np.diff(x)
-        if np.any(dx <= 0):
-            raise ValueError(""`x` must be strictly increasing sequence."")
-
-        n = x.shape[0]
-        y = np.rollaxis(y, axis)
+        x, dx, y, axis, _ = prepare_input(x, y, axis)
+        n = len(x)
 
         bc, y = self._validate_bc(bc_type, y, y.shape[1:], axis)
 
@@ -689,15 +765,8 @@ def __init__(self, x, y, axis=0, bc_type='not-a-knot', extrapolate=None):
                 s = solve_banded((1, 1), A, b, overwrite_ab=True,
                                  overwrite_b=True, check_finite=False)
 
-        # Compute coefficients in PPoly form.
-        t = (s[:-1] + s[1:] - 2 * slope) / dxr
-        c = np.empty((4, n - 1) + y.shape[1:], dtype=t.dtype)
-        c[0] = t / dxr
-        c[1] = (slope - s[:-1]) / dxr - t
-        c[2] = s[:-1]
-        c[3] = y[:-1]
-
-        super(CubicSpline, self).__init__(c, x, extrapolate=extrapolate)
+        super(CubicSpline, self).__init__(x, y, s, axis=0,
+                                          extrapolate=extrapolate)
         self.axis = axis
 
     @staticmethod
diff --git a/scipy/interpolate/tests/test_polyint.py b/scipy/interpolate/tests/test_polyint.py
index 172e6ae44f46..40b96352066a 100644
--- a/scipy/interpolate/tests/test_polyint.py
+++ b/scipy/interpolate/tests/test_polyint.py
@@ -12,8 +12,9 @@
 from scipy.interpolate import (
     KroghInterpolator, krogh_interpolate,
     BarycentricInterpolator, barycentric_interpolate,
-    approximate_taylor_polynomial, pchip, PchipInterpolator,
-    pchip_interpolate, Akima1DInterpolator, CubicSpline, make_interp_spline)
+    approximate_taylor_polynomial, CubicHermiteSpline, pchip,
+    PchipInterpolator, pchip_interpolate, Akima1DInterpolator, CubicSpline,
+    make_interp_spline)
 
 from scipy._lib.six import xrange
 
@@ -32,7 +33,11 @@ def check_shape(interpolator_cls, x_shape, y_shape, deriv_shape=None, axis=0,
         return
 
     xi = np.zeros(x_shape)
-    yi = interpolator_cls(x, y, axis=axis, **extra_args)(xi)
+    if interpolator_cls is CubicHermiteSpline:
+        dydx = np.random.rand(*((6,) + y_shape)).transpose(s)
+        yi = interpolator_cls(x, y, dydx, axis=axis, **extra_args)(xi)
+    else:
+        yi = interpolator_cls(x, y, axis=axis, **extra_args)(xi)
 
     target_shape = ((deriv_shape or ()) + y.shape[:axis]
                     + x_shape + y.shape[axis:][1:])
@@ -40,7 +45,12 @@ def check_shape(interpolator_cls, x_shape, y_shape, deriv_shape=None, axis=0,
 
     # check it works also with lists
     if x_shape and y.size > 0:
-        interpolator_cls(list(x), list(y), axis=axis, **extra_args)(list(xi))
+        if interpolator_cls is CubicHermiteSpline:
+            interpolator_cls(list(x), list(y), list(dydx), axis=axis,
+                             **extra_args)(list(xi))
+        else:
+            interpolator_cls(list(x), list(y), axis=axis,
+                             **extra_args)(list(xi))
 
     # check also values
     if xi.size > 0 and deriv_shape is None:
@@ -60,8 +70,8 @@ def test_shapes():
     def spl_interp(x, y, axis):
         return make_interp_spline(x, y, axis=axis)
 
-    for ip in [KroghInterpolator, BarycentricInterpolator, pchip,
-               Akima1DInterpolator, CubicSpline, spl_interp]:
+    for ip in [KroghInterpolator, BarycentricInterpolator, CubicHermiteSpline,
+               pchip, Akima1DInterpolator, CubicSpline, spl_interp]:
         for s1 in SHAPES:
             for s2 in SHAPES:
                 for axis in range(-len(s2), len(s2)):
@@ -132,16 +142,18 @@ def bspl_antideriv(x, y, axis=0):
                     check_shape(ip, s1, s2, (), axis)
 
 
-def _check_complex(ip):
+def test_complex():
     x = [1, 2, 3, 4]
     y = [1, 2, 1j, 3]
-    p = ip(x, y)
-    assert_allclose(y, p(x))
 
-
-def test_complex():
     for ip in [KroghInterpolator, BarycentricInterpolator, pchip, CubicSpline]:
-        _check_complex(ip)
+        p = ip(x, y)
+        assert_allclose(y, p(x))
+
+    dydx = [0, -1j, 2, 3j]
+    p = CubicHermiteSpline(x, y, dydx)
+    assert_allclose(y, p(x))
+    assert_allclose(dydx, p(x, 1))
 
 
 class TestKrogh(object):
@@ -370,7 +382,7 @@ def test_overshoot(self):
                 y1, y2 = y2, y1
             xp = np.linspace(x1, x2, 10)
             yp = p(xp)
-            assert_(((y1 <= yp) & (yp <= y2)).all())
+            assert_(((y1 <= yp + 1e-15) & (yp <= y2 + 1e-15)).all())
 
     def test_monotone(self):
         # PCHIP should preserve monotonicty
@@ -480,6 +492,7 @@ def test_roots(self):
         r = p.roots()
         assert_allclose(r, 0.5)
 
+
 class TestCubicSpline(object):
     @staticmethod
     def check_correctness(S, bc_start='not-a-knot', bc_end='not-a-knot',
@@ -662,3 +675,21 @@ def test_incorrect_inputs(self):
         # periodic condition, y[-1] must be equal to y[0]:
         assert_raises(ValueError, CubicSpline, x, y, 0, 'periodic', True)
 
+
+def test_CubicHermiteSpline_correctness():
+    x = [0, 2, 7]
+    y = [-1, 2, 3]
+    dydx = [0, 3, 7]
+    s = CubicHermiteSpline(x, y, dydx)
+    assert_allclose(s(x), y, rtol=1e-15)
+    assert_allclose(s(x, 1), dydx, rtol=1e-15)
+
+
+def test_CubicHermiteSpline_error_handling():
+    x = [1, 2, 3]
+    y = [0, 3, 5]
+    dydx = [1, -1, 2, 3]
+    assert_raises(ValueError, CubicHermiteSpline, x, y, dydx)
+
+    dydx_with_nan = [1, 0, np.nan]
+    assert_raises(ValueError, CubicHermiteSpline, x, y, dydx_with_nan)
"
TST: Add tests for error handling in CubicHermiteSpline,ffa6ff714adadc24bc92de374c011d2924cfd501,"diff --git a/scipy/interpolate/tests/test_polyint.py b/scipy/interpolate/tests/test_polyint.py
index c7eb09f7a22a..40b96352066a 100644
--- a/scipy/interpolate/tests/test_polyint.py
+++ b/scipy/interpolate/tests/test_polyint.py
@@ -676,10 +676,20 @@ def test_incorrect_inputs(self):
         assert_raises(ValueError, CubicSpline, x, y, 0, 'periodic', True)
 
 
-def test_CubicHermiteSpline():
+def test_CubicHermiteSpline_correctness():
     x = [0, 2, 7]
     y = [-1, 2, 3]
     dydx = [0, 3, 7]
     s = CubicHermiteSpline(x, y, dydx)
     assert_allclose(s(x), y, rtol=1e-15)
     assert_allclose(s(x, 1), dydx, rtol=1e-15)
+
+
+def test_CubicHermiteSpline_error_handling():
+    x = [1, 2, 3]
+    y = [0, 3, 5]
+    dydx = [1, -1, 2, 3]
+    assert_raises(ValueError, CubicHermiteSpline, x, y, dydx)
+
+    dydx_with_nan = [1, 0, np.nan]
+    assert_raises(ValueError, CubicHermiteSpline, x, y, dydx_with_nan)
"
ENH: optimize: update _get_solver docstring,d56a5d8d8d9d398ca84c77c87f9b31dd10d8fb77,"diff --git a/scipy/optimize/_linprog_ip.py b/scipy/optimize/_linprog_ip.py
index 28abf2edc0a4..03f8fc9f29f7 100644
--- a/scipy/optimize/_linprog_ip.py
+++ b/scipy/optimize/_linprog_ip.py
@@ -46,22 +46,33 @@ def _get_solver(M, sparse=False, lstsq=False, sym_pos=True,
 
     Parameters
     ----------
-    sparse : bool
+    M : 2D array
+        As defined in [4] Equation 8.31
+    sparse : bool (default = False)
         True if the system to be solved is sparse. This is typically set
         True when the original ``A_ub`` and ``A_eq`` arrays are sparse.
-    lstsq : bool
+    lstsq : bool (default = False)
         True if the system is ill-conditioned and/or (nearly) singular and
         thus a more robust least-squares solver is desired. This is sometimes
         needed as the solution is approached.
-    sym_pos : bool
+    sym_pos : bool (default = True)
         True if the system matrix is symmetric positive definite
         Sometimes this needs to be set false as the solution is approached,
         even when the system should be symmetric positive definite, due to
         numerical difficulties.
-    cholesky : bool
+    cholesky : bool (default = True)
         True if the system is to be solved by Cholesky, rather than LU,
         decomposition. This is typically faster unless the problem is very
         small or prone to numerical difficulties.
+    permc_spec : str (default = 'MMD_AT_PLUS_A')
+        Sparsity preservation strategy used by SuperLU. Acceptable values are:
+
+        - ``NATURAL``: natural ordering.
+        - ``MMD_ATA``: minimum degree ordering on the structure of A^T A.
+        - ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.
+        - ``COLAMD``: approximate minimum degree column ordering.
+
+        See SuperLU documentation.
 
     Returns
     -------
@@ -981,21 +992,21 @@ def _linprog_ip(
     For dense problems, solvers are tried in the following order:
 
     1. ``scipy.linalg.cho_factor`` (if scikit-sparse and SuiteSparse are installed)
-    
+
     2. ``scipy.linalg.solve`` with option ``sym_pos=True``
-    
+
     3. ``scipy.linalg.solve`` with option ``sym_pos=False``
-    
+
     4. ``scipy.linalg.lstsq``
 
     For sparse problems:
 
     1. ``sksparse.cholmod.cholesky`` (if scikit-sparse and SuiteSparse are installed)
-    
+
     2. ``scipy.sparse.linalg.factorized`` (if scikits.umfpack and SuiteSparse are installed)
-    
+
     3. ``scipy.sparse.linalg.splu`` (which uses SuperLU distributed with SciPy)
-    
+
     4. ``scipy.sparse.linalg.lsqr``
 
     If the solver fails for any reason, successively more robust (but slower)
"
"Merge pull request #10072 from WarrenWeckesser/fix-boxcox

BUG: stats: Fix boxcox_llf to avoid loss of precision.",bc493fc7630457e80b4c7fd17efa25180925c64d,"diff --git a/scipy/stats/morestats.py b/scipy/stats/morestats.py
index 23c0ab14b0ac..c59e2c74ae5e 100644
--- a/scipy/stats/morestats.py
+++ b/scipy/stats/morestats.py
@@ -896,11 +896,18 @@ def boxcox_llf(lmb, data):
     if N == 0:
         return np.nan
 
-    y = boxcox(data, lmb)
-    y_mean = np.mean(y, axis=0)
-    llf = (lmb - 1) * np.sum(np.log(data), axis=0)
-    llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))
-    return llf
+    logdata = np.log(data)
+
+    # Compute the variance of the transformed data.
+    if lmb == 0:
+        variance = np.var(logdata, axis=0)
+    else:
+        # Transform without the constant offset 1/lmb.  The offset does
+        # not effect the variance, and the subtraction of the offset can
+        # lead to loss of precision.
+        variance = np.var(data**lmb / lmb, axis=0)
+
+    return (lmb - 1) * np.sum(logdata, axis=0) - N/2 * np.log(variance)
 
 
 def _boxcox_conf_interval(x, lmax, alpha):
diff --git a/scipy/stats/tests/test_morestats.py b/scipy/stats/tests/test_morestats.py
index 84ae99c7a6cd..4d8f3ac9147c 100644
--- a/scipy/stats/tests/test_morestats.py
+++ b/scipy/stats/tests/test_morestats.py
@@ -1211,6 +1211,66 @@ def test_2d_input(self):
     def test_empty(self):
         assert_(np.isnan(stats.boxcox_llf(1, [])))
 
+    def test_gh_6873(self):
+        # Regression test for gh-6873.
+        # This example was taken from gh-7534, a duplicate of gh-6873.
+        data = [198.0, 233.0, 233.0, 392.0]
+        llf = stats.boxcox_llf(-8, data)
+        # The expected value was computed with mpmath.
+        assert_allclose(llf, -17.93934208579061)
+
+
+# This is the data from github user Qukaiyi, given as an example
+# of a data set that caused boxcox to fail.
+_boxcox_data = [
+    15957, 112079, 1039553, 711775, 173111, 307382, 183155, 53366, 760875,
+    207500, 160045, 473714, 40194, 440319, 133261, 265444, 155590, 36660,
+    904939, 55108, 138391, 339146, 458053, 63324, 1377727, 1342632, 41575,
+    68685, 172755, 63323, 368161, 199695, 538214, 167760, 388610, 398855,
+    1001873, 364591, 1320518, 194060, 194324, 2318551, 196114, 64225, 272000,
+    198668, 123585, 86420, 1925556, 695798, 88664, 46199, 759135, 28051,
+    345094, 1977752, 51778, 82746, 638126, 2560910, 45830, 140576, 1603787,
+    57371, 548730, 5343629, 2298913, 998813, 2156812, 423966, 68350, 145237,
+    131935, 1600305, 342359, 111398, 1409144, 281007, 60314, 242004, 113418,
+    246211, 61940, 95858, 957805, 40909, 307955, 174159, 124278, 241193,
+    872614, 304180, 146719, 64361, 87478, 509360, 167169, 933479, 620561,
+    483333, 97416, 143518, 286905, 597837, 2556043, 89065, 69944, 196858,
+    88883, 49379, 916265, 1527392, 626954, 54415, 89013, 2883386, 106096,
+    402697, 45578, 349852, 140379, 34648, 757343, 1305442, 2054757, 121232,
+    606048, 101492, 51426, 1820833, 83412, 136349, 1379924, 505977, 1303486,
+    95853, 146451, 285422, 2205423, 259020, 45864, 684547, 182014, 784334,
+    174793, 563068, 170745, 1195531, 63337, 71833, 199978, 2330904, 227335,
+    898280, 75294, 2011361, 116771, 157489, 807147, 1321443, 1148635, 2456524,
+    81839, 1228251, 97488, 1051892, 75397, 3009923, 2732230, 90923, 39735,
+    132433, 225033, 337555, 1204092, 686588, 1062402, 40362, 1361829, 1497217,
+    150074, 551459, 2019128, 39581, 45349, 1117187, 87845, 1877288, 164448,
+    10338362, 24942, 64737, 769946, 2469124, 2366997, 259124, 2667585, 29175,
+    56250, 74450, 96697, 5920978, 838375, 225914, 119494, 206004, 430907,
+    244083, 219495, 322239, 407426, 618748, 2087536, 2242124, 4736149, 124624,
+    406305, 240921, 2675273, 4425340, 821457, 578467, 28040, 348943, 48795,
+    145531, 52110, 1645730, 1768364, 348363, 85042, 2673847, 81935, 169075,
+    367733, 135474, 383327, 1207018, 93481, 5934183, 352190, 636533, 145870,
+    55659, 146215, 73191, 248681, 376907, 1606620, 169381, 81164, 246390,
+    236093, 885778, 335969, 49266, 381430, 307437, 350077, 34346, 49340,
+    84715, 527120, 40163, 46898, 4609439, 617038, 2239574, 159905, 118337,
+    120357, 430778, 3799158, 3516745, 54198, 2970796, 729239, 97848, 6317375,
+    887345, 58198, 88111, 867595, 210136, 1572103, 1420760, 574046, 845988,
+    509743, 397927, 1119016, 189955, 3883644, 291051, 126467, 1239907, 2556229,
+    411058, 657444, 2025234, 1211368, 93151, 577594, 4842264, 1531713, 305084,
+    479251, 20591, 1466166, 137417, 897756, 594767, 3606337, 32844, 82426,
+    1294831, 57174, 290167, 322066, 813146, 5671804, 4425684, 895607, 450598,
+    1048958, 232844, 56871, 46113, 70366, 701618, 97739, 157113, 865047,
+    194810, 1501615, 1765727, 38125, 2733376, 40642, 437590, 127337, 106310,
+    4167579, 665303, 809250, 1210317, 45750, 1853687, 348954, 156786, 90793,
+    1885504, 281501, 3902273, 359546, 797540, 623508, 3672775, 55330, 648221,
+    266831, 90030, 7118372, 735521, 1009925, 283901, 806005, 2434897, 94321,
+    309571, 4213597, 2213280, 120339, 64403, 8155209, 1686948, 4327743,
+    1868312, 135670, 3189615, 1569446, 706058, 58056, 2438625, 520619, 105201,
+    141961, 179990, 1351440, 3148662, 2804457, 2760144, 70775, 33807, 1926518,
+    2362142, 186761, 240941, 97860, 1040429, 1431035, 78892, 484039, 57845,
+    724126, 3166209, 175913, 159211, 1182095, 86734, 1921472, 513546, 326016,
+    1891609
+]
 
 class TestBoxcox(object):
 
@@ -1266,6 +1326,14 @@ def test_boxcox_bad_arg(self):
     def test_empty(self):
         assert_(stats.boxcox([]).shape == (0,))
 
+    def test_gh_6873(self):
+        # Regression test for gh-6873.
+        y, lam = stats.boxcox(_boxcox_data)
+        # The expected value of lam was computed with the function
+        # powerTransform in the R library 'car'.  I trust that value
+        # to only about five significant digits.
+        assert_allclose(lam, -0.051654, rtol=1e-5)
+
 
 class TestBoxcoxNormmax(object):
     def setup_method(self):
"
"Merge pull request #9705 from SuperFluffy/fix_expm_wrong_coefficients

Fix coefficients in expm helper function",4a497ccf7c5da98e64964cb96bc1108045d2a925,"diff --git a/scipy/sparse/linalg/matfuncs.py b/scipy/sparse/linalg/matfuncs.py
index dfb0d43805b6..1079166fa601 100644
--- a/scipy/sparse/linalg/matfuncs.py
+++ b/scipy/sparse/linalg/matfuncs.py
@@ -844,19 +844,17 @@ def _ell(A, m):
     if len(A.shape) != 2 or A.shape[0] != A.shape[1]:
         raise ValueError('expected A to be like a square matrix')
 
-    p = 2*m + 1
-
     # The c_i are explained in (2.2) and (2.6) of the 2005 expm paper.
     # They are coefficients of terms of a generating function series expansion.
-    choose_2p_p = scipy.special.comb(2*p, p, exact=True)
-    abs_c_recip = float(choose_2p_p * math.factorial(2*p + 1))
+    choose_2m_m = scipy.special.comb(2*m, m, exact=True)
+    abs_c_recip = float(choose_2m_m * math.factorial(2*m + 1))
 
     # This is explained after Eq. (1.2) of the 2009 expm paper.
     # It is the ""unit roundoff"" of IEEE double precision arithmetic.
     u = 2**-53
 
     # Compute the one-norm of matrix power p of abs(A).
-    A_abs_onenorm = _onenorm_matrix_power_nnm(abs(A), p)
+    A_abs_onenorm = _onenorm_matrix_power_nnm(abs(A), 2*m + 1)
 
     # Treat zero norm as a special case.
     if not A_abs_onenorm:
"
"Merge pull request #9559 from rgommers/globalopt-tutorial

DOC: add section on global optimizers to tutorial",533f1bbf4793b3e665bd750a82786f954b88f816,"diff --git a/doc/source/tutorial/examples/optimize_global_1.py b/doc/source/tutorial/examples/optimize_global_1.py
new file mode 100644
index 000000000000..190f51d93a02
--- /dev/null
+++ b/doc/source/tutorial/examples/optimize_global_1.py
@@ -0,0 +1,53 @@
+import numpy as np
+import matplotlib.pyplot as plt
+from scipy import optimize
+
+
+def eggholder(x):
+    return (-(x[1] + 47) * np.sin(np.sqrt(abs(x[0]/2 + (x[1]  + 47))))
+            -x[0] * np.sin(np.sqrt(abs(x[0] - (x[1]  + 47)))))
+
+bounds = [(-512, 512), (-512, 512)]
+
+x = np.arange(-512, 513)
+y = np.arange(-512, 513)
+xgrid, ygrid = np.meshgrid(x, y)
+xy = np.stack([xgrid, ygrid])
+
+results = dict()
+results['shgo'] = optimize.shgo(eggholder, bounds)
+results['DA'] = optimize.dual_annealing(eggholder, bounds)
+results['DE'] = optimize.differential_evolution(eggholder, bounds)
+results['BH'] = optimize.basinhopping(eggholder, bounds)
+results['shgo_sobol'] = optimize.shgo(eggholder, bounds, n=200, iters=5,
+                                      sampling_method='sobol')
+
+fig = plt.figure(figsize=(4.5, 4.5))
+ax = fig.add_subplot(111)
+im = ax.imshow(eggholder(xy), interpolation='bilinear', origin='lower',
+               cmap='gray')
+ax.set_xlabel('x')
+ax.set_ylabel('y')
+
+def plot_point(res, marker='o', color=None):
+    ax.plot(512+res.x[0], 512+res.x[1], marker=marker, color=color, ms=10)
+
+plot_point(results['BH'], color='y')  # basinhopping           - yellow
+plot_point(results['DE'], color='c')  # differential_evolution - cyan
+plot_point(results['DA'], color='w')  # dual_annealing.        - white
+
+# SHGO produces multiple minima, plot them all (with a smaller marker size)
+plot_point(results['shgo'], color='r', marker='+')
+plot_point(results['shgo_sobol'], color='r', marker='x')
+for i in range(results['shgo_sobol'].xl.shape[0]):
+    ax.plot(512 + results['shgo_sobol'].xl[i, 0],
+            512 + results['shgo_sobol'].xl[i, 1],
+            'ro', ms=2)
+
+ax.set_xlim([-4, 514*2])
+ax.set_ylim([-4, 514*2])
+
+fig.tight_layout()
+plt.show()
+
+
diff --git a/doc/source/tutorial/examples/optimize_global_2.py b/doc/source/tutorial/examples/optimize_global_2.py
new file mode 100644
index 000000000000..1f09194d9a79
--- /dev/null
+++ b/doc/source/tutorial/examples/optimize_global_2.py
@@ -0,0 +1,25 @@
+import numpy as np
+import matplotlib.pyplot as plt
+from mpl_toolkits.mplot3d import Axes3D
+
+def eggholder(x):
+    return (-(x[1] + 47) * np.sin(np.sqrt(abs(x[0]/2 + (x[1]  + 47))))
+            -x[0] * np.sin(np.sqrt(abs(x[0] - (x[1]  + 47)))))
+
+bounds = [(-512, 512), (-512, 512)]
+
+x = np.arange(-512, 513)
+y = np.arange(-512, 513)
+xgrid, ygrid = np.meshgrid(x, y)
+xy = np.stack([xgrid, ygrid])
+
+fig = plt.figure(figsize=(6, 4))
+ax = fig.add_subplot(111, projection='3d')
+ax.view_init(45, -45)
+ax.plot_surface(xgrid, ygrid, eggholder(xy), cmap='terrain')
+ax.set_xlabel('x')
+ax.set_ylabel('y')
+ax.set_zlabel('eggholder(x, y)')
+
+fig.tight_layout()
+plt.show()
diff --git a/doc/source/tutorial/optimize.rst b/doc/source/tutorial/optimize.rst
index 35f9ac26cd61..d1f08c176c93 100644
--- a/doc/source/tutorial/optimize.rst
+++ b/doc/source/tutorial/optimize.rst
@@ -19,7 +19,8 @@ The module contains:
    functions (:func:`minimize`) using a variety of algorithms (e.g. BFGS,
    Nelder-Mead simplex, Newton Conjugate Gradient, COBYLA or SLSQP)
 
-2. Global (brute-force) optimization routines  (e.g. :func:`basinhopping`, :func:`differential_evolution`)
+2. Global optimization routines  (e.g. :func:`basinhopping`,
+   :func:`differential_evolution`, :func:`shgo`, :func:`dual_annealing`).
 
 3. Least-squares minimization (:func:`least_squares`) and curve fitting
    (:func:`curve_fit`) algorithms
@@ -702,6 +703,121 @@ And the optimization problem is solved with:
 Most of the options available for the method ``'trust-constr'`` are not available
 for ``'SLSQP'``.
 
+Global optimization
+-------------------
+
+Global optimization aims to find the global minimum of a function within given
+bounds, in the presence of potentially many local minima. Typically global
+minimizers efficiently search the parameter space, while using a local
+minimizer (e.g. :func:`minimize`) under the hood.  SciPy contains a
+number of good global optimizers.  Here we'll use those on the same objective
+function, namely the (aptly named) ``eggholder`` function::
+
+   >>> def eggholder(x):
+   ...     return (-(x[1] + 47) * np.sin(np.sqrt(abs(x[0]/2 + (x[1]  + 47))))
+   ...             -x[0] * np.sin(np.sqrt(abs(x[0] - (x[1]  + 47)))))
+
+   >>> bounds = [(-512, 512), (-512, 512)]
+
+This function looks like an egg carton::
+
+   >>> import matplotlib.pyplot as plt
+   >>> from mpl_toolkits.mplot3d import Axes3D
+
+   >>> x = np.arange(-512, 513)
+   >>> y = np.arange(-512, 513)
+   >>> xgrid, ygrid = np.meshgrid(x, y)
+   >>> xy = np.stack([xgrid, ygrid])
+
+   >>> fig = plt.figure()
+   >>> ax = fig.add_subplot(111, projection='3d')
+   >>> ax.view_init(45, -45)
+   >>> ax.plot_surface(xgrid, ygrid, eggholder(xy), cmap='terrain')
+   >>> ax.set_xlabel('x')
+   >>> ax.set_ylabel('y')
+   >>> ax.set_zlabel('eggholder(x, y)')
+   >>> plt.show()
+
+.. plot:: tutorial/examples/optimize_global_2.py
+   :align: center
+   :include-source: 0
+
+We now use the global optimizers to obtain the minimum and the function value
+at the minimum. We'll store the results in a dictionary so we can compare
+different optimization results later.
+
+   >>> from scipy import optimize
+   >>> results = dict()
+   >>> results['shgo'] = optimize.shgo(eggholder, bounds)
+   >>> results['shgo']
+        fun: -935.3379515604197  # may vary
+       funl: array([-935.33795156])
+    message: 'Optimization terminated successfully.'
+       nfev: 42
+        nit: 2
+      nlfev: 37
+      nlhev: 0
+      nljev: 9
+    success: True
+          x: array([439.48096952, 453.97740589])
+         xl: array([[439.48096952, 453.97740589]])
+
+   >>> results['DA'] = optimize.dual_annealing(eggholder, bounds)
+   >>> results['DA']
+        fun: -956.9182316237413  # may vary
+    message: ['Maximum number of iteration reached']
+       nfev: 4091
+       nhev: 0
+        nit: 1000
+       njev: 0
+          x: array([482.35324114, 432.87892901])
+
+All optimizers return an ``OptimizeResult``, which in addition to the solution
+contains information on the number of function evaluations, whether the
+optimization was successful, and more.  For brevity we won't show the full
+output of the other optimizers::
+
+   >>> results['DE'] = optimize.differential_evolution(eggholder, bounds)
+   >>> results['BH'] = optimize.basinhopping(eggholder, bounds)
+
+:func:`shgo` has a second method, which returns all local minima rather than
+only what it thinks is the global minimum::
+
+   >>> results['shgo_sobol'] = optimize.shgo(eggholder, bounds, n=200, iters=5,
+   ...                                       sampling_method='sobol')
+
+We'll now plot all found minima on a heatmap of the function::
+
+   >>> fig = plt.figure()
+   >>> ax = fig.add_subplot(111)
+   >>> im = ax.imshow(eggholder(xy), interpolation='bilinear', origin='lower',
+   ...                cmap='gray')
+   >>> ax.set_xlabel('x')
+   >>> ax.set_ylabel('y')
+   >>>
+   >>> def plot_point(res, marker='o', color=None):
+   ...     ax.plot(512+res.x[0], 512+res.x[1], marker=marker, color=color, ms=10)
+
+   >>> plot_point(results['BH'], color='y')  # basinhopping           - yellow
+   >>> plot_point(results['DE'], color='c')  # differential_evolution - cyan
+   >>> plot_point(results['DA'], color='w')  # dual_annealing.        - white
+
+   >>> # SHGO produces multiple minima, plot them all (with a smaller marker size)
+   >>> plot_point(results['shgo'], color='r', marker='+')
+   >>> plot_point(results['shgo_sobol'], color='r', marker='x')
+   >>> for i in range(results['shgo_sobol'].xl.shape[0]):
+   ...     ax.plot(512 + results['shgo_sobol'].xl[i, 0],
+   ...             512 + results['shgo_sobol'].xl[i, 1],
+   ...             'ro', ms=2)
+
+   >>> ax.set_xlim([-4, 514*2])
+   >>> ax.set_ylim([-4, 514*2])
+   >>> plt.show()
+
+.. plot:: tutorial/examples/optimize_global_1.py
+   :align: center
+   :include-source: 0
+
 Least-squares minimization (:func:`least_squares`)
 --------------------------------------------------
 
"
"Merge pull request #9990 from andyfaff/constr

ENH: constraint violation",fd3d85f641ddec1a69993cdac13c03b9873f9341,"diff --git a/scipy/optimize/_constraints.py b/scipy/optimize/_constraints.py
index 50dc24b5632e..f1f3de9c00f8 100644
--- a/scipy/optimize/_constraints.py
+++ b/scipy/optimize/_constraints.py
@@ -6,6 +6,7 @@
     VectorFunction, LinearVectorFunction, IdentityVectorFunction)
 from .optimize import OptimizeWarning
 from warnings import warn
+from scipy._lib._numpy_compat import suppress_warnings
 from scipy.sparse import issparse
 
 class NonlinearConstraint(object):
@@ -249,6 +250,29 @@ def __init__(self, constraint, x0, sparse_jacobian=None,
         self.bounds = (lb, ub)
         self.keep_feasible = keep_feasible
 
+    def violation(self, x):
+        """"""How much the constraint is exceeded by.
+
+        Parameters
+        ----------
+        x : array-like
+            Vector of independent variables
+
+        Returns
+        -------
+        excess : array-like
+            How much the constraint is exceeded by, for each of the
+            constraints specified by `PreparedConstraint.fun`.
+        """"""
+        with suppress_warnings() as sup:
+            sup.filter(UserWarning)
+            ev = self.fun.fun(np.asarray(x))
+
+        excess_lb = np.maximum(self.bounds[0] - ev, 0)
+        excess_ub = np.maximum(ev - self.bounds[1], 0)
+
+        return excess_lb + excess_ub
+
 
 def new_bounds_to_old(lb, ub, n):
     """"""Convert the new bounds representation to the old one.
diff --git a/scipy/optimize/tests/test_constraints.py b/scipy/optimize/tests/test_constraints.py
index 4c52faa5c8e7..064419eaacd4 100644
--- a/scipy/optimize/tests/test_constraints.py
+++ b/scipy/optimize/tests/test_constraints.py
@@ -76,12 +76,21 @@ def test_prepare_constraint_infeasible_x0():
     bounds = Bounds(lb, ub, enforce_feasibility)
     pytest.raises(ValueError, PreparedConstraint, bounds, x0)
 
+    pc = PreparedConstraint(Bounds(lb, ub), [1, 2, 3])
+    assert (pc.violation([1, 2, 3]) > 0).any()
+    assert (pc.violation([0.25, 21, 31]) == 0).all()
+
     x0 = np.array([1, 2, 3, 4])
     A = np.array([[1, 2, 3, 4], [5, 0, 0, 6], [7, 0, 8, 0]])
     enforce_feasibility = np.array([True, True, True], dtype=bool)
     linear = LinearConstraint(A, -np.inf, 0, enforce_feasibility)
     pytest.raises(ValueError, PreparedConstraint, linear, x0)
 
+    pc = PreparedConstraint(LinearConstraint(A, -np.inf, 0),
+                            [1, 2, 3, 4])
+    assert (pc.violation([1, 2, 3, 4]) > 0).any()
+    assert (pc.violation([-10, 2, -10, 4]) == 0).all()
+
     def fun(x):
         return A.dot(x)
 
@@ -95,6 +104,28 @@ def hess(x, v):
                                     enforce_feasibility)
     pytest.raises(ValueError, PreparedConstraint, nonlinear, x0)
 
+    pc = PreparedConstraint(nonlinear, [-10, 2, -10, 4])
+    assert (pc.violation([1, 2, 3, 4]) > 0).any()
+    assert (pc.violation([-10, 2, -10, 4]) == 0).all()
+
+
+def test_violation():
+    def cons_f(x):
+        return np.array([x[0] ** 2 + x[1], x[0] ** 2 - x[1]])
+
+    nlc = NonlinearConstraint(cons_f, [-1, -0.8500], [2, 2])
+    pc = PreparedConstraint(nlc, [0.5, 1])
+
+    assert_array_equal(pc.violation([0.5, 1]), [0., 0.])
+
+    np.testing.assert_almost_equal(pc.violation([0.5, 1.2]), [0., 0.1])
+
+    np.testing.assert_almost_equal(pc.violation([1.2, 1.2]), [0.64, 0])
+
+    np.testing.assert_almost_equal(pc.violation([0.1, -1.2]), [0.19, 0])
+
+    np.testing.assert_almost_equal(pc.violation([0.1, 2]), [0.01, 1.14])
+
 
 def test_new_bounds_to_old():
     lb = np.array([-np.inf, 2, 3])
"
ENH: optimize: minor cleanup,2db186de4bd7822ced82477068e5d05aa46edf44,"diff --git a/scipy/optimize/_linprog_ip.py b/scipy/optimize/_linprog_ip.py
index 1b782a53b54e..28abf2edc0a4 100644
--- a/scipy/optimize/_linprog_ip.py
+++ b/scipy/optimize/_linprog_ip.py
@@ -26,15 +26,14 @@
 from scipy.linalg import LinAlgError
 from .optimize import OptimizeWarning, OptimizeResult, _check_unknown_options
 from ._linprog_util import _postsolve
+has_umfpack = True
+has_cholmod = True
 try:
     from sksparse.cholmod import cholesky as cholmod
-    has_cholmod = True
 except ImportError:
     has_cholmod = False
-has_umfpack = False
 try:
-    import scikits.umfpack as umfpack  # test whether to use factorized
-    has_umfpack = True
+    import scikits.umfpack  # test whether to use factorized
 except ImportError:
     has_umfpack = False
 
@@ -191,8 +190,6 @@ def _get_delta(
            2000. 197-232.
 
     """"""
-    global has_umfpack
-
     if A.shape[0] == 0:
         # If there are no constraints, some solvers fail (understandably)
         # rather than returning empty solution. This gets the job done.
@@ -1094,8 +1091,8 @@ def _linprog_ip(
         cholesky = False
 
     if sparse and lstsq:
-        warn(""Invalid option combination 'sparse':True ""
-             ""and 'lstsq':True; Sparse least squares is not recommended."",
+        warn(""Option combination 'sparse':True and 'lstsq':True ""
+             ""is not recommended."",
              OptimizeWarning, stacklevel=3)
 
     if lstsq and cholesky:
"
ENH: optimize: revert doc makefile change,d4f2b1913bb8e9062d21d8daa19529dbb5acf099,"diff --git a/doc/Makefile b/doc/Makefile
index 2228e3636665..08bf7f997a4c 100644
--- a/doc/Makefile
+++ b/doc/Makefile
@@ -1,7 +1,7 @@
 # Makefile for Sphinx documentation
 #
 
-PYVER ?= 3.7
+PYVER ?= 3.6
 PYTHON = python$(PYVER)
 
 # You can set these variables from the command line.
"
ENH: optimize: allow keyboard interrupt in get_solver,b7a6ba65734c113c2c7c5c35d38bd49c28c6be75,"diff --git a/scipy/optimize/_linprog_ip.py b/scipy/optimize/_linprog_ip.py
index 8023c2ae493e..1b782a53b54e 100644
--- a/scipy/optimize/_linprog_ip.py
+++ b/scipy/optimize/_linprog_ip.py
@@ -101,6 +101,8 @@ def solve(r, sym_pos=sym_pos):
     # what all of them are. It doesn't really matter: if the matrix can't be
     # factorized, return None. get_solver will be called again with different
     # inputs, and a new routine will try to factorize the matrix.
+    except KeyboardInterrupt:
+        raise
     except Exception:
         return None
     return solve
"
ENH: optimize: fixed enumerated list reST,ac363aebd994525d1ae42dd834def914a3d35464,"diff --git a/doc/Makefile b/doc/Makefile
index 08bf7f997a4c..2228e3636665 100644
--- a/doc/Makefile
+++ b/doc/Makefile
@@ -1,7 +1,7 @@
 # Makefile for Sphinx documentation
 #
 
-PYVER ?= 3.6
+PYVER ?= 3.7
 PYTHON = python$(PYVER)
 
 # You can set these variables from the command line.
diff --git a/scipy/optimize/_linprog_ip.py b/scipy/optimize/_linprog_ip.py
index 98c2a1e80716..8023c2ae493e 100644
--- a/scipy/optimize/_linprog_ip.py
+++ b/scipy/optimize/_linprog_ip.py
@@ -261,8 +261,8 @@ def _get_delta(
         # For sparse systems, the order is:
         # 1. sksparse.cholmod.cholesky (if available)
         # 2. scipy.sparse.linalg.factorized (if umfpack available)
-        #    scipy.sparse.linalg.splu (otherwise)
-        # 3. scipy.sparse.linalg.lsqr
+        # 3. scipy.sparse.linalg.splu
+        # 4. scipy.sparse.linalg.lsqr
         solved = False
         while(not solved):
             try:
@@ -982,15 +982,21 @@ def _linprog_ip(
     For dense problems, solvers are tried in the following order:
 
     1. ``scipy.linalg.cho_factor`` (if scikit-sparse and SuiteSparse are installed)
+    
     2. ``scipy.linalg.solve`` with option ``sym_pos=True``
+    
     3. ``scipy.linalg.solve`` with option ``sym_pos=False``
+    
     4. ``scipy.linalg.lstsq``
 
-    For sparse problems::
+    For sparse problems:
 
     1. ``sksparse.cholmod.cholesky`` (if scikit-sparse and SuiteSparse are installed)
+    
     2. ``scipy.sparse.linalg.factorized`` (if scikits.umfpack and SuiteSparse are installed)
+    
     3. ``scipy.sparse.linalg.splu`` (which uses SuperLU distributed with SciPy)
+    
     4. ``scipy.sparse.linalg.lsqr``
 
     If the solver fails for any reason, successively more robust (but slower)
"
ENH: optimize: updated documentation,2f0e22bfe850f87119a89fa81dbb4d169c409f11,"diff --git a/scipy/optimize/_linprog_ip.py b/scipy/optimize/_linprog_ip.py
index f67564eaa5f4..98c2a1e80716 100644
--- a/scipy/optimize/_linprog_ip.py
+++ b/scipy/optimize/_linprog_ip.py
@@ -287,8 +287,6 @@ def _get_delta(
                         ""approached. However, if you see this frequently, ""
                         ""consider setting option 'cholesky' to False."",
                         OptimizeWarning, stacklevel=5)
-                elif has_umfpack:
-                    has_umfpack = False
                 elif sym_pos:
                     sym_pos = False
                     warn(
@@ -951,7 +949,7 @@ def _linprog_ip(
     Notes
     -----
     This method implements the algorithm outlined in [4]_ with ideas from [8]_
-    and a structure inspired by the simpler methods of [6]_ and [4]_.
+    and a structure inspired by the simpler methods of [6]_.
 
     The primal-dual path following method begins with initial 'guesses' of
     the primal and dual variables of the standard form problem and iteratively
@@ -981,19 +979,19 @@ def _linprog_ip(
     With default options, the solver used to perform the factorization depends
     on third-party software availability and the conditioning of the problem.
 
-    For dense problems, solvers are tried in the following order.::
+    For dense problems, solvers are tried in the following order:
 
-        1: ``scipy.linalg.cho_factor`` (if scikit-sparse and SuiteSparse are installed)
-        2: ``scipy.linalg.solve`` with option ``sym_pos=True``
-        3: ``scipy.linalg.solve`` with option ``sym_pos=False``
-        4: ``scipy.linalg.lstsq``
+    1. ``scipy.linalg.cho_factor`` (if scikit-sparse and SuiteSparse are installed)
+    2. ``scipy.linalg.solve`` with option ``sym_pos=True``
+    3. ``scipy.linalg.solve`` with option ``sym_pos=False``
+    4. ``scipy.linalg.lstsq``
 
     For sparse problems::
 
-        1: ``sksparse.cholmod.cholesky`` (if scikit-sparse and SuiteSparse are installed)
-        2: ``scipy.sparse.linalg.factorized`` (if scikits.umfpack and SuiteSparse are installed)
-        3: ``scipy.sparse.linalg.splu`` (which uses SuperLU distributed with SciPy)
-        4: ``scipy.sparse.linalg.lsqr``
+    1. ``sksparse.cholmod.cholesky`` (if scikit-sparse and SuiteSparse are installed)
+    2. ``scipy.sparse.linalg.factorized`` (if scikits.umfpack and SuiteSparse are installed)
+    3. ``scipy.sparse.linalg.splu`` (which uses SuperLU distributed with SciPy)
+    4. ``scipy.sparse.linalg.lsqr``
 
     If the solver fails for any reason, successively more robust (but slower)
     solvers are attempted in the order indicated. Attempting, failing, and
"
"Merge pull request #9915 from rainwoodman/ckdtree-query-r-array

cKDTree query_ball_point improvements",f992ba979227044fbd11da648d339c8026de91a1,"diff --git a/scipy/spatial/ckdtree.pyx b/scipy/spatial/ckdtree.pyx
index 3f5cfebd8b07..93d83fb59eee 100644
--- a/scipy/spatial/ckdtree.pyx
+++ b/scipy/spatial/ckdtree.pyx
@@ -13,42 +13,35 @@ import scipy.sparse
 
 cimport numpy as np
 from numpy.math cimport INFINITY
-    
+
 from cpython.mem cimport PyMem_Malloc, PyMem_Realloc, PyMem_Free
 from libc.string cimport memset, memcpy
+from libcpp.vector cimport vector
+from libcpp.algorithm cimport sort
 
 cimport cython
 
 from multiprocessing import cpu_count
 import threading
 
-cdef extern from ""limits.h"":
+cdef extern from ""<limits.h>"":
     long LONG_MAX
 
-cdef extern from ""ckdtree_methods.h"":
-    int number_of_processors
-    
-number_of_processors = cpu_count()
-
-from libcpp.vector cimport vector
-from libc cimport string
+cdef int number_of_processors = cpu_count()
 
 __all__ = ['cKDTree']
 
-    
-# Borrowed references
-# ===================
-
 cdef extern from *:
-    
-    struct ckdtree:
-        pass
-        
     int NPY_LIKELY(int)
     int NPY_UNLIKELY(int)
 
-       
+
+# C++ implementations
+# ===================
+
 cdef extern from ""ckdtree_decl.h"":
+    int ckdtree_isinf(np.float64_t x) nogil
+
     struct ckdtreenode:
         np.intp_t split_dim
         np.intp_t children
@@ -59,8 +52,96 @@ cdef extern from ""ckdtree_decl.h"":
         ckdtreenode *greater
         np.intp_t _less
         np.intp_t _greater
-    
-    
+
+    struct ckdtree:
+        vector[ckdtreenode]  *tree_buffer
+        ckdtreenode   *ctree
+        np.float64_t   *raw_data
+        np.intp_t      n
+        np.intp_t      m
+        np.intp_t      leafsize
+        np.float64_t   *raw_maxes
+        np.float64_t   *raw_mins
+        np.intp_t      *raw_indices
+        np.float64_t   *raw_boxsize_data
+        np.intp_t size
+
+    # External build and query methods in C++. Cython will
+    # release the GIL to avoid locking up the interpreter.
+
+    int build_ckdtree(ckdtree *self,
+                         np.intp_t start_idx,
+                         np.intp_t end_idx,
+                         np.float64_t *maxes,
+                         np.float64_t *mins,
+                         int _median,
+                         int _compact) nogil except +
+
+    int build_weights(ckdtree *self,
+                         np.float64_t *node_weights,
+                         np.float64_t *weights) nogil except +
+
+    int query_knn(const ckdtree *self,
+                     np.float64_t *dd,
+                     np.intp_t    *ii,
+                     const np.float64_t *xx,
+                     const np.intp_t    n,
+                     const np.intp_t    *k,
+                     const np.intp_t    nk,
+                     const np.intp_t    kmax,
+                     const np.float64_t eps,
+                     const np.float64_t p,
+                     const np.float64_t distance_upper_bound) nogil except +
+
+    int query_pairs(const ckdtree *self,
+                       const np.float64_t r,
+                       const np.float64_t p,
+                       const np.float64_t eps,
+                       vector[ordered_pair] *results) nogil except +
+
+    int count_neighbors_unweighted(const ckdtree *self,
+                           const ckdtree *other,
+                           np.intp_t     n_queries,
+                           np.float64_t  *real_r,
+                           np.intp_t     *results,
+                           const np.float64_t p,
+                           int cumulative) nogil except +
+
+    int count_neighbors_weighted(const ckdtree *self,
+                           const ckdtree *other,
+                           np.float64_t  *self_weights,
+                           np.float64_t  *other_weights,
+                           np.float64_t  *self_node_weights,
+                           np.float64_t  *other_node_weights,
+                           np.intp_t     n_queries,
+                           np.float64_t  *real_r,
+                           np.float64_t     *results,
+                           const np.float64_t p,
+                           int cumulative) nogil except +
+
+    int query_ball_point(const ckdtree *self,
+                            const np.float64_t *x,
+                            const np.float64_t *r,
+                            const np.float64_t p,
+                            const np.float64_t eps,
+                            const np.intp_t n_queries,
+                            vector[np.intp_t] **results,
+                            const int return_length) nogil except +
+
+    int query_ball_tree(const ckdtree *self,
+                           const ckdtree *other,
+                           const np.float64_t r,
+                           const np.float64_t p,
+                           const np.float64_t eps,
+                           vector[np.intp_t] **results) nogil except +
+
+    int sparse_distance_matrix(const ckdtree *self,
+                                  const ckdtree *other,
+                                  const np.float64_t p,
+                                  const np.float64_t max_distance,
+                                  vector[coo_entry] *results) nogil except +
+
+
 # C++ helper functions
 # ====================
 
@@ -77,48 +158,32 @@ cdef extern from ""ordered_pair.h"":
         np.intp_t i
         np.intp_t j
 
-def new_object(obj):
-    return obj.__new__(obj)
- 
-cdef extern from ""cpp_utils.h"": 
-    object pickle_tree_buffer(vector[ckdtreenode] *buf)    
-    object unpickle_tree_buffer(vector[ckdtreenode] *buf, object src)
-    ckdtreenode *tree_buffer_root(vector[ckdtreenode] *buf)
-    ordered_pair *ordered_pair_vector_buf(vector[ordered_pair] *buf)
-    coo_entry *coo_entry_vector_buf(vector[coo_entry] *buf)
-    void *tree_buffer_pointer(vector[ckdtreenode] *buf)
-    np.intp_t *npy_intp_vector_buf(vector[np.intp_t] *buf)
-    np.float64_t *npy_float64_vector_buf(vector[np.float64_t] *buf)
-    ctypedef void *intvector_ptr_t 
-
-
-
 # coo_entry wrapper
 # =================
 
 cdef class coo_entries:
 
-    cdef: 
+    cdef:
         readonly object __array_interface__
         vector[coo_entry] *buf
-        
-    def __cinit__(coo_entries self):    
+
+    def __cinit__(coo_entries self):
         self.buf = NULL
 
-    def __init__(coo_entries self):    
+    def __init__(coo_entries self):
         self.buf = new vector[coo_entry]()
-        
+
     def __dealloc__(coo_entries self):
         if self.buf != NULL:
             del self.buf
-            
+
     # The methods ndarray, dict, coo_matrix, and dok_matrix must only
     # be called after the buffer is filled with coo_entry data. This
     # is because std::vector can reallocate its internal buffer when
     # push_back is called.
-            
-    def ndarray(coo_entries self):    
-        cdef: 
+
+    def ndarray(coo_entries self):
+        cdef:
             coo_entry *pr
             np.uintp_t uintptr
             np.intp_t n
@@ -126,9 +191,9 @@ cdef class coo_entries:
         res_dtype = np.dtype(_dtype, align = True)
         n = <np.intp_t> self.buf.size()
         if NPY_LIKELY(n > 0):
-            pr = coo_entry_vector_buf(self.buf) 
+            pr = &self.buf.front()
             uintptr = <np.uintp_t> (<void*> pr)
-            dtype = np.dtype(np.uint8)               
+            dtype = np.dtype(np.uint8)
             self.__array_interface__ = dict(
                 data = (uintptr, False),
                 descr = dtype.descr,
@@ -136,11 +201,11 @@ cdef class coo_entries:
                 strides = (dtype.itemsize,),
                 typestr = dtype.str,
                 version = 3,
-            ) 
+            )
             return np.asarray(self).view(dtype=res_dtype)
         else:
             return np.empty(shape=(0,), dtype=res_dtype)
-        
+
     def dict(coo_entries self):
         cdef:
             np.intp_t i, j, k, n
@@ -149,59 +214,59 @@ cdef class coo_entries:
             dict res_dict
         n = <np.intp_t> self.buf.size()
         if NPY_LIKELY(n > 0):
-            pr = coo_entry_vector_buf(self.buf)        
-            res_dict = dict()           
-            for k in range(n):                    
+            pr = &self.buf.front()
+            res_dict = dict()
+            for k in range(n):
                 i = pr[k].i
                 j = pr[k].j
-                v = pr[k].v                    
+                v = pr[k].v
                 res_dict[(i,j)] = v
             return res_dict
         else:
             return {}
-    
+
     def coo_matrix(coo_entries self, m, n):
         res_arr = self.ndarray()
         return scipy.sparse.coo_matrix(
                        (res_arr['v'], (res_arr['i'], res_arr['j'])),
                                        shape=(m, n))
-        
+
     def dok_matrix(coo_entries self, m, n):
         return self.coo_matrix(m,n).todok()
-        
-        
+
+
 # ordered_pair wrapper
 # ====================
 
 cdef class ordered_pairs:
 
-    cdef: 
+    cdef:
         readonly object __array_interface__
         vector[ordered_pair] *buf
-        
+
     def __cinit__(ordered_pairs self):
         self.buf = NULL
 
     def __init__(ordered_pairs self):
         self.buf = new vector[ordered_pair]()
-        
+
     def __dealloc__(ordered_pairs self):
         if self.buf != NULL:
             del self.buf
-            
-    # The methods ndarray and set must only be called after the buffer 
+
+    # The methods ndarray and set must only be called after the buffer
     # is filled with ordered_pair data.
-    
+
     def ndarray(ordered_pairs self):
-        cdef: 
+        cdef:
             ordered_pair *pr
-            np.uintp_t uintptr 
-            np.intp_t n            
+            np.uintp_t uintptr
+            np.intp_t n
         n = <np.intp_t> self.buf.size()
         if NPY_LIKELY(n > 0):
-            pr = ordered_pair_vector_buf(self.buf) 
-            uintptr = <np.uintp_t> (<void*> pr)       
-            dtype = np.dtype(np.intp)               
+            pr = &self.buf.front()
+            uintptr = <np.uintp_t> (<void*> pr)
+            dtype = np.dtype(np.intp)
             self.__array_interface__ = dict(
                 data = (uintptr, False),
                 descr = dtype.descr,
@@ -213,29 +278,29 @@ cdef class ordered_pairs:
             return np.asarray(self)
         else:
             return np.empty(shape=(0,2), dtype=np.intp)
-        
-    def set(ordered_pairs self):        
-        cdef: 
+
+    def set(ordered_pairs self):
+        cdef:
             ordered_pair *pair
             np.intp_t i, n
             set results
         results = set()
-        pair = ordered_pair_vector_buf(self.buf)
+        pair = &self.buf.front()
         n = <np.intp_t> self.buf.size()
         if sizeof(long) < sizeof(np.intp_t):
             # Needed for Python 2.x on Win64
             for i in range(n):
                 results.add((int(pair.i), int(pair.j)))
-                pair += 1 
+                pair += 1
         else:
             # other platforms
             for i in range(n):
                 results.add((pair.i, pair.j))
                 pair += 1
         return results
-    
-        
-            
+
+
+
 # Tree structure exposed to Python
 # ================================
 
@@ -244,20 +309,20 @@ cdef class cKDTreeNode:
     class cKDTreeNode
 
     This class exposes a Python view of a node in the cKDTree object.
-    
+
     All attributes are read-only.
-    
+
     Attributes
     ----------
     level : int
         The depth of the node. 0 is the level of the root node.
     split_dim : int
-        The dimension along which this node is split. If this value is -1  
+        The dimension along which this node is split. If this value is -1
         the node is a leafnode in the kd-tree. Leafnodes are not split further
         and scanned by brute force.
     split : float
         The value used to separate split this node. Points with value >= split
-        in the split_dim dimension are sorted to the 'greater' subnode 
+        in the split_dim dimension are sorted to the 'greater' subnode
         whereas those with value < split are sorted to the 'lesser' subnode.
     children : int
         The number of data points sorted to this node.
@@ -283,16 +348,16 @@ cdef class cKDTreeNode:
         ckdtreenode           *_node
         np.ndarray            _data
         np.ndarray            _indices
-        
+
     cdef void _setup(cKDTreeNode self):
         self.split_dim = self._node.split_dim
         self.children = self._node.children
         self.split = self._node.split
-        
-    property data_points:   
+
+    property data_points:
         def __get__(cKDTreeNode self):
             return self._data[self.indices,:]
-                     
+
     property indices:
         def __get__(cKDTreeNode self):
             cdef np.intp_t i, start, stop
@@ -301,9 +366,9 @@ cdef class cKDTreeNode:
                 stop = self._node.end_idx
                 return self._indices[start:stop]
             else:
-                return np.hstack([self.lesser.indices, 
+                return np.hstack([self.lesser.indices,
                            self.greater.indices])
-                           
+
     property lesser:
         def __get__(cKDTreeNode self):
             if self.split_dim == -1:
@@ -316,7 +381,7 @@ cdef class cKDTreeNode:
                 n.level = self.level + 1
                 n._setup()
                 return n
-                
+
     property greater:
         def __get__(cKDTreeNode self):
             if self.split_dim == -1:
@@ -330,90 +395,11 @@ cdef class cKDTreeNode:
                 n._setup()
                 return n
 
-    
+
 # Main cKDTree class
 # ==================
 
-cdef extern from ""ckdtree_methods.h"":
-
-    # External build and query methods in C++. These will internally
-    # release the GIL to avoid locking up the interpreter.
-    
-    int ckdtree_isinf(np.float64_t x)
-    
-    object build_ckdtree(ckdtree *self, 
-                         np.intp_t start_idx, 
-                         np.intp_t end_idx,
-                         np.float64_t *maxes, 
-                         np.float64_t *mins, 
-                         int _median, 
-                         int _compact)
-
-    object build_weights(ckdtree *self, 
-                         np.float64_t *node_weights,
-                         np.float64_t *weights)
-       
-    object query_knn(const ckdtree *self, 
-                     np.float64_t *dd, 
-                     np.intp_t    *ii, 
-                     const np.float64_t *xx,
-                     const np.intp_t    n,
-                     const np.intp_t    *k, 
-                     const np.intp_t    nk, 
-                     const np.intp_t    kmax, 
-                     const np.float64_t eps, 
-                     const np.float64_t p, 
-                     const np.float64_t distance_upper_bound) 
-                     
-    object query_pairs(const ckdtree *self, 
-                       const np.float64_t r, 
-                       const np.float64_t p, 
-                       const np.float64_t eps,
-                       vector[ordered_pair] *results)
-
-    object count_neighbors_unweighted(const ckdtree *self,
-                           const ckdtree *other,
-                           np.intp_t     n_queries,
-                           np.float64_t  *real_r,
-                           np.intp_t     *results,
-                           const np.float64_t p,
-                           int cumulative)
-
-    object count_neighbors_weighted(const ckdtree *self,
-                           const ckdtree *other,
-                           np.float64_t  *self_weights,
-                           np.float64_t  *other_weights,
-                           np.float64_t  *self_node_weights,
-                           np.float64_t  *other_node_weights,
-                           np.intp_t     n_queries,
-                           np.float64_t  *real_r,
-                           np.float64_t     *results,
-                           const np.float64_t p,
-                           int cumulative)
-
-    object query_ball_point(const ckdtree *self,
-                            const np.float64_t *x,
-                            const np.float64_t r,
-                            const np.float64_t p,
-                            const np.float64_t eps,
-                            const np.intp_t n_queries,
-                            vector[np.intp_t] **results)
-
-    object query_ball_tree(const ckdtree *self,
-                           const ckdtree *other,
-                           const np.float64_t r,
-                           const np.float64_t p,
-                           const np.float64_t eps,
-                           vector[np.intp_t] **results)                     
-     
-    object sparse_distance_matrix(const ckdtree *self,
-                                  const ckdtree *other,
-                                  const np.float64_t p,
-                                  const np.float64_t max_distance,
-                                  vector[coo_entry] *results)                    
-                      
-                      
-cdef public class cKDTree [object ckdtree, type ckdtree_type]:
+cdef class cKDTree:
     """"""
     cKDTree(data, leafsize=16, compact_nodes=True, copy_data=False,
             balanced_tree=True, boxsize=None)
@@ -422,54 +408,54 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
     This class provides an index into a set of k-dimensional points
     which can be used to rapidly look up the nearest neighbors of any
-    point. 
+    point.
 
-    The algorithm used is described in Maneewongvatana and Mount 1999. 
+    The algorithm used is described in Maneewongvatana and Mount 1999.
     The general idea is that the kd-tree is a binary trie, each of whose
     nodes represents an axis-aligned hyperrectangle. Each node specifies
     an axis and splits the set of points based on whether their coordinate
-    along that axis is greater than or less than a particular value. 
+    along that axis is greater than or less than a particular value.
 
-    During construction, the axis and splitting point are chosen by the 
+    During construction, the axis and splitting point are chosen by the
     ""sliding midpoint"" rule, which ensures that the cells do not all
-    become long and thin. 
+    become long and thin.
 
-    The tree can be queried for the r closest neighbors of any given point 
-    (optionally returning only those within some maximum distance of the 
-    point). It can also be queried, with a substantial gain in efficiency, 
+    The tree can be queried for the r closest neighbors of any given point
+    (optionally returning only those within some maximum distance of the
+    point). It can also be queried, with a substantial gain in efficiency,
     for the r approximate closest neighbors.
 
-    For large dimensions (20 is already large) do not expect this to run 
+    For large dimensions (20 is already large) do not expect this to run
     significantly faster than brute force. High-dimensional nearest-neighbor
     queries are a substantial open problem in computer science.
 
     Parameters
     ----------
     data : array_like, shape (n,m)
-        The n data points of dimension m to be indexed. This array is 
-        not copied unless this is necessary to produce a contiguous 
-        array of doubles, and so modifying this data will result in 
+        The n data points of dimension m to be indexed. This array is
+        not copied unless this is necessary to produce a contiguous
+        array of doubles, and so modifying this data will result in
         bogus results. The data are also copied if the kd-tree is built
         with copy_data=True.
     leafsize : positive int, optional
         The number of points at which the algorithm switches over to
         brute-force. Default: 16.
-    compact_nodes : bool, optional    
+    compact_nodes : bool, optional
         If True, the kd-tree is built to shrink the hyperrectangles to
-        the actual data range. This usually gives a more compact tree that 
-        is robust against degenerated input data and gives faster queries 
+        the actual data range. This usually gives a more compact tree that
+        is robust against degenerated input data and gives faster queries
         at the expense of longer build time. Default: True.
     copy_data : bool, optional
-        If True the data is always copied to protect the kd-tree against 
+        If True the data is always copied to protect the kd-tree against
         data corruption. Default: False.
-    balanced_tree : bool, optional    
-        If True, the median is used to split the hyperrectangles instead of 
-        the midpoint. This usually gives a more compact tree and 
+    balanced_tree : bool, optional
+        If True, the median is used to split the hyperrectangles instead of
+        the midpoint. This usually gives a more compact tree and
         faster queries at the expense of longer build time. Default: True.
     boxsize : array_like or scalar, optional
-        Apply a m-d toroidal topology to the KDTree.. The topology is generated 
+        Apply a m-d toroidal topology to the KDTree.. The topology is generated
         by :math:`x_i + n_i L_i` where :math:`n_i` are integers and :math:`L_i`
-        is the boxsize along i-th dimension. The input data shall be wrapped 
+        is the boxsize along i-th dimension. The input data shall be wrapped
         into :math:`[0, L_i)`. A ValueError is raised if any of the data is
         outside of this bound.
 
@@ -502,54 +488,56 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
     """"""
     cdef:
-        vector[ckdtreenode]      *tree_buffer
-        ckdtreenode              *ctree 
-        readonly cKDTreeNode     tree 
+        ckdtree * cself
+        readonly cKDTreeNode     tree
         readonly np.ndarray      data
-        np.float64_t             *raw_data
-        readonly np.intp_t       n, m
-        readonly np.intp_t       leafsize
         readonly np.ndarray      maxes
-        np.float64_t             *raw_maxes
         readonly np.ndarray      mins
-        np.float64_t             *raw_mins
         readonly np.ndarray      indices
-        np.intp_t                *raw_indices
-        np.ndarray               _median_workspace
         readonly object          boxsize
         np.ndarray               boxsize_data
-        np.float64_t             *raw_boxsize_data
-        readonly np.intp_t       size
+
+    property n:
+        def __get__(self): return self.cself.n
+    property m:
+        def __get__(self): return self.cself.m
+    property leafsize:
+        def __get__(self): return self.cself.leafsize
+    property size:
+        def __get__(self): return self.cself.size
 
     def __cinit__(cKDTree self):
-        self.tree_buffer = NULL        
-            
-    def __init__(cKDTree self, data, np.intp_t leafsize=16, compact_nodes=True, 
+        self.cself = <ckdtree * > PyMem_Malloc(sizeof(ckdtree))
+        self.cself.tree_buffer = NULL
+
+    def __init__(cKDTree self, data, np.intp_t leafsize=16, compact_nodes=True,
             copy_data=False, balanced_tree=True, boxsize=None):
-        cdef np.ndarray[np.float64_t, ndim=2] data_arr
-        cdef np.float64_t *tmp
-        cdef int _median, _compact
-        cdef np.ndarray[np.float64_t, ndim=1] boxsize_arr
-        data_arr = np.ascontiguousarray(data, dtype=np.float64)
-        if copy_data and (data_arr is data):
-            data_arr = data_arr.copy()
-        self.data = data_arr
-        self.n = data_arr.shape[0]
-        self.m = data_arr.shape[1]
-        self.leafsize = leafsize
-        if self.leafsize<1:
+        cdef np.float64_t [::1] tmpmaxes, tmpmins
+        cdef ckdtree * cself = self.cself
+
+        data = np.array(data, order='C', copy=copy_data, dtype=np.float64)
+
+        if data.ndim != 2:
+            raise ValueError(""data must be 2 dimensions"")
+
+        self.data = data
+        cself.n = data.shape[0]
+        cself.m = data.shape[1]
+        cself.leafsize = leafsize
+
+        if leafsize<1:
             raise ValueError(""leafsize must be at least 1"")
 
         if boxsize is None:
             self.boxsize = None
             self.boxsize_data = None
         else:
-            boxsize_arr = np.empty(2 * self.m, dtype=np.float64)
-            boxsize_arr[:self.m] = boxsize
-            boxsize_arr[self.m:] = 0.5 * boxsize_arr[:self.m]
-            # FIXME: how to use a matching del if new is used?
-            self.boxsize_data = boxsize_arr
-            self.boxsize = boxsize_arr[:self.m].copy()
+            self.boxsize_data = np.empty(2 * self.m, dtype=np.float64)
+            boxsize = np.float64(np.broadcast_to(boxsize, self.m))
+            self.boxsize_data[:self.m] = boxsize
+            self.boxsize_data[self.m:] = 0.5 * boxsize
+
+            self.boxsize = boxsize
             periodic_mask = self.boxsize > 0
             if ((self.data >= self.boxsize[None, :])[:, periodic_mask]).any():
                 raise ValueError(""Some input data are greater than the size of the periodic box."")
@@ -562,61 +550,55 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
         self._pre_init()
 
-        _compact = 1 if compact_nodes else 0
-        _median = 1 if balanced_tree else 0
-        if _median:
-            self._median_workspace = np.zeros(self.n)
+        compact = 1 if compact_nodes else 0
+        median = 1 if balanced_tree else 0
 
-        self.tree_buffer = new vector[ckdtreenode]()
-        
-        try:
-            tmp = <np.float64_t*> PyMem_Malloc(self.m*2*sizeof(np.float64_t))
-            if tmp == NULL: raise MemoryError()            
-            memcpy(tmp, self.raw_maxes, self.m*sizeof(np.float64_t))
-            memcpy(tmp + self.m, self.raw_mins, self.m*sizeof(np.float64_t))
-            build_ckdtree(<ckdtree*> self, 0, self.n, tmp, tmp + self.m, 
-                _median, _compact)
-        finally:
-            PyMem_Free(tmp)
+        cself.tree_buffer = new vector[ckdtreenode]()
+
+        tmpmaxes = np.copy(self.maxes)
+        tmpmins = np.copy(self.mins)
+
+        build_ckdtree(cself, 0, cself.n, &tmpmaxes[0], &tmpmins[0], median, compact)
 
-        self._median_workspace = None
-        
         # set up the tree structure pointers
         self._post_init()
-        
-        # make the tree viewable from Python
-        self.tree = cKDTreeNode()
-        self.tree._node = self.ctree
-        self.tree._data = self.data
-        self.tree._indices = self.indices
-        self.tree.level = 0
-        self.tree._setup()
 
-    cdef int _pre_init(cKDTree self) except -1:
+    cdef _pre_init(cKDTree self):
+        cself = self.cself
 
         # finalize the pointers from array attributes
 
-        self.raw_data = <np.float64_t*> np.PyArray_DATA(self.data)
-        self.raw_maxes = <np.float64_t*> np.PyArray_DATA(self.maxes)
-        self.raw_mins = <np.float64_t*> np.PyArray_DATA(self.mins)
-        self.raw_indices = <np.intp_t*> np.PyArray_DATA(self.indices)
+        cself.raw_data = <np.float64_t*> np.PyArray_DATA(self.data)
+        cself.raw_maxes = <np.float64_t*> np.PyArray_DATA(self.maxes)
+        cself.raw_mins = <np.float64_t*> np.PyArray_DATA(self.mins)
+        cself.raw_indices = <np.intp_t*> np.PyArray_DATA(self.indices)
 
         if self.boxsize_data is not None:
-            self.raw_boxsize_data = <np.float64_t*>np.PyArray_DATA(self.boxsize_data)
-
-        return 0        
+            cself.raw_boxsize_data = <np.float64_t*>np.PyArray_DATA(self.boxsize_data)
+        else:
+            cself.raw_boxsize_data = NULL
 
-    cdef int _post_init(cKDTree self) except -1:
+    cdef _post_init(cKDTree self):
+        cself = self.cself
         # finalize the tree points, this calls _post_init_traverse
-        
-        self.ctree = tree_buffer_root(self.tree_buffer)
+
+        cself.ctree = &cself.tree_buffer.front()
 
         # set the size attribute after tree_buffer is built
-        self.size = self.tree_buffer.size()
+        cself.size = cself.tree_buffer.size()
 
-        return self._post_init_traverse(self.ctree)
-         
-    cdef int _post_init_traverse(cKDTree self, ckdtreenode *node) except -1:
+        self._post_init_traverse(cself.ctree)
+
+        # make the tree viewable from Python
+        self.tree = cKDTreeNode()
+        self.tree._node = cself.ctree
+        self.tree._data = self.data
+        self.tree._indices = self.indices
+        self.tree.level = 0
+        self.tree._setup()
+
+    cdef _post_init_traverse(cKDTree self, ckdtreenode *node):
+        cself = self.cself
         # recurse the tree and re-initialize
         # ""less"" and ""greater"" fields
         if node.split_dim == -1:
@@ -624,22 +606,21 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             node.less = NULL
             node.greater = NULL
         else:
-            node.less = self.ctree + node._less
-            node.greater = self.ctree + node._greater
+            node.less = cself.ctree + node._less
+            node.greater = cself.ctree + node._greater
             self._post_init_traverse(node.less)
             self._post_init_traverse(node.greater)
-                
-        return 0
-        
 
     def __dealloc__(cKDTree self):
-        if self.tree_buffer != NULL:
-            del self.tree_buffer
+        cself = self.cself
+        if cself.tree_buffer != NULL:
+            del cself.tree_buffer
+        PyMem_Free(cself)
 
     # -----
     # query
     # -----
-    
+
     @cython.boundscheck(False)
     def query(cKDTree self, object x, object k=1, np.float64_t eps=0,
               np.float64_t p=2, np.float64_t distance_upper_bound=INFINITY,
@@ -654,15 +635,15 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         x : array_like, last dimension self.m
             An array of points to query.
         k : list of integer or integer
-            The list of k-th nearest neighbors to return. If k is an 
+            The list of k-th nearest neighbors to return. If k is an
             integer it is treated as a list of [1, ... k] (range(1, k+1)).
             Note that the counting starts from 1.
         eps : non-negative float
-            Return approximate nearest neighbors; the k-th returned value 
-            is guaranteed to be no further than (1+eps) times the 
+            Return approximate nearest neighbors; the k-th returned value
+            is guaranteed to be no further than (1+eps) times the
             distance to the real k-th nearest neighbor.
         p : float, 1<=p<=infinity
-            Which Minkowski p-norm to use. 
+            Which Minkowski p-norm to use.
             1 is the sum-of-absolute-values ""Manhattan"" distance
             2 is the usual Euclidean distance
             infinity is the maximum-coordinate-difference distance
@@ -675,11 +656,11 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         n_jobs : int, optional
             Number of jobs to schedule for parallel processing. If -1 is given
             all processors are used. Default: 1.
-                        
+
         Returns
         -------
         d : array of floats
-            The distances to the nearest neighbors. 
+            The distances to the nearest neighbors.
             If ``x`` has shape ``tuple+(self.m,)``, then ``d`` has shape ``tuple+(k,)``.
             When k == 1, the last dimension of the output is squeezed.
             Missing neighbors are indicated with infinite distances.
@@ -693,9 +674,9 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         -----
         If the KD-Tree is periodic, the position ``x`` is wrapped into the
         box.
-        
+
         When the input k is a list, a query for arange(max(k)) is performed, but
-        only columns that store the requested values of k are preserved. This is 
+        only columns that store the requested values of k are preserved. This is
         implemented in a manner that reduces memory usage.
 
         Examples
@@ -745,11 +726,11 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
          [13 12]]
 
         """"""
-        
+
         cdef:
             np.intp_t n, i, j
             int overflown
-        
+
         x_arr = np.asarray(x, dtype=np.float64)
         if x_arr.ndim == 0 or x_arr.shape[x_arr.ndim - 1] != self.m:
             raise ValueError(""x must consist of vectors of length %d but ""
@@ -767,55 +748,31 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             if k == 1:
                 nearest = True
             k = np.arange(1, k + 1)
-    
+
         retshape = np.shape(x)[:-1]
         n = <np.intp_t> np.prod(retshape)
-        xx = np.ascontiguousarray(x_arr).reshape(n, self.m)
+        cdef np.float64_t [:, ::1] xx = np.ascontiguousarray(x_arr).reshape(n, self.m)
 
         # The C++ function touches all dd and ii entries,
         # setting the missing values.
 
-        dd = np.empty((n,len(k)),dtype=np.float64)
-        ii = np.empty((n,len(k)),dtype=np.intp)
+        cdef np.float64_t [:, ::1] dd = np.empty((n,len(k)),dtype=np.float64)
+        cdef np.intp_t [:, ::1] ii = np.empty((n,len(k)),dtype=np.intp)
+        cdef np.intp_t [::1] kk = np.array(k, dtype=np.intp)
+
+        cdef np.intp_t kmax = np.max(k)
 
-        # Do the query in an external C++ function. 
+        # Do the query in an external C++ function.
         # The GIL will be released in the external query function.
-        def _thread_func(self, np.intp_t start, np.intp_t stop):
-            cdef: 
-                np.ndarray[np.intp_t,ndim=2] _ii = ii
-                np.ndarray[np.float64_t,ndim=2] _dd = dd
-                np.ndarray[np.float64_t,ndim=2] _xx = xx
-                np.ndarray[np.intp_t,ndim=1] _k = np.array(k, dtype=np.intp)
-            
-            kmax = np.max(k)
-
-            query_knn(<ckdtree*>self, &_dd[start,0], &_ii[start,0], 
-                &_xx[start,0], stop-start, &_k[0], len(k), kmax, eps, p, distance_upper_bound)
-        
-        if (n_jobs == -1): 
+        def _thread_func(np.intp_t start, np.intp_t stop):
+            query_knn(self.cself, &dd[start,0], &ii[start,0],
+                &xx[start,0], stop-start, &kk[0], kk.shape[0], kmax, eps, p, distance_upper_bound)
+
+        if (n_jobs == -1):
             n_jobs = number_of_processors
-        
-        if n_jobs > 1:
-            # static scheduling without load balancing is good enough
-                             
-            ranges = [(j * n // n_jobs, (j + 1) * n // n_jobs)
-                            for j in range(n_jobs)]
-            
-            # There might be n_jobs+1 threads spawned here, but only n_jobs of 
-            # them will do significant work.
-            threads = [threading.Thread(target=_thread_func,
-                                args=(self, start, stop)) for start, stop in ranges]
-
-            # Set the daemon flag so the process can be aborted, 
-            # start all threads and wait for completion.
-            for t in threads:
-                t.daemon = True
-                t.start()
-            for t in threads: 
-                t.join()
-        else:
-            _thread_func(self, 0, n)
-                
+
+        _run_threads(_thread_func, n, n_jobs)
+
         # massage the output in conformabity to the documented behavior
 
         if sizeof(long) < sizeof(np.intp_t):
@@ -827,7 +784,7 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                         # C long overlow, return array of dtype=np.int_p
                         overflown = True
                         break
-                if overflown: 
+                if overflown:
                     break
 
             if overflown:
@@ -835,8 +792,8 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                 iiret = np.reshape(ii,retshape+(len(k),))
             else:
                 ddret = np.reshape(dd,retshape+(len(k),))
-                iiret = np.reshape(ii,retshape+(len(k),)).astype(int) 
-                        
+                iiret = np.reshape(ii,retshape+(len(k),)).astype(int)
+
         else:
             # ... most other platforms
             ddret = np.reshape(dd,retshape+(len(k),))
@@ -849,27 +806,28 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             if single:
                 ddret = float(ddret)
                 iiret = int(iiret)
-            
+
         return ddret, iiret
 
     # ----------------
     # query_ball_point
     # ----------------
 
-    def query_ball_point(cKDTree self, object x, np.float64_t r,
+    def query_ball_point(cKDTree self, object x, object r,
                          np.float64_t p=2., np.float64_t eps=0, n_jobs=1,
-                         return_sorted=None):
+                         return_sorted=None,
+                         return_length=False):
         """"""
         query_ball_point(self, x, r, p=2., eps=0)
-        
+
         Find all points within distance r of point(s) x.
 
         Parameters
         ----------
         x : array_like, shape tuple + (self.m,)
             The point or points to search for neighbors of.
-        r : positive float
-            The radius of points to return.
+        r : array_like, float
+            The radius of points to return, shall broadcast to the length of x.
         p : float, optional
             Which Minkowski p-norm to use.  Should be in the range [1, inf].
             A finite large p may cause a ValueError if overflow can occur.
@@ -888,6 +846,10 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             was added.
 
             .. versionadded:: 1.2.0
+        return_length: bool, optional
+            Return the number of points inside the radius instead of a list
+            of the indices.
+            .. versionadded:: 1.3.0
 
         Returns
         -------
@@ -912,138 +874,100 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         [4, 8, 9, 12]
 
         """"""
-        
+
         cdef:
-            np.ndarray[np.float64_t, ndim=1, mode=""c""] xx
-            np.ndarray[np.float64_t, ndim=2, mode=""c""] vxx
-            vector[np.intp_t] *vres
-            vector[np.intp_t] **vvres
-            np.uintp_t vvres_uintp
-            np.intp_t *cur
+            np.float64_t[::1] vrr
+            np.float64_t[:, ::1] vxx
+            object[::1] vout
+            np.intp_t[::1] vlen
             list tmp
             np.intp_t i, j, n, m
-        
-        vres = NULL
-        vvres = NULL
-        
-        try:
-               
-            x = np.asarray(x, dtype=np.float64)
-            if x.shape[-1] != self.m:
-                raise ValueError(""Searching for a %d-dimensional point in a ""
-                                 ""%d-dimensional KDTree"" % 
-                                     (int(x.shape[-1]), int(self.m)))
-            if len(x.shape) == 1:
-                vres = new vector[np.intp_t]()
-                xx = np.ascontiguousarray(x, dtype=np.float64)
-                query_ball_point(<ckdtree*> self, &xx[0], r, p, eps, 1, &vres)
-                n = <np.intp_t> vres.size()
-                tmp = n * [None]
-                if NPY_LIKELY(n > 0):
-                    cur = npy_intp_vector_buf(vres)
-                    for i in range(n):
-                        if return_sorted:
-                            tmp[i] = sorted(cur[0])
-                        else:
-                            tmp[i] = cur[0]
-                        cur += 1
-                result = tmp
-            
-            else:
-                retshape = x.shape[:-1]
-                
-                # allocate an array of std::vector<npy_intp>
-                n = np.prod(retshape)
-                vvres = (<vector[np.intp_t] **> 
-                    PyMem_Malloc(n * sizeof(intvector_ptr_t)))
+            np.intp_t xndim
+
+        x = np.asarray(x, dtype=np.float64)
+        if x.shape[-1] != self.m:
+            raise ValueError(""Searching for a %d-dimensional point in a ""
+                             ""%d-dimensional KDTree"" %
+                                 (int(x.shape[-1]), int(self.m)))
+
+        r = np.array(np.broadcast_to(r, x.shape[:-1]), order='C', dtype=np.float64)
+
+        retshape = x.shape[:-1]
+
+        # scalar query if xndim == 1
+        xndim = x.ndim
+
+        # allocate an array of std::vector<npy_intp>
+        n = np.prod(retshape)
+
+        if return_length:
+            result = np.empty(retshape, dtype=np.intp)
+            vlen = result.reshape(-1)
+        else:
+            result = np.empty(retshape, dtype=object)
+            vout = result.reshape(-1)
+
+        vxx = np.reshape(x, (-1, x.shape[-1]))
+        vrr = np.reshape(r, (-1))
+
+        def _thread_func(np.intp_t start, np.intp_t stop):
+            cdef vector[np.intp_t] **vvres
+            cdef np.intp_t i
+            cdef np.intp_t *cur
+            try:
+                vvres = (<vector[np.intp_t] **>
+                    PyMem_Malloc((stop-start) * sizeof(void*)))
                 if vvres == NULL:
                     raise MemoryError()
-                
-                memset(<void*> vvres, 0, n * sizeof(intvector_ptr_t))      
-            
-                for i in range(n):
+
+                memset(<void*> vvres, 0, (stop-start) * sizeof(void*))
+
+                for i in range(stop - start):
                     vvres[i] = new vector[np.intp_t]()
-                
-                result = np.empty(retshape, dtype=object)
-                
-                vxx = np.zeros((n,self.m), dtype=np.float64)
-                i = 0
-                for c in np.ndindex(retshape):
-                    vxx[i,:] = x[c]
-                    i += 1
-                    
-                # multithreading logic is similar to cKDTree.query
-                                        
-                if (n_jobs == -1): 
-                    n_jobs = number_of_processors
-        
-                if n_jobs > 1:
-                
-                    CHUNK = n//n_jobs if n//n_jobs else n
-                             
-                    def _thread_func(self, _j, _vxx, r, p, eps, _vvres, CHUNK): 
-                        cdef: 
-                            np.intp_t j = _j
-                            np.ndarray[np.float64_t,ndim=2] vxx = _vxx
-                            vector[np.intp_t] **vvres                   
-                            np.intp_t start = j*CHUNK
-                            np.intp_t stop = start + CHUNK
-                        stop = n if stop > n else stop
-                        vvres = (<vector[np.intp_t] **> 
-                                  (<void*> (<np.uintp_t> _vvres)))                                    
-                        if start < n:
-                            query_ball_point(<ckdtree*>self, &vxx[start,0], 
-                                r, p, eps, stop-start, vvres+start)
-                                
-                    vvres_uintp = <np.uintp_t> (<void*> vvres)
-                    threads = [threading.Thread(target=_thread_func,
-                               args=(self, j, vxx, r, p, eps,vvres_uintp,CHUNK))
-                                  for j in range(1+(n//CHUNK))]
-                    for t in threads:
-                        t.daemon = True
-                        t.start()
-                    for t in threads: 
-                        t.join()
-                                                                
-                else:
-                
-                    query_ball_point(<ckdtree*>self, &vxx[0,0], r, p, eps, 
-                        n, vvres)
-                
-                i = 0
-                for c in np.ndindex(retshape):
+
+                query_ball_point(self.cself, &vxx[start, 0],
+                    &vrr[start + 0], p, eps, stop - start, vvres, return_length)
+
+                for i in range(stop - start):
+                    if return_length:
+                        vlen[start + i] = vvres[i].front()
+                        continue
+
+                    if return_sorted:
+                        sort(vvres[i].begin(), vvres[i].end())
+                    elif return_sorted is None and xndim > 1:
+                        # compatibility with the old bug not sorting scalar queries.
+                        sort(vvres[i].begin(), vvres[i].end())
+
                     m = <np.intp_t> (vvres[i].size())
-                    if NPY_LIKELY(m > 0):
-                        tmp = m * [None]
-                        cur = npy_intp_vector_buf(vvres[i])
-                        for j in range(m):
-                            tmp[j] = cur[0]
-                            cur += 1
-                        if return_sorted or return_sorted is None:
-                            result[c] = sorted(tmp)
-                        else:
-                            result[c] = tmp
-                    else:
-                        result[c] = []
-                    i += 1
-        
-        finally:
-            if vres != NULL: 
-                del vres
-                
-            if vvres != NULL:
-                for i in range(n):
-                    if vvres[i] != NULL:
-                        del vvres[i]     
-                PyMem_Free(vvres)
-                
-        return result   
-            
+                    tmp = m * [None]
+
+                    cur = &vvres[i].front()
+                    for j in range(m):
+                        tmp[j] = cur[0]
+                        cur += 1
+                    vout[start + i] = tmp
+            finally:
+                if vvres != NULL:
+                    for i in range(stop-start):
+                        if vvres[i] != NULL:
+                            del vvres[i]
+                    PyMem_Free(vvres)
+
+        # multithreading logic is similar to cKDTree.query
+        if n_jobs == -1:
+            n_jobs = number_of_processors
+
+        _run_threads(_thread_func, n, n_jobs)
+
+        if xndim == 1: # scalar query, unpack result.
+            result = result[()]
+        return result
 
     # ---------------
     # query_ball_tree
     # ---------------
-    
+
     def query_ball_tree(cKDTree self, cKDTree other,
                         np.float64_t r, np.float64_t p=2., np.float64_t eps=0):
         """"""
@@ -1074,8 +998,8 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             list of the indices of its neighbors in ``other.data``.
 
         """"""
-        
-        cdef: 
+
+        cdef:
             vector[np.intp_t] **vvres
             np.intp_t i, j, n, m
             np.intp_t *cur
@@ -1086,46 +1010,46 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         if self.m != other.m:
             raise ValueError(""Trees passed to query_ball_tree have different ""
                              ""dimensionality"")
-     
+
         n = self.n
-        
+
         try:
-        
+
             # allocate an array of std::vector<npy_intp>
-            vvres = (<vector[np.intp_t] **> 
-                PyMem_Malloc(n * sizeof(intvector_ptr_t)))
+            vvres = (<vector[np.intp_t] **>
+                PyMem_Malloc(n * sizeof(void*)))
             if vvres == NULL:
                 raise MemoryError()
-                
-            memset(<void*> vvres, 0, n * sizeof(intvector_ptr_t))      
-            
+
+            memset(<void*> vvres, 0, n * sizeof(void*))
+
             for i in range(n):
                 vvres[i] = new vector[np.intp_t]()
-        
+
             # query in C++
             # the GIL will be released in the C++ code
-            query_ball_tree(
-                <ckdtree*> self, <ckdtree*> other, r, p, eps, vvres)
-                          
-            # store the results in a list of lists                                        
+            query_ball_tree(self.cself, other.cself, r, p, eps, vvres)
+
+            # store the results in a list of lists
             results = n * [None]
             for i in range(n):
                 m = <np.intp_t> (vvres[i].size())
                 if NPY_LIKELY(m > 0):
                     tmp = m * [None]
-                    cur = npy_intp_vector_buf(vvres[i]) 
+                    sort(vvres[i].begin(), vvres[i].end())
+                    cur = &vvres[i].front()
                     for j in range(m):
                         tmp[j] = cur[0]
                         cur += 1
-                    results[i] = sorted(tmp)
+                    results[i] = tmp
                 else:
-                    results[i] = []    
-                                  
+                    results[i] = []
+
         finally:
             if vvres != NULL:
                 for i in range(n):
                     if vvres[i] != NULL:
-                        del vvres[i]     
+                        del vvres[i]
                 PyMem_Free(vvres)
 
         return results
@@ -1133,7 +1057,7 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
     # -----------
     # query_pairs
     # -----------
-    
+
     def query_pairs(cKDTree self, np.float64_t r, np.float64_t p=2.,
                     np.float64_t eps=0, output_type='set'):
         """"""
@@ -1161,22 +1085,22 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         -------
         results : set or ndarray
             Set of pairs ``(i,j)``, with ``i < j``, for which the corresponding
-            positions are close. If output_type is 'ndarray', an ndarry is 
+            positions are close. If output_type is 'ndarray', an ndarry is
             returned instead of a set.
 
         """"""
-                 
+
         cdef ordered_pairs results
 
         results = ordered_pairs()
-        query_pairs(<ckdtree*> self, r, p, eps, results.buf)
-        
+        query_pairs(self.cself, r, p, eps, results.buf)
+
         if output_type == 'set':
             return results.set()
         elif output_type == 'ndarray':
             return results.ndarray()
         else:
-            raise ValueError(""Invalid output type"") 
+            raise ValueError(""Invalid output type"")
 
     def _build_weights(cKDTree self, object weights):
         """"""
@@ -1199,20 +1123,19 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
         """"""
         cdef np.intp_t num_of_nodes
-        cdef np.ndarray[np.float64_t, ndim=1, mode=""c""] node_weights
-        cdef np.ndarray[np.float64_t, ndim=1, mode=""c""] proper_weights
+        cdef np.float64_t [::1] node_weights
+        cdef np.float64_t [::1] proper_weights
 
-        num_of_nodes = self.tree_buffer.size();
+        num_of_nodes = self.cself.tree_buffer.size();
         node_weights = np.empty(num_of_nodes, dtype=np.float64)
 
-        # FIXME: use templates to avoid the type conversion 
+        # FIXME: use templates to avoid the type conversion
         proper_weights = np.ascontiguousarray(weights, dtype=np.float64)
 
         if len(proper_weights) != self.n:
             raise ValueError('Number of weights differ from the number of data points')
 
-        build_weights(<ckdtree*> self, <np.float64_t*>np.PyArray_DATA(node_weights),
-                            <np.float64_t*> np.PyArray_DATA(proper_weights))
+        build_weights(self.cself, &node_weights[0], &proper_weights[0])
 
         return node_weights
 
@@ -1221,7 +1144,7 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
     # ---------------
 
     @cython.boundscheck(False)
-    def count_neighbors(cKDTree self, cKDTree other, object r, np.float64_t p=2., 
+    def count_neighbors(cKDTree self, cKDTree other, object r, np.float64_t p=2.,
                         object weights=None, int cumulative=True):
         """"""
         count_neighbors(self, other, r, p=2., weights=None, cumulative=True)
@@ -1243,18 +1166,18 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             The other tree to draw points from, can be the same tree as self.
         r : float or one-dimensional array of floats
             The radius to produce a count for. Multiple radii are searched with
-            a single tree traversal. 
-            If the count is non-cumulative(``cumulative=False``), ``r`` defines 
+            a single tree traversal.
+            If the count is non-cumulative(``cumulative=False``), ``r`` defines
             the edges of the bins, and must be non-decreasing.
-        p : float, optional 
-            1<=p<=infinity. 
+        p : float, optional
+            1<=p<=infinity.
             Which Minkowski p-norm to use.
             Default 2.0.
             A finite large p may cause a ValueError if overflow can occur.
         weights : tuple, array_like, or None, optional
             If None, the pair-counting is unweighted.
             If given as a tuple, weights[0] is the weights of points in ``self``, and
-            weights[1] is the weights of points in ``other``; either can be None to 
+            weights[1] is the weights of points in ``other``; either can be None to
             indicate the points are unweighted.
             If given as an array_like, weights is the weights of points in ``self``
             and ``other``. For this to make sense, ``self`` and ``other`` must be the
@@ -1344,18 +1267,18 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         .. [5] https://github.com/scipy/scipy/pull/5647#issuecomment-168474926
 
         """"""
-        cdef: 
+        cdef:
             int r_ndim
             np.intp_t n_queries, i
-            np.ndarray[np.float64_t, ndim=1, mode=""c""] real_r
-            np.ndarray[np.float64_t, ndim=1, mode=""c""] fresults
-            np.ndarray[np.intp_t, ndim=1, mode=""c""] iresults
-            np.ndarray[np.float64_t, ndim=1, mode=""c""] w1, w1n
-            np.ndarray[np.float64_t, ndim=1, mode=""c""] w2, w2n
-            np.float64_t *w1p
-            np.float64_t *w1np
-            np.float64_t *w2p
-            np.float64_t *w2np
+            np.float64_t[::1] real_r
+            np.float64_t[::1] fresults
+            np.intp_t[::1] iresults
+            np.float64_t[::1] w1, w1n
+            np.float64_t[::1] w2, w2n
+            np.float64_t *w1p = NULL
+            np.float64_t *w1np = NULL
+            np.float64_t *w2p = NULL
+            np.float64_t *w2np = NULL
 
         # Make sure trees are compatible
         if self.m != other.m:
@@ -1370,8 +1293,9 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                              ""one-dimensional array of values"")
         real_r = np.array(r, ndmin=1, dtype=np.float64, copy=True)
         if not cumulative:
-            if (real_r[:-1] > real_r[1:]).any():
-                raise ValueError(""r must be non-decreasing for non-cumulative counting."");
+            for i in range(real_r.shape[0] - 1):
+                if real_r[i] > real_r[i + 1]:
+                    raise ValueError(""r must be non-decreasing for non-cumulative counting."");
         real_r, uind, inverse = np.unique(real_r, return_inverse=True, return_index=True)
         n_queries = real_r.shape[0]
 
@@ -1396,32 +1320,27 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             results = np.zeros(n_queries + 1, dtype=np.intp)
 
             iresults = results
-            count_neighbors_unweighted(<ckdtree*> self, <ckdtree*> other, n_queries,
+            count_neighbors_unweighted(self.cself, other.cself, n_queries,
                             &real_r[0], &iresults[0], p, cumulative)
 
         else:
             int_result = False
+
             # weighted / half weighted, use the floating point arithmetics
             if self_weights is not None:
                 w1 = np.ascontiguousarray(self_weights, dtype=np.float64)
                 w1n = self._build_weights(w1)
-                w1p = <np.float64_t*> np.PyArray_DATA(w1)
-                w1np = <np.float64_t*> np.PyArray_DATA(w1n)
-            else:
-                w1p = NULL
-                w1np = NULL
+                w1p = &w1[0]
+                w1np = &w1n[0]
             if other_weights is not None:
                 w2 = np.ascontiguousarray(other_weights, dtype=np.float64)
                 w2n = other._build_weights(w2)
-                w2p = <np.float64_t*> np.PyArray_DATA(w2)
-                w2np = <np.float64_t*> np.PyArray_DATA(w2n)
-            else:
-                w2p = NULL
-                w2np = NULL
+                w2p = &w2[0]
+                w2np = &w2n[0]
 
             results = np.zeros(n_queries + 1, dtype=np.float64)
             fresults = results
-            count_neighbors_weighted(<ckdtree*> self, <ckdtree*> other,
+            count_neighbors_weighted(self.cself, other.cself,
                                     w1p, w2p, w1np, w2np,
                                     n_queries,
                                     &real_r[0], &fresults[0], p, cumulative)
@@ -1443,11 +1362,11 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                 return results[0]
         else:
             return results
-    
+
     # ----------------------
     # sparse_distance_matrix
     # ----------------------
-    
+
     def sparse_distance_matrix(cKDTree self, cKDTree other,
                                np.float64_t max_distance,
                                np.float64_t p=2.,
@@ -1465,11 +1384,11 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         other : cKDTree
 
         max_distance : positive float
-        
+
         p : float, 1<=p<=infinity
             Which Minkowski p-norm to use.
             A finite large p may cause a ValueError if overflow can occur.
-        
+
         output_type : string, optional
             Which container to use for output data. Options: 'dok_matrix',
             'coo_matrix', 'dict', or 'ndarray'. Default: 'dok_matrix'.
@@ -1477,29 +1396,29 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         Returns
         -------
         result : dok_matrix, coo_matrix, dict or ndarray
-            Sparse matrix representing the results in ""dictionary of keys"" 
+            Sparse matrix representing the results in ""dictionary of keys""
             format. If a dict is returned the keys are (i,j) tuples of indices.
             If output_type is 'ndarray' a record array with fields 'i', 'j',
             and 'k' is returned,
         """"""
-        
+
         cdef coo_entries res
 
         # Make sure trees are compatible
         if self.m != other.m:
             raise ValueError(""Trees passed to sparse_distance_matrix have ""
-                             ""different dimensionality"")                                      
+                             ""different dimensionality"")
         # do the query
         res = coo_entries()
         sparse_distance_matrix(
-                <ckdtree*> self, <ckdtree*> other, p, max_distance, res.buf)
-                
+                self.cself, other.cself, p, max_distance, res.buf)
+
         if output_type == 'dict':
             return res.dict()
         elif output_type == 'ndarray':
             return res.ndarray()
         elif output_type == 'coo_matrix':
-            return res.coo_matrix(self.n, other.n)            
+            return res.coo_matrix(self.n, other.n)
         elif output_type == 'dok_matrix':
             return res.dok_matrix(self.n, other.n)
         else:
@@ -1508,42 +1427,58 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
     # ----------------------
     # pickle
-    # ----------------------    
-
-        
-    def __reduce__(self):
-        return (new_object, (cKDTree,), self.__getstate__())
+    # ----------------------
 
     def __getstate__(cKDTree self):
         cdef object state
-        cdef object tree = pickle_tree_buffer(self.tree_buffer)
-        state = (tree, self.data.copy(), self.n, self.m, self.leafsize,
-                      self.maxes, self.mins, self.indices.copy(), 
+        cdef np.intp_t size
+        cdef ckdtree * cself = self.cself
+        size = cself.tree_buffer.size() * sizeof(ckdtreenode)
+
+        cdef np.ndarray tree = np.asarray(<char[:size]> <char*> &cself.tree_buffer.front())
+
+        state = (tree.copy(), self.data.copy(), self.n, self.m, self.leafsize,
+                      self.maxes, self.mins, self.indices.copy(),
                       self.boxsize, self.boxsize_data)
         return state
-            
+
     def __setstate__(cKDTree self, state):
-        cdef object tree
-        self.tree_buffer = new vector[ckdtreenode]()
-        
+        cdef np.ndarray tree
+        cdef ckdtree * cself = self.cself
+        cdef np.ndarray mytree
+
         # unpack the state
-        (tree, self.data, self.n, self.m, self.leafsize, 
+        (tree, self.data, self.cself.n, self.cself.m, self.cself.leafsize,
             self.maxes, self.mins, self.indices, self.boxsize, self.boxsize_data) = state
 
+        cself.tree_buffer = new vector[ckdtreenode]()
+        cself.tree_buffer.resize(tree.size // sizeof(ckdtreenode))
+
+        mytree = np.asarray(<char[:tree.size]> <char*> &cself.tree_buffer.front())
+
         # set raw pointers
         self._pre_init()
-        
-        # copy kd-tree buffer 
-        unpickle_tree_buffer(self.tree_buffer, tree)    
-        
+
+        # copy the tree data
+        mytree[:] = tree
+
+
         # set up the tree structure pointers
         self._post_init()
-        
-        # make the tree viewable from Python
-        self.tree = cKDTreeNode()
-        self.tree._node = self.ctree
-        self.tree._data = self.data
-        self.tree._indices = self.indices
-        self.tree.level = 0
-        self.tree._setup() 
 
+def _run_threads(_thread_func, n, n_jobs):
+    if n_jobs > 1:
+        ranges = [(j * n // n_jobs, (j + 1) * n // n_jobs)
+                        for j in range(n_jobs)]
+
+        threads = [threading.Thread(target=_thread_func,
+                   args=(start, end))
+                   for start, end in ranges]
+        for t in threads:
+            t.daemon = True
+            t.start()
+        for t in threads:
+            t.join()
+
+    else:
+        _thread_func(0, n)
diff --git a/scipy/spatial/ckdtree/src/build.cxx b/scipy/spatial/ckdtree/src/build.cxx
index 2990ee5a3809..7fb96d896f20 100644
--- a/scipy/spatial/ckdtree/src/build.cxx
+++ b/scipy/spatial/ckdtree/src/build.cxx
@@ -1,6 +1,3 @@
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -13,30 +10,26 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
 #include ""ordered_pair.h""
-#include ""ckdtree_methods.h""
-#include ""cpp_exc.h""
-#include ""cpp_utils.h""
 #include ""partial_sort.h""
 
+#define tree_buffer_root(buf) (&(buf)[0][0])
 
-
-static npy_intp
-build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
-      npy_float64 *maxes, npy_float64 *mins,
+static ckdtree_intp_t
+build(ckdtree *self, ckdtree_intp_t start_idx, intptr_t end_idx,
+      double *maxes, double *mins,
       const int _median, const int _compact)
 {
 
-    const npy_intp m = self->m;
-    const npy_float64 *data = self->raw_data;
-    npy_intp *indices = (npy_intp *)(self->raw_indices);
+    const ckdtree_intp_t m = self->m;
+    const double *data = self->raw_data;
+    ckdtree_intp_t *indices = (intptr_t *)(self->raw_indices);
 
     ckdtreenode new_node, *n, *root;
-    npy_intp node_index, _less, _greater;
-    npy_intp i, j, p, q, d;
-    npy_float64 size, split, minval, maxval;
+    ckdtree_intp_t node_index, _less, _greater;
+    ckdtree_intp_t i, j, p, q, d;
+    double size, split, minval, maxval;
 
     /* put a new node into the node stack */
     self->tree_buffer->push_back(new_node);
@@ -56,13 +49,13 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
     }
     else {
 
-        if (NPY_LIKELY(_compact)) {
+        if (CKDTREE_LIKELY(_compact)) {
             /* Recompute hyperrectangle bounds. This should lead to a more
              * compact kd-tree but comes at the expense of larger construction
              * time. However, construction time is usually dwarfed by the
              * query time by orders of magnitude.
              */
-            const npy_float64 *tmp_data_point;
+            const double *tmp_data_point;
             tmp_data_point = data + indices[start_idx] * m;
             for(i=0; i<m; ++i) {
                 maxes[i] = tmp_data_point[i];
@@ -71,7 +64,7 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
             for (j = start_idx + 1; j < end_idx; ++j) {
                 tmp_data_point = data + indices[j] * m;
                 for(i=0; i<m; ++i) {
-                    npy_float64 tmp = tmp_data_point[i];
+                    double tmp = tmp_data_point[i];
                     maxes[i] = maxes[i] > tmp ? maxes[i] : tmp;
                     mins[i] = mins[i] < tmp ? mins[i] : tmp;
                 }
@@ -99,7 +92,7 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
 
         /* construct new inner node */
 
-        if (NPY_LIKELY(_median)) {
+        if (CKDTREE_LIKELY(_median)) {
             /* split on median to create a balanced tree
              * adopted from scikit-learn
              */
@@ -122,7 +115,7 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
             else if (data[indices[q] * m + d] >= split)
                 --q;
             else {
-                npy_intp t = indices[p];
+                ckdtree_intp_t t = indices[p];
                 indices[p] = indices[q];
                 indices[q] = t;
                 ++p;
@@ -140,7 +133,7 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
                     split = data[indices[j] * m + d];
                 }
             }
-            npy_intp t = indices[start_idx];
+            ckdtree_intp_t t = indices[start_idx];
             indices[start_idx] = indices[j];
             indices[j] = t;
             p = start_idx + 1;
@@ -156,21 +149,21 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
                     split = data[indices[j] * m + d];
                 }
             }
-            npy_intp t = indices[end_idx-1];
+            ckdtree_intp_t t = indices[end_idx-1];
             indices[end_idx-1] = indices[j];
             indices[j] = t;
             p = end_idx - 1;
             q = end_idx - 2;
         }
 
-        if (NPY_LIKELY(_compact)) {
+        if (CKDTREE_LIKELY(_compact)) {
             _less = build(self, start_idx, p, maxes, mins, _median, _compact);
             _greater = build(self, p, end_idx, maxes, mins, _median, _compact);
         }
         else
         {
-            std::vector<npy_float64> tmp(m);
-            npy_float64 *mids = &tmp[0];
+            std::vector<double> tmp(m);
+            double *mids = &tmp[0];
 
             for (i=0; i<m; ++i) mids[i] = maxes[i];
             mids[d] = split;
@@ -200,42 +193,22 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
 
 
 
-extern ""C"" PyObject*
-build_ckdtree(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
-              npy_float64 *maxes, npy_float64 *mins, int _median, int _compact)
+int build_ckdtree(ckdtree *self, ckdtree_intp_t start_idx, intptr_t end_idx,
+              double *maxes, double *mins, int _median, int _compact)
 
 {
-
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            build(self, start_idx, end_idx, maxes, mins, _median, _compact);
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
-    }
+    build(self, start_idx, end_idx, maxes, mins, _median, _compact);
+    return 0;
 }
 
-static npy_float64
+static double
 add_weights(ckdtree *self,
-           npy_float64 *node_weights,
-           npy_intp node_index,
-           npy_float64 *weights)
+           double *node_weights,
+           ckdtree_intp_t node_index,
+           double *weights)
 {
 
-    npy_intp *indices = (npy_intp *)(self->raw_indices);
+    ckdtree_intp_t *indices = (intptr_t *)(self->raw_indices);
 
     ckdtreenode *n, *root;
 
@@ -243,16 +216,16 @@ add_weights(ckdtree *self,
 
     n = root + node_index;
 
-    npy_float64 sum = 0;
+    double sum = 0;
 
     if (n->split_dim != -1) {
         /* internal nodes; recursively calculate the total weight */
-        npy_float64 left, right;
+        double left, right;
         left = add_weights(self, node_weights, n->_less, weights);
         right = add_weights(self, node_weights, n->_greater, weights);
         sum = left + right;
     } else {
-        npy_intp i;
+        ckdtree_intp_t i;
 
         /* Leaf nodes */
         for (i = n->start_idx; i < n->end_idx; ++i) {
@@ -264,30 +237,11 @@ add_weights(ckdtree *self,
     return sum;
 }
 
-
-extern ""C"" PyObject*
-build_weights (ckdtree *self, npy_float64 *node_weights, npy_float64 *weights)
+int
+build_weights (ckdtree *self, double *node_weights, double *weights)
 {
 
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            add_weights(self, node_weights, 0, weights);
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
-    }
+    add_weights(self, node_weights, 0, weights);
+    return 0;
 }
 
diff --git a/scipy/spatial/ckdtree/src/ckdtree_decl.h b/scipy/spatial/ckdtree/src/ckdtree_decl.h
index fc9f85adf346..0ae3a93dce35 100644
--- a/scipy/spatial/ckdtree/src/ckdtree_decl.h
+++ b/scipy/spatial/ckdtree/src/ckdtree_decl.h
@@ -2,55 +2,131 @@
 #define CKDTREE_CPP_DECL
 
 /*
- * Make sure that these declarations are correct
- * by looking at the header file ckdtree.h which
- * is generated by running
- *
- * $ cython ckdtree.pyx
- *
- * Unless you add fields to cKDTree there will be
- * no change in struct ckdtree. The fields are laid
- * out in the same order they are defined in Cython.
- */
+ * Use numpy to provide some platform independency.
+ * Define these functions for your platform
+ * */
+#include <cmath> /* needed for isinf / sc_inf from c99compat under CLANG */
+#include ""_c99compat.h""
+#include <numpy/npy_common.h>
+#define CKDTREE_LIKELY(x) NPY_LIKELY(x)
+#define CKDTREE_UNLIKELY(x)  NPY_UNLIKELY(x)
+#define CKDTREE_PREFETCH(x, rw, loc)  NPY_PREFETCH(x, rw, loc)
+
+#define ckdtree_intp_t npy_intp
+#define ckdtree_isinf(x)   sc_isinf(x)
+#define ckdtree_fmin(x, y)   fmin(x, y)
+#define ckdtree_fmax(x, y)   fmax(x, y)
+#define ckdtree_fabs(x)   fabs(x)
+
+#include ""ordered_pair.h""
+#include ""coo_entries.h""
 
 struct ckdtreenode {
-    npy_intp      split_dim;
-    npy_intp      children;
-    npy_float64   split;
-    npy_intp      start_idx;
-    npy_intp      end_idx;
+    ckdtree_intp_t      split_dim;
+    ckdtree_intp_t      children;
+    double   split;
+    ckdtree_intp_t      start_idx;
+    ckdtree_intp_t      end_idx;
     ckdtreenode   *less;
     ckdtreenode   *greater;
-    npy_intp      _less;
-    npy_intp      _greater;
+    ckdtree_intp_t      _less;
+    ckdtree_intp_t      _greater;
 };
 
-#ifdef CKDTREE_METHODS_IMPL
 struct ckdtree {
-    PyObject_HEAD
-    // vtab pointer is present as long as cKDTree has cdef methods
-    const void          *vtab;
     // tree structure
     std::vector<ckdtreenode>  *tree_buffer;
-    const ckdtreenode   *ctree;
-    const PyObject      *dummy;
+    ckdtreenode   *ctree;
     // meta data
-    const PyArrayObject *data;
-    const npy_float64   *raw_data;
-    const npy_intp      n;
-    const npy_intp      m;
-    const npy_intp      leafsize;
-    const PyArrayObject *maxes;
-    const npy_float64   *raw_maxes;
-    const PyArrayObject *mins;
-    const npy_float64   *raw_mins;
-    const PyArrayObject *indices;
-    const npy_intp      *raw_indices;
-    const PyArrayObject *_median_workspace;
-    const PyObject      *boxsize;
-    const PyArrayObject *boxsize_data;
-    const npy_float64   *raw_boxsize_data;
-    const npy_intp size;
+    double   *raw_data;
+    ckdtree_intp_t      n;
+    ckdtree_intp_t      m;
+    ckdtree_intp_t      leafsize;
+    double   *raw_maxes;
+    double   *raw_mins;
+    ckdtree_intp_t      *raw_indices;
+    double   *raw_boxsize_data;
+    ckdtree_intp_t size;
 };
-#endif
+
+/* Build methods in C++ for better speed and GIL release */
+
+int
+build_ckdtree(ckdtree *self, ckdtree_intp_t start_idx, intptr_t end_idx,
+              double *maxes, double *mins, int _median, int _compact);
+
+int
+build_weights (ckdtree *self, double *node_weights, double *weights);
+
+/* Query methods in C++ for better speed and GIL release */
+
+int
+query_knn(const ckdtree     *self,
+          double       *dd,
+          ckdtree_intp_t          *ii,
+          const double *xx,
+          const ckdtree_intp_t     n,
+          const ckdtree_intp_t     *k,
+          const ckdtree_intp_t     nk,
+          const ckdtree_intp_t     kmax,
+          const double  eps,
+          const double  p,
+          const double  distance_upper_bound);
+
+int
+query_pairs(const ckdtree *self,
+            const double r,
+            const double p,
+            const double eps,
+            std::vector<ordered_pair> *results);
+
+int
+count_neighbors_unweighted(const ckdtree *self,
+                const ckdtree *other,
+                ckdtree_intp_t n_queries,
+                double *real_r,
+                ckdtree_intp_t *results,
+                const double p,
+                int cumulative);
+
+int
+count_neighbors_weighted(const ckdtree *self,
+                const ckdtree *other,
+                double *self_weights,
+                double *other_weights,
+                double *self_node_weights,
+                double *other_node_weights,
+                ckdtree_intp_t n_queries,
+                double *real_r,
+                double *results,
+                const double p,
+                int cumulative);
+
+int
+query_ball_point(const ckdtree *self,
+                 const double *x,
+                 const double *r,
+                 const double p,
+                 const double eps,
+                 const ckdtree_intp_t n_queries,
+                 std::vector<ckdtree_intp_t> **results,
+                 const int return_length);
+
+int
+query_ball_tree(const ckdtree *self,
+                const ckdtree *other,
+                const double r,
+                const double p,
+                const double eps,
+                std::vector<ckdtree_intp_t> **results
+                );
+
+int
+sparse_distance_matrix(const ckdtree *self,
+                       const ckdtree *other,
+                       const double p,
+                       const double max_distance,
+                       std::vector<coo_entry> *results);
+
+
 #endif
diff --git a/scipy/spatial/ckdtree/src/ckdtree_methods.h b/scipy/spatial/ckdtree/src/ckdtree_methods.h
deleted file mode 100644
index 04c7c8833074..000000000000
--- a/scipy/spatial/ckdtree/src/ckdtree_methods.h
+++ /dev/null
@@ -1,216 +0,0 @@
-
-#ifndef CKDTREE_CPP_METHODS
-#define CKDTREE_CPP_METHODS
-
-#ifdef CKDTREE_METHODS_IMPL
-#define CKDTREE_EXTERN extern ""C""
-#else
-#define CKDTREE_EXTERN extern ""C""
-struct ckdtree;
-#endif
-
-extern int number_of_processors;
-
-#ifndef NPY_LIKELY
-#define NPY_LIKELY(x) (x)
-#endif
-
-#ifndef NPY_UNLIKELY
-#define NPY_UNLIKELY(x) (x)
-#endif
-
-#include <cmath>
-#include <vector>
-#include ""numpy/npy_math.h""
-#include ""ordered_pair.h""
-#include ""coo_entries.h""
-
-#if defined(__GNUC__)
-
-inline void
-prefetch_datapoint(const npy_float64 *x, const npy_intp m)
-{
-    const int cache_line = 64;  // x86, amd64
-    char *cur = (char*)x;
-    char *end = (char*)(x+m);
-    while (cur < end) {
-        __builtin_prefetch((void*)cur);
-        cur += cache_line;
-    }
-}
-
-#else
-
-#if defined(_WIN32)
-
-#include <xmmintrin.h>
-
-inline void
-prefetch_datapoint(const npy_float64 *x, const npy_intp m)
-{
-    const int cache_line = 64;  // x86, amd64
-    char *cur = (char*)x;
-    char *end = (char*)(x+m);
-    while (cur < end) {
-        _mm_prefetch((const char*)cur,_MM_HINT_T0);
-        cur += cache_line;
-    }
-}
-
-#else
-
-#define prefetch_datapoint(x,y)
-
-#endif // _WIN32
-#endif // __GNUC__
-
-/*
- * Utility functions
- * =================
- */
-
-#define ckdtree_isinf(x) (x == NPY_INFINITY)
-
-inline npy_float64
-dmax(const npy_float64 x, const npy_float64 y)
-{
-    if (x > y)
-        return x;
-    else
-        return y;
-};
-
-inline npy_float64
-dmin(const npy_float64 x, const npy_float64 y)
-{
-    if (x < y)
-        return x;
-    else
-        return y;
-};
-
-
-inline npy_float64
-dabs(const npy_float64 x)
-{
-    if (x > 0)
-        return x;
-    else
-        return -x;
-}
-
-/*
- * Measuring distances
- * ===================
- */
-inline npy_float64
-sqeuclidean_distance_double(const npy_float64 *u, const npy_float64 *v, npy_intp n)
-{
-    npy_float64 s;
-    npy_intp i;
-    // manually unrolled loop, might be vectorized
-    npy_float64 acc[4] = {0., 0., 0., 0.};
-    for (i = 0; i < n/4; i += 4) {
-        npy_float64 _u[4] = {u[i], u[i + 1], u[i + 2], u[i + 3]};
-        npy_float64 _v[4] = {v[i], v[i + 1], v[i + 2], v[i + 3]};
-        npy_float64 diff[4] = {_u[0] - _v[0],
-                               _u[1] - _v[1],
-                               _u[2] - _v[2],
-                               _u[3] - _v[3]};
-        acc[0] += diff[0] * diff[0];
-        acc[1] += diff[1] * diff[1];
-        acc[2] += diff[2] * diff[2];
-        acc[3] += diff[3] * diff[3];
-    }
-    s = acc[0] + acc[1] + acc[2] + acc[3];
-    if (i < n) {
-        for(; i<n; ++i) {
-            npy_float64 d = u[i] - v[i];
-            s += d * d;
-        }
-    }
-    return s;
-}
-
-
-/* Build methods in C++ for better speed and GIL release */
-
-CKDTREE_EXTERN PyObject*
-build_ckdtree(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
-              npy_float64 *maxes, npy_float64 *mins, int _median, int _compact);
-
-extern ""C"" PyObject*
-build_weights (ckdtree *self, npy_float64 *node_weights, npy_float64 *weights);
-
-/* Query methods in C++ for better speed and GIL release */
-
-CKDTREE_EXTERN PyObject*
-query_knn(const ckdtree     *self,
-          npy_float64       *dd,
-          npy_intp          *ii,
-          const npy_float64 *xx,
-          const npy_intp     n,
-          const npy_intp     *k,
-          const npy_intp     nk,
-          const npy_intp     kmax,
-          const npy_float64  eps,
-          const npy_float64  p,
-          const npy_float64  distance_upper_bound);
-
-CKDTREE_EXTERN PyObject*
-query_pairs(const ckdtree *self,
-            const npy_float64 r,
-            const npy_float64 p,
-            const npy_float64 eps,
-            std::vector<ordered_pair> *results);
-
-CKDTREE_EXTERN PyObject*
-count_neighbors_unweighted(const ckdtree *self,
-                const ckdtree *other,
-                npy_intp n_queries,
-                npy_float64 *real_r,
-                npy_intp *results,
-                const npy_float64 p,
-                int cumulative);
-
-CKDTREE_EXTERN PyObject*
-count_neighbors_weighted(const ckdtree *self,
-                const ckdtree *other,
-                npy_float64 *self_weights,
-                npy_float64 *other_weights,
-                npy_float64 *self_node_weights,
-                npy_float64 *other_node_weights,
-                npy_intp n_queries,
-                npy_float64 *real_r,
-                npy_float64 *results,
-                const npy_float64 p,
-                int cumulative);
-
-CKDTREE_EXTERN PyObject*
-query_ball_point(const ckdtree *self,
-                 const npy_float64 *x,
-                 const npy_float64 r,
-                 const npy_float64 p,
-                 const npy_float64 eps,
-                 const npy_intp n_queries,
-                 std::vector<npy_intp> **results);
-
-CKDTREE_EXTERN PyObject*
-query_ball_tree(const ckdtree *self,
-                const ckdtree *other,
-                const npy_float64 r,
-                const npy_float64 p,
-                const npy_float64 eps,
-                std::vector<npy_intp> **results);
-
-CKDTREE_EXTERN PyObject*
-sparse_distance_matrix(const ckdtree *self,
-                       const ckdtree *other,
-                       const npy_float64 p,
-                       const npy_float64 max_distance,
-                       std::vector<coo_entry> *results);
-
-
-#endif
-
-
diff --git a/scipy/spatial/ckdtree/src/coo_entries.h b/scipy/spatial/ckdtree/src/coo_entries.h
index 4f0f368e125c..b2edd7797d7c 100644
--- a/scipy/spatial/ckdtree/src/coo_entries.h
+++ b/scipy/spatial/ckdtree/src/coo_entries.h
@@ -1,13 +1,10 @@
 #ifndef CKDTREE_COO_ENTRIES
 #define CKDTREE_COO_ENTRIES
 
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 struct coo_entry {
-    npy_intp i;
-    npy_intp j;
-    npy_float64 v;
+    ckdtree_intp_t i;
+    ckdtree_intp_t j;
+    double v;
 };
 
 #endif
diff --git a/scipy/spatial/ckdtree/src/count_neighbors.cxx b/scipy/spatial/ckdtree/src/count_neighbors.cxx
index 5f79f80bf2ac..4847606a18b1 100644
--- a/scipy/spatial/ckdtree/src/count_neighbors.cxx
+++ b/scipy/spatial/ckdtree/src/count_neighbors.cxx
@@ -1,6 +1,3 @@
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -14,21 +11,18 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
-#include ""ckdtree_methods.h""
-#include ""cpp_exc.h""
 #include ""rectangle.h""
 
 struct WeightedTree {
     const ckdtree *tree;
-    npy_float64 *weights;
-    npy_float64 *node_weights;
+    double *weights;
+    double *node_weights;
 };
 
 struct CNBParams
 {
-    npy_float64 *r;
+    double *r;
     void * results; /* will be casted inside */
     WeightedTree self, other;
     int cumulative;
@@ -38,13 +32,13 @@ template <typename MinMaxDist, typename WeightType, typename ResultType> static
 traverse(
     RectRectDistanceTracker<MinMaxDist> *tracker,
     const CNBParams *params,
-    npy_float64 *start, npy_float64 *end,
+    double *start, double *end,
     const ckdtreenode *node1,
     const ckdtreenode *node2)
 {
     static void (* const next)(RectRectDistanceTracker<MinMaxDist> *tracker,
             const CNBParams *params,
-            npy_float64 *start, npy_float64 *end,
+            double *start, double *end,
             const ckdtreenode *node1,
             const ckdtreenode *node2) = traverse<MinMaxDist, WeightType, ResultType>;
 
@@ -55,13 +49,13 @@ traverse(
      * and see if any work remains to be done
      */
 
-    npy_float64 * new_start = std::lower_bound(start, end, tracker->min_distance);
-    npy_float64 * new_end = std::lower_bound(start, end, tracker->max_distance);
+    double * new_start = std::lower_bound(start, end, tracker->min_distance);
+    double * new_end = std::lower_bound(start, end, tracker->max_distance);
 
 
     /* since max_distance >= min_distance, end < start never happens */
     if (params->cumulative) {
-        npy_float64 * i;
+        double * i;
         if (new_end != end) {
             ResultType nn = WeightType::get_weight(&params->self, node1)
                           * WeightType::get_weight(&params->other, node2);
@@ -93,41 +87,41 @@ traverse(
     /* OK, need to probe a bit deeper */
     if (node1->split_dim == -1) {  /* 1 is leaf node */
         if (node2->split_dim == -1) {  /* 1 & 2 are leaves */
-            npy_intp i, j;
-            const npy_float64 p = tracker->p;
-            const npy_float64 tmd = tracker->max_distance;
-            const npy_float64 *sdata = params->self.tree->raw_data;
-            const npy_intp *sindices = params->self.tree->raw_indices;
-            const npy_float64 *odata = params->other.tree->raw_data;
-            const npy_intp *oindices = params->other.tree->raw_indices;
-            const npy_intp m = params->self.tree->m;
-            const npy_intp start1 = node1->start_idx;
-            const npy_intp start2 = node2->start_idx;
-            const npy_intp end1 = node1->end_idx;
-            const npy_intp end2 = node2->end_idx;
-
-            prefetch_datapoint(sdata + sindices[start1] * m, m);
+            ckdtree_intp_t i, j;
+            const double p = tracker->p;
+            const double tmd = tracker->max_distance;
+            const double *sdata = params->self.tree->raw_data;
+            const ckdtree_intp_t *sindices = params->self.tree->raw_indices;
+            const double *odata = params->other.tree->raw_data;
+            const ckdtree_intp_t *oindices = params->other.tree->raw_indices;
+            const ckdtree_intp_t m = params->self.tree->m;
+            const ckdtree_intp_t start1 = node1->start_idx;
+            const ckdtree_intp_t start2 = node2->start_idx;
+            const ckdtree_intp_t end1 = node1->end_idx;
+            const ckdtree_intp_t end2 = node2->end_idx;
+
+            CKDTREE_PREFETCH(sdata + sindices[start1] * m, 0, m);
 
             if (start1 < end1 - 1)
-                prefetch_datapoint(sdata + sindices[start1+1] * m, m);
+                CKDTREE_PREFETCH(sdata + sindices[start1+1] * m, 0, m);
 
             /* brute-force */
             for (i = start1; i < end1; ++i) {
 
                 if (i < end1 - 2)
-                    prefetch_datapoint(sdata + sindices[i+2] * m, m);
+                    CKDTREE_PREFETCH(sdata + sindices[i+2] * m, 0, m);
 
-                prefetch_datapoint(odata + oindices[start2] * m, m);
+                CKDTREE_PREFETCH(odata + oindices[start2] * m, 0, m);
 
                 if (start2 < end2 - 1)
-                    prefetch_datapoint(odata + oindices[start2+1] * m, m);
+                    CKDTREE_PREFETCH(odata + oindices[start2+1] * m, 0, m);
 
                 for (j = start2; j < end2; ++j) {
 
                     if (j < end2 - 2)
-                        prefetch_datapoint(odata + oindices[j+2] * m, m);
+                        CKDTREE_PREFETCH(odata + oindices[j+2] * m, 0, m);
 
-                    npy_float64 d = MinMaxDist::point_point_p(params->self.tree,
+                    double d = MinMaxDist::point_point_p(params->self.tree,
                             sdata + sindices[i] * m,
                             odata + oindices[j] * m,
                             p, m, tmd);
@@ -138,7 +132,7 @@ traverse(
                          * r's than to generate a distance array, sort it, then
                          * search for all r's via binary search
                          */
-                        npy_float64 * l;
+                        double * l;
                         for (l = start; l < end; ++l) {
                             if (d <= *l) {
                                 results[l - params->r] += WeightType::get_weight(&params->self, sindices[i])
@@ -146,7 +140,7 @@ traverse(
                             }
                         }
                     } else {
-                        const npy_float64 *l = std::lower_bound(start, end, d);
+                        const double *l = std::lower_bound(start, end, d);
                         results[l - params->r] += WeightType::get_weight(&params->self, sindices[i])
                                                 * WeightType::get_weight(&params->other, sindices[j]);
                     }
@@ -200,7 +194,7 @@ traverse(
 
 template <typename WeightType, typename ResultType> void
 count_neighbors(struct CNBParams *params,
-                npy_intp n_queries, const npy_float64 p)
+                ckdtree_intp_t n_queries, const double p)
 {
 
     const ckdtree *self = params->self.tree;
@@ -216,14 +210,14 @@ count_neighbors(struct CNBParams *params,
     Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
     Rectangle r2(other->m, other->raw_mins, other->raw_maxes);
 
-    if (NPY_LIKELY(self->raw_boxsize_data == NULL)) {
-        HANDLE(NPY_LIKELY(p == 2), MinkowskiDistP2)
+    if (CKDTREE_LIKELY(self->raw_boxsize_data == NULL)) {
+        HANDLE(CKDTREE_LIKELY(p == 2), MinkowskiDistP2)
         HANDLE(p == 1, MinkowskiDistP1)
         HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
         HANDLE(1, MinkowskiDistPp)
         {}
     } else {
-        HANDLE(NPY_LIKELY(p == 2), BoxMinkowskiDistP2)
+        HANDLE(CKDTREE_LIKELY(p == 2), BoxMinkowskiDistP2)
         HANDLE(p == 1, BoxMinkowskiDistP1)
         HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
         HANDLE(1, BoxMinkowskiDistPp)
@@ -233,22 +227,23 @@ count_neighbors(struct CNBParams *params,
 
 struct Unweighted {
     /* the interface for accessing weights of unweighted data. */
-    static inline npy_intp
+    static inline ckdtree_intp_t
     get_weight(const WeightedTree *wt, const ckdtreenode * node)
     {
         return node->children;
     }
-    static inline npy_intp
-    get_weight(const WeightedTree *wt, const npy_intp i)
+    static inline ckdtree_intp_t
+    get_weight(const WeightedTree *wt, const ckdtree_intp_t i)
     {
         return 1;
     }
 };
 
-extern ""C"" PyObject*
+
+int
 count_neighbors_unweighted(const ckdtree *self, const ckdtree *other,
-                npy_intp n_queries, npy_float64 *real_r, npy_intp *results,
-                const npy_float64 p, int cumulative) {
+                ckdtree_intp_t n_queries, double *real_r, intptr_t *results,
+                const double p, int cumulative) {
 
     CNBParams params = {0};
 
@@ -258,51 +253,33 @@ count_neighbors_unweighted(const ckdtree *self, const ckdtree *other,
     params.other.tree = other;
     params.cumulative = cumulative;
 
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            count_neighbors<Unweighted, npy_intp>(&params, n_queries, p);
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
-    }
+    count_neighbors<Unweighted, ckdtree_intp_t>(&params, n_queries, p);
+
+    return 0;
 }
 
 struct Weighted {
     /* the interface for accessing weights of weighted data. */
-    static inline npy_float64
+    static inline double
     get_weight(const WeightedTree *wt, const ckdtreenode * node)
     {
         return (wt->weights != NULL)
            ? wt->node_weights[node - wt->tree->ctree]
            : node->children;
     }
-    static inline npy_float64
-    get_weight(const WeightedTree *wt, const npy_intp i)
+    static inline double
+    get_weight(const WeightedTree *wt, const ckdtree_intp_t i)
     {
         return (wt->weights != NULL)?wt->weights[i]:1;
     }
 };
 
-
-extern ""C"" PyObject*
+int
 count_neighbors_weighted(const ckdtree *self, const ckdtree *other,
-                npy_float64 *self_weights, npy_float64 *other_weights,
-                npy_float64 *self_node_weights, npy_float64 *other_node_weights,
-                npy_intp n_queries, npy_float64 *real_r, npy_float64 *results,
-                const npy_float64 p, int cumulative)
+                double *self_weights, double *other_weights,
+                double *self_node_weights, double *other_node_weights,
+                ckdtree_intp_t n_queries, double *real_r, double *results,
+                const double p, int cumulative)
 {
 
     CNBParams params = {0};
@@ -321,25 +298,9 @@ count_neighbors_weighted(const ckdtree *self, const ckdtree *other,
         params.other.weights = other_weights;
         params.other.node_weights = other_node_weights;
     }
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            count_neighbors<Weighted, npy_float64>(&params, n_queries, p);
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
-    }
+
+    count_neighbors<Weighted, double>(&params, n_queries, p);
+
+    return 0;
 }
 
diff --git a/scipy/spatial/ckdtree/src/cpp_exc.cxx b/scipy/spatial/ckdtree/src/cpp_exc.cxx
deleted file mode 100644
index 824abee56a6d..000000000000
--- a/scipy/spatial/ckdtree/src/cpp_exc.cxx
+++ /dev/null
@@ -1,67 +0,0 @@
-/*
- * Catch C++ standard exceptions and raise corresponding
- * Python exceptions. Use simplified GIL API to ensure
- * we have the GIL.
- */
-
-#include <new>
-#include <typeinfo>
-#include <stdexcept>
-#include <ios>
-
-#include <Python.h>
-
-extern ""C"" void
-translate_cpp_exception()
-{
-    try {
-        if (PyErr_Occurred())
-            return;
-        else
-            throw;
-    }
-    catch (const std::bad_alloc &exn) {
-        PyErr_NoMemory();
-    }
-    catch (const std::bad_cast &exn) {
-        PyErr_SetString(PyExc_TypeError, exn.what());
-    }
-    catch (const std::domain_error &exn) {
-        PyErr_SetString(PyExc_ValueError, exn.what());
-    }
-    catch (const std::invalid_argument &exn) {
-        PyErr_SetString(PyExc_ValueError, exn.what());
-    }
-    catch (const std::ios_base::failure &exn) {
-        PyErr_SetString(PyExc_IOError, exn.what());
-    }
-    catch (const std::out_of_range &exn) {
-        PyErr_SetString(PyExc_IndexError, exn.what());
-    }
-    catch (const std::overflow_error &exn) {
-        PyErr_SetString(PyExc_OverflowError, exn.what());
-    }
-    catch (const std::range_error &exn) {
-        PyErr_SetString(PyExc_ArithmeticError, exn.what());
-    }
-    catch (const std::underflow_error &exn) {
-        PyErr_SetString(PyExc_ArithmeticError, exn.what());
-    }
-    catch (const std::logic_error &exn) {
-        PyErr_SetString(PyExc_RuntimeError, exn.what());
-    }
-    catch (const std::exception& exn) {
-        PyErr_SetString(PyExc_RuntimeError, exn.what());
-    }
-    catch (...) {
-        PyErr_SetString(PyExc_RuntimeError, ""Unknown exception"");
-    }
-}
-
-extern ""C"" void
-translate_cpp_exception_with_gil()
-{
-    PyGILState_STATE state = PyGILState_Ensure();
-    translate_cpp_exception();
-    PyGILState_Release(state);
-}
diff --git a/scipy/spatial/ckdtree/src/cpp_exc.h b/scipy/spatial/ckdtree/src/cpp_exc.h
deleted file mode 100644
index 557caf21d5a0..000000000000
--- a/scipy/spatial/ckdtree/src/cpp_exc.h
+++ /dev/null
@@ -1,18 +0,0 @@
-/*
- * Catch C++ standard exceptions and raise corresponding
- * Python exceptions. Use simplified GIL API to ensure
- * we have the GIL.
- */
-
-
-#ifndef CKDTREE_CPP_EXC_H
-#define CKDTREE_CPP_EXC_H
-
-extern ""C"" void
-translate_cpp_exception();
-
-extern ""C"" void
-translate_cpp_exception_with_gil();
-
-#endif
-
diff --git a/scipy/spatial/ckdtree/src/cpp_utils.h b/scipy/spatial/ckdtree/src/cpp_utils.h
deleted file mode 100644
index 51be061dcf39..000000000000
--- a/scipy/spatial/ckdtree/src/cpp_utils.h
+++ /dev/null
@@ -1,109 +0,0 @@
-#include <vector>
-#include <cstring>
-#include <Python.h>
-
-#include ""ordered_pair.h""
-#include ""ckdtree_decl.h""
-#include ""cpp_exc.h""
-#include ""coo_entries.h""
-
-
-#if PY_MAJOR_VERSION < 3
-    #define ckdtree_PyBytes_FromStringAndSize(v,len) PyString_FromStringAndSize(v,len)
-    #define ckdtree_PyBytes_Size(o) PyString_Size(o)
-    #define ckdtree_PyBytes_AsString(o) PyString_AsString(o)
-#else
-    #define ckdtree_PyBytes_FromStringAndSize(v,len) PyBytes_FromStringAndSize(v,len)
-    #define ckdtree_PyBytes_Size(o) PyBytes_Size(o)
-    #define ckdtree_PyBytes_AsString(o) PyBytes_AsString(o)
-#endif
-
-
-inline void*
-tree_buffer_pointer(std::vector<ckdtreenode> *buf)
-{
-    std::vector<ckdtreenode> &tmp = *buf;
-    if (NPY_UNLIKELY(tmp.size() == 0))
-        return NULL;
-    return (void*)&tmp[0];
-}
-
-
-inline ckdtreenode*
-tree_buffer_root(std::vector<ckdtreenode> *buf)
-{
-    std::vector<ckdtreenode> &tmp = *buf;
-    if (NPY_UNLIKELY(tmp.size() == 0))
-        return NULL;
-    return &tmp[0];
-}
-
-inline ordered_pair *
-ordered_pair_vector_buf(std::vector<ordered_pair> *buf)
-{
-    std::vector<ordered_pair> &tmp = *buf;
-    if (NPY_UNLIKELY(tmp.size() == 0))
-        return NULL;
-    return &tmp[0];
-}
-
-
-typedef std::vector<npy_intp> *intvector_ptr_t;
-
-inline npy_intp *
-npy_intp_vector_buf(std::vector<npy_intp> *buf)
-{
-    std::vector<npy_intp> &tmp = *buf;
-    if (NPY_UNLIKELY(tmp.size() == 0))
-        return NULL;
-    return &tmp[0];
-}
-
-inline npy_float64 *
-npy_float64_vector_buf(std::vector<npy_float64> *buf)
-{
-    std::vector<npy_float64> &tmp = *buf;
-    if (NPY_UNLIKELY(tmp.size() == 0))
-        return NULL;
-    return &tmp[0];
-}
-
-inline coo_entry *
-coo_entry_vector_buf(std::vector<coo_entry> *buf)
-{
-    std::vector<coo_entry> &tmp = *buf;
-    if (NPY_UNLIKELY(tmp.size() == 0))
-        return NULL;
-    return &tmp[0];
-}
-
-
-static PyObject *
-pickle_tree_buffer(std::vector<ckdtreenode> *buf)
-{
-    char *v = (char*) &(buf->front());
-    Py_ssize_t len = buf->size() * sizeof(ckdtreenode);
-    return ckdtree_PyBytes_FromStringAndSize(v,len);
-}
-
-
-static PyObject *
-unpickle_tree_buffer(std::vector<ckdtreenode> *buf, PyObject *src)
-{
-    Py_ssize_t s, n;
-    ckdtreenode *target, *cur;
-    s = ckdtree_PyBytes_Size(src);
-    if (PyErr_Occurred()) return NULL;
-    n = s / sizeof(ckdtreenode);
-    cur = (ckdtreenode *)ckdtree_PyBytes_AsString(src);
-    if (PyErr_Occurred()) return NULL;
-    try {
-        buf->resize(n);
-        target = &(buf->front());
-        std::memcpy((void*)target,(void*)cur,s);
-    } catch (...) {
-        translate_cpp_exception();
-        return NULL;
-    }
-    Py_RETURN_NONE;
-}
diff --git a/scipy/spatial/ckdtree/src/distance.h b/scipy/spatial/ckdtree/src/distance.h
index 8920b422bb18..03b52a579046 100644
--- a/scipy/spatial/ckdtree/src/distance.h
+++ b/scipy/spatial/ckdtree/src/distance.h
@@ -1,15 +1,15 @@
 #include ""distance_base.h""
-#include ""_c99compat.h""
+
 
 struct PlainDist1D {
-    static inline const npy_float64 side_distance_from_min_max(
-        const ckdtree * tree, const npy_float64 x,
-        const npy_float64 min,
-        const npy_float64 max,
-        const npy_intp k
+    static inline const double side_distance_from_min_max(
+        const ckdtree * tree, const double x,
+        const double min,
+        const double max,
+        const ckdtree_intp_t k
         )
     {
-        npy_float64 s, t;
+        double s, t;
         s = 0;
         t = x - max;
         if (t > s) {
@@ -23,23 +23,23 @@ struct PlainDist1D {
     static inline void
     interval_interval(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_intp k,
-                        npy_float64 *min, npy_float64 *max)
+                        const ckdtree_intp_t k,
+                        double *min, double *max)
     {
         /* Compute the minimum/maximum distance along dimension k between points in
          * two hyperrectangles.
          */
-        *min = dmax(0, dmax(rect1.mins()[k] - rect2.maxes()[k],
+        *min = ckdtree_fmax(0., fmax(rect1.mins()[k] - rect2.maxes()[k],
                               rect2.mins()[k] - rect1.maxes()[k]));
-        *max = dmax(rect1.maxes()[k] - rect2.mins()[k],
+        *max = ckdtree_fmax(rect1.maxes()[k] - rect2.mins()[k],
                               rect2.maxes()[k] - rect1.mins()[k]);
     }
 
-    static inline npy_float64
+    static inline double
     point_point(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-                 const npy_intp k) {
-        return dabs(x[k] - y[k]);
+               const double *x, const double *y,
+                 const ckdtree_intp_t k) {
+        return ckdtree_fabs(x[k] - y[k]);
     }
 };
 
@@ -48,12 +48,46 @@ typedef BaseMinkowskiDistPinf<PlainDist1D> MinkowskiDistPinf;
 typedef BaseMinkowskiDistP1<PlainDist1D> MinkowskiDistP1;
 typedef BaseMinkowskiDistP2<PlainDist1D> NonOptimizedMinkowskiDistP2;
 
+/*
+ * Measuring distances
+ * ===================
+ */
+inline double
+sqeuclidean_distance_double(const double *u, const double *v, ckdtree_intp_t n)
+{
+    double s;
+    ckdtree_intp_t i;
+    // manually unrolled loop, might be vectorized
+    double acc[4] = {0., 0., 0., 0.};
+    for (i = 0; i < n/4; i += 4) {
+        double _u[4] = {u[i], u[i + 1], u[i + 2], u[i + 3]};
+        double _v[4] = {v[i], v[i + 1], v[i + 2], v[i + 3]};
+        double diff[4] = {_u[0] - _v[0],
+                               _u[1] - _v[1],
+                               _u[2] - _v[2],
+                               _u[3] - _v[3]};
+        acc[0] += diff[0] * diff[0];
+        acc[1] += diff[1] * diff[1];
+        acc[2] += diff[2] * diff[2];
+        acc[3] += diff[3] * diff[3];
+    }
+    s = acc[0] + acc[1] + acc[2] + acc[3];
+    if (i < n) {
+        for(; i<n; ++i) {
+            double d = u[i] - v[i];
+            s += d * d;
+        }
+    }
+    return s;
+}
+
+
 struct MinkowskiDistP2: NonOptimizedMinkowskiDistP2 {
-    static inline npy_float64
+    static inline double
     point_point_p(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-               const npy_float64 p, const npy_intp k,
-               const npy_float64 upperbound)
+               const double *x, const double *y,
+               const double p, const ckdtree_intp_t k,
+               const double upperbound)
     {
         return sqeuclidean_distance_double(x, y, k);
     }
@@ -61,9 +95,9 @@ struct MinkowskiDistP2: NonOptimizedMinkowskiDistP2 {
 
 struct BoxDist1D {
     static inline void _interval_interval_1d (
-        npy_float64 min, npy_float64 max,
-        npy_float64 *realmin, npy_float64 *realmax,
-        const npy_float64 full, const npy_float64 half
+        double min, double max,
+        double *realmin, double *realmax,
+        const double full, const double half
     )
     {
         /* Minimum and maximum distance of two intervals in a periodic box
@@ -83,13 +117,13 @@ struct BoxDist1D {
          *
          * We will fix the convention later.
          * */
-        if (NPY_UNLIKELY(full <= 0)) {
+        if (CKDTREE_UNLIKELY(full <= 0)) {
             /* A non-periodic dimension */
             /* \/     */
             if(max <= 0 || min >= 0) {
                 /* do not pass though 0 */
-                min = dabs(min);
-                max = dabs(max);
+                min = ckdtree_fabs(min);
+                max = ckdtree_fabs(max);
                 if(min < max) {
                     *realmin = min;
                     *realmax = max;
@@ -98,9 +132,9 @@ struct BoxDist1D {
                     *realmax = min;
                 }
             } else {
-                min = dabs(min);
-                max = dabs(max);
-                *realmax = fmax(max, min);
+                min = ckdtree_fabs(min);
+                max = ckdtree_fabs(max);
+                *realmax = ckdtree_fmax(max, min);
                 *realmin = 0;
             }
             /* done with non-periodic dimension */
@@ -108,8 +142,8 @@ struct BoxDist1D {
         }
         if(max <= 0 || min >= 0) {
             /* do not pass through 0 */
-            min = dabs(min);
-            max = dabs(max);
+            min = ckdtree_fabs(min);
+            max = ckdtree_fabs(max);
             if(min > max) {
                 double t = min;
                 min = max;
@@ -126,7 +160,7 @@ struct BoxDist1D {
             } else {
                 /* min below, max above */
                 *realmax = half;
-                *realmin = dmin(min, full - max);
+                *realmin = ckdtree_fmin(min, full - max);
             }
         } else {
             /* pass though 0 */
@@ -140,8 +174,8 @@ struct BoxDist1D {
     static inline void
     interval_interval(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_intp k,
-                        npy_float64 *min, npy_float64 *max)
+                        const ckdtree_intp_t k,
+                        double *min, double *max)
     {
         /* Compute the minimum/maximum distance along dimension k between points in
          * two hyperrectangles.
@@ -151,39 +185,39 @@ struct BoxDist1D {
                     tree->raw_boxsize_data[k], tree->raw_boxsize_data[k + rect1.m]);
     }
 
-    static inline npy_float64
+    static inline double
     point_point(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-               const npy_intp k)
+               const double *x, const double *y,
+               const ckdtree_intp_t k)
     {
-        npy_float64 r1;
+        double r1;
         r1 = wrap_distance(x[k] - y[k], tree->raw_boxsize_data[k + tree->m], tree->raw_boxsize_data[k]);
-        r1 = dabs(r1);
+        r1 = ckdtree_fabs(r1);
         return r1;
     }
 
-    static inline const npy_float64
-    wrap_position(const npy_float64 x, const npy_float64 boxsize)
+    static inline const double
+    wrap_position(const double x, const double boxsize)
     {
         if (boxsize <= 0) return x;
-        const npy_float64 r = std::floor(x / boxsize);
-        npy_float64 x1 = x - r * boxsize;
+        const double r = std::floor(x / boxsize);
+        double x1 = x - r * boxsize;
         /* ensure result is within the box. */
         while(x1 >= boxsize) x1 -= boxsize;
         while(x1 < 0) x1 += boxsize;
         return x1;
     }
 
-    static inline const npy_float64 side_distance_from_min_max(
-        const ckdtree * tree, const npy_float64 x,
-        const npy_float64 min,
-        const npy_float64 max,
-        const npy_intp k
+    static inline const double side_distance_from_min_max(
+        const ckdtree * tree, const double x,
+        const double min,
+        const double max,
+        const ckdtree_intp_t k
         )
     {
-        npy_float64 s, t, tmin, tmax;
-        npy_float64 fb = tree->raw_boxsize_data[k];
-        npy_float64 hb = tree->raw_boxsize_data[k + tree->m];
+        double s, t, tmin, tmax;
+        double fb = tree->raw_boxsize_data[k];
+        double hb = tree->raw_boxsize_data[k + tree->m];
 
         if (fb <= 0) {
             /* non-periodic dimension */
@@ -196,14 +230,14 @@ struct BoxDist1D {
         tmax = x - max;
         tmin = x - min;
         /* is the test point in this range */
-        if(NPY_LIKELY(tmax < 0 && tmin > 0)) {
+        if(CKDTREE_LIKELY(tmax < 0 && tmin > 0)) {
             /* yes. min distance is 0 */
             return 0;
         }
 
         /* no */
-        tmax = dabs(tmax);
-        tmin = dabs(tmin);
+        tmax = ckdtree_fabs(tmax);
+        tmin = ckdtree_fabs(tmin);
 
         /* make tmin the closer edge */
         if(tmin > tmax) { t = tmin; tmin = tmax; tmax = t; }
@@ -224,15 +258,15 @@ struct BoxDist1D {
     }
 
     private:
-    static inline npy_float64
-    wrap_distance(const npy_float64 x, const npy_float64 hb, const npy_float64 fb)
+    static inline double
+    wrap_distance(const double x, const double hb, const double fb)
     {
-        npy_float64 x1;
-        if (NPY_UNLIKELY(x < -hb)) x1 = fb + x;
-        else if (NPY_UNLIKELY(x > hb)) x1 = x - fb;
+        double x1;
+        if (CKDTREE_UNLIKELY(x < -hb)) x1 = fb + x;
+        else if (CKDTREE_UNLIKELY(x > hb)) x1 = x - fb;
         else x1 = x;
     #if 0
-        printf(""dabs_b x : %g x1 %g\n"", x, x1);
+        printf(""ckdtree_fabs_b x : %g x1 %g\n"", x, x1);
     #endif
         return x1;
     }
diff --git a/scipy/spatial/ckdtree/src/distance_base.h b/scipy/spatial/ckdtree/src/distance_base.h
index c88e05b5dd60..9321a2931fed 100644
--- a/scipy/spatial/ckdtree/src/distance_base.h
+++ b/scipy/spatial/ckdtree/src/distance_base.h
@@ -7,8 +7,8 @@ struct BaseMinkowskiDistPp {
     static inline void
     interval_interval_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_intp k, const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const ckdtree_intp_t k, const double p,
+                        double *min, double *max)
     {
         /* Compute the minimum/maximum distance along dimension k between points in
          * two hyperrectangles.
@@ -21,13 +21,13 @@ struct BaseMinkowskiDistPp {
     static inline void
     rect_rect_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const double p,
+                        double *min, double *max)
     {
         *min = 0.;
         *max = 0.;
-        for(npy_intp i=0; i<rect1.m; ++i) {
-            npy_float64 min_, max_;
+        for(ckdtree_intp_t i=0; i<rect1.m; ++i) {
+            double min_, max_;
 
             Dist1D::interval_interval(tree, rect1, rect2, i, &min_, &max_);
 
@@ -36,11 +36,11 @@ struct BaseMinkowskiDistPp {
         }
     }
 
-    static inline npy_float64
+    static inline double
     point_point_p(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-               const npy_float64 p, const npy_intp k,
-               const npy_float64 upperbound)
+               const double *x, const double *y,
+               const double p, const ckdtree_intp_t k,
+               const double upperbound)
     {
        /*
         * Compute the distance between x and y
@@ -50,8 +50,8 @@ struct BaseMinkowskiDistPp {
         * than upperbound may be returned (the calculation is truncated).
         */
 
-        npy_intp i;
-        npy_float64 r, r1;
+        ckdtree_intp_t i;
+        double r, r1;
         r = 0;
         for (i=0; i<k; ++i) {
             r1 = Dist1D::point_point(tree, x, y, i);
@@ -62,8 +62,8 @@ struct BaseMinkowskiDistPp {
         return r;
     }
 
-    static inline npy_float64
-    distance_p(const npy_float64 s, const npy_float64 p)
+    static inline double
+    distance_p(const double s, const double p)
     {
         return std::pow(s,p);
     }
@@ -75,8 +75,8 @@ struct BaseMinkowskiDistP1 : public BaseMinkowskiDistPp<Dist1D> {
     static inline void
     interval_interval_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_intp k, const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const ckdtree_intp_t k, const double p,
+                        double *min, double *max)
     {
         /* Compute the minimum/maximum distance along dimension k between points in
          * two hyperrectangles.
@@ -87,13 +87,13 @@ struct BaseMinkowskiDistP1 : public BaseMinkowskiDistPp<Dist1D> {
     static inline void
     rect_rect_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const double p,
+                        double *min, double *max)
     {
         *min = 0.;
         *max = 0.;
-        for(npy_intp i=0; i<rect1.m; ++i) {
-            npy_float64 min_, max_;
+        for(ckdtree_intp_t i=0; i<rect1.m; ++i) {
+            double min_, max_;
 
             Dist1D::interval_interval(tree, rect1, rect2, i, &min_, &max_);
 
@@ -102,14 +102,14 @@ struct BaseMinkowskiDistP1 : public BaseMinkowskiDistPp<Dist1D> {
         }
     }
 
-    static inline npy_float64
+    static inline double
     point_point_p(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-               const npy_float64 p, const npy_intp k,
-               const npy_float64 upperbound)
+               const double *x, const double *y,
+               const double p, const ckdtree_intp_t k,
+               const double upperbound)
     {
-        npy_intp i;
-        npy_float64 r;
+        ckdtree_intp_t i;
+        double r;
         r = 0;
         for (i=0; i<k; ++i) {
             r += Dist1D::point_point(tree, x, y, i);
@@ -119,8 +119,8 @@ struct BaseMinkowskiDistP1 : public BaseMinkowskiDistPp<Dist1D> {
         return r;
     }
 
-    static inline npy_float64
-    distance_p(const npy_float64 s, const npy_float64 p)
+    static inline double
+    distance_p(const double s, const double p)
     {
         return s;
     }
@@ -131,8 +131,8 @@ struct BaseMinkowskiDistPinf : public BaseMinkowskiDistPp<Dist1D> {
     static inline void
     interval_interval_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_intp k, npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const ckdtree_intp_t k, double p,
+                        double *min, double *max)
     {
         return rect_rect_p(tree, rect1, rect2, p, min, max);
     }
@@ -140,39 +140,39 @@ struct BaseMinkowskiDistPinf : public BaseMinkowskiDistPp<Dist1D> {
     static inline void
     rect_rect_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const double p,
+                        double *min, double *max)
     {
         *min = 0.;
         *max = 0.;
-        for(npy_intp i=0; i<rect1.m; ++i) {
-            npy_float64 min_, max_;
+        for(ckdtree_intp_t i=0; i<rect1.m; ++i) {
+            double min_, max_;
 
             Dist1D::interval_interval(tree, rect1, rect2, i, &min_, &max_);
 
-            *min = dmax(*min, min_);
-            *max = dmax(*max, max_);
+            *min = ckdtree_fmax(*min, min_);
+            *max = ckdtree_fmax(*max, max_);
         }
     }
 
-    static inline npy_float64
+    static inline double
     point_point_p(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-               const npy_float64 p, const npy_intp k,
-               const npy_float64 upperbound)
+               const double *x, const double *y,
+               const double p, const ckdtree_intp_t k,
+               const double upperbound)
     {
-        npy_intp i;
-        npy_float64 r;
+        ckdtree_intp_t i;
+        double r;
         r = 0;
         for (i=0; i<k; ++i) {
-            r = dmax(r,Dist1D::point_point(tree, x, y, i));
+            r = ckdtree_fmax(r,Dist1D::point_point(tree, x, y, i));
             if (r>upperbound)
                 return r;
         }
         return r;
     }
-    static inline npy_float64
-    distance_p(const npy_float64 s, const npy_float64 p)
+    static inline double
+    distance_p(const double s, const double p)
     {
         return s;
     }
@@ -183,8 +183,8 @@ struct BaseMinkowskiDistP2 : public BaseMinkowskiDistPp<Dist1D> {
     static inline void
     interval_interval_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_intp k, const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const ckdtree_intp_t k, const double p,
+                        double *min, double *max)
     {
         /* Compute the minimum/maximum distance along dimension k between points in
          * two hyperrectangles.
@@ -197,13 +197,13 @@ struct BaseMinkowskiDistP2 : public BaseMinkowskiDistPp<Dist1D> {
     static inline void
     rect_rect_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const double p,
+                        double *min, double *max)
     {
         *min = 0.;
         *max = 0.;
-        for(npy_intp i=0; i<rect1.m; ++i) {
-            npy_float64 min_, max_;
+        for(ckdtree_intp_t i=0; i<rect1.m; ++i) {
+            double min_, max_;
 
             Dist1D::interval_interval(tree, rect1, rect2, i, &min_, &max_);
             min_ *= min_;
@@ -213,26 +213,26 @@ struct BaseMinkowskiDistP2 : public BaseMinkowskiDistPp<Dist1D> {
             *max += max_;
         }
     }
-    static inline npy_float64
+    static inline double
 
     point_point_p(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-               const npy_float64 p, const npy_intp k,
-               const npy_float64 upperbound)
+               const double *x, const double *y,
+               const double p, const ckdtree_intp_t k,
+               const double upperbound)
     {
-        npy_intp i;
-        npy_float64 r;
+        ckdtree_intp_t i;
+        double r;
         r = 0;
         for (i=0; i<k; ++i) {
-            npy_float64 r1 = Dist1D::point_point(tree, x, y, i);
+            double r1 = Dist1D::point_point(tree, x, y, i);
             r += r1 * r1;
             if (r>upperbound)
                 return r;
         }
         return r;
     }
-    static inline npy_float64
-    distance_p(const npy_float64 s, const npy_float64 p)
+    static inline double
+    distance_p(const double s, const double p)
     {
         return s * s;
     }
diff --git a/scipy/spatial/ckdtree/src/globals.cxx b/scipy/spatial/ckdtree/src/globals.cxx
deleted file mode 100644
index 690ea42b2de9..000000000000
--- a/scipy/spatial/ckdtree/src/globals.cxx
+++ /dev/null
@@ -1 +0,0 @@
-int number_of_processors;
diff --git a/scipy/spatial/ckdtree/src/ordered_pair.h b/scipy/spatial/ckdtree/src/ordered_pair.h
index f6b90607e12a..353d59088829 100644
--- a/scipy/spatial/ckdtree/src/ordered_pair.h
+++ b/scipy/spatial/ckdtree/src/ordered_pair.h
@@ -3,13 +3,13 @@
 #define CKDTREE_ORDERED_PAIR
 
 struct ordered_pair {
-    npy_intp i;
-    npy_intp j;
+    ckdtree_intp_t i;
+    ckdtree_intp_t j;
 };
 
 inline void
 add_ordered_pair(std::vector<ordered_pair> *results,
-                       const npy_intp i, const npy_intp j)
+                       const ckdtree_intp_t i, const intptr_t j)
 {
     if (i > j) {
         ordered_pair p = {j,i};
diff --git a/scipy/spatial/ckdtree/src/partial_sort.h b/scipy/spatial/ckdtree/src/partial_sort.h
index 155b04c6affa..502dc7ef4eef 100644
--- a/scipy/spatial/ckdtree/src/partial_sort.h
+++ b/scipy/spatial/ckdtree/src/partial_sort.h
@@ -2,30 +2,27 @@
 #ifndef CKDTREE_PARTIAL_SORT
 #define CKDTREE_PARTIAL_SORT
 
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 /* Splitting routines for a balanced kd-tree
  * Code originally written by Jake Vanderplas for scikit-learn
  *
  */
 
 inline void
-index_swap(npy_intp *arr, npy_intp i1, npy_intp i2)
+index_swap(ckdtree_intp_t *arr, intptr_t i1, intptr_t i2)
 {
     /* swap the values at index i1 and i2 of arr */
-    npy_intp tmp = arr[i1];
+    ckdtree_intp_t tmp = arr[i1];
     arr[i1] = arr[i2];
     arr[i2] = tmp;
 }
 
 static void
-partition_node_indices(const npy_float64 *data,
-                       npy_intp *node_indices,
-                       npy_intp split_dim,
-                       npy_intp split_index,
-                       npy_intp n_features,
-                       npy_intp n_points)
+partition_node_indices(const double *data,
+                       ckdtree_intp_t *node_indices,
+                       ckdtree_intp_t split_dim,
+                       ckdtree_intp_t split_index,
+                       ckdtree_intp_t n_features,
+                       ckdtree_intp_t n_points)
 {
     /* Partition points in the node into two equal-sized groups
      * Upon return, the values in node_indices will be rearranged such that
@@ -64,8 +61,8 @@ partition_node_indices(const npy_float64 *data,
      *    modified as noted above.
      */
 
-    npy_intp left, right, midindex, i;
-    npy_float64 d1, d2;
+    ckdtree_intp_t left, right, midindex, i;
+    double d1, d2;
     left = 0;
     right = n_points - 1;
     for(;;) {
diff --git a/scipy/spatial/ckdtree/src/query.cxx b/scipy/spatial/ckdtree/src/query.cxx
index 582e9fcd548a..5595826b6580 100644
--- a/scipy/spatial/ckdtree/src/query.cxx
+++ b/scipy/spatial/ckdtree/src/query.cxx
@@ -1,13 +1,3 @@
-/*
- * This would break SciPy with NumPy 1.6 so just accept the compiler
- * warning for now.
- * #define NPY_NO_DEPRECATED_API NPY_1_9_API_VERSION
- *
- */
-
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -20,12 +10,9 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
 #include ""ordered_pair.h""
-#include ""ckdtree_methods.h""
 #include ""rectangle.h""
-#include ""cpp_exc.h""
 
 /*
  * Priority queue
@@ -33,28 +20,28 @@
  */
 
 union heapcontents {
-    npy_intp intdata;
+    ckdtree_intp_t intdata;
     void     *ptrdata;
 };
 
 struct heapitem {
-    npy_float64 priority;
+    double priority;
     heapcontents contents;
 };
 
 struct heap {
 
     std::vector<heapitem> _heap;
-    npy_intp n;
-    npy_intp space;
+    ckdtree_intp_t n;
+    ckdtree_intp_t space;
 
-    heap (npy_intp initial_size) : _heap(initial_size) {
+    heap (ckdtree_intp_t initial_size) : _heap(initial_size) {
         space = initial_size;
         n = 0;
     }
 
     inline void push(heapitem &item) {
-        npy_intp i;
+        ckdtree_intp_t i;
         heapitem t;
         n++;
 
@@ -75,7 +62,7 @@ struct heap {
 
     inline void remove() {
         heapitem t;
-        npy_intp i, j, k, l, nn;
+        ckdtree_intp_t i, j, k, l, nn;
         _heap[0] = _heap[n-1];
         n--;
         /*
@@ -118,36 +105,36 @@ struct heap {
 
 struct nodeinfo {
     const ckdtreenode  *node;
-    npy_intp     m;
-    npy_float64  min_distance; /* full min distance */
-    npy_float64        buf[1]; // the good old struct hack
+    ckdtree_intp_t     m;
+    double  min_distance; /* full min distance */
+    double        buf[1]; // the good old struct hack
     /* accessors to 'packed' attributes */
-    inline npy_float64        * const side_distances() {
+    inline double        * const side_distances() {
         /* min distance to the query per side; we
          * update this as the query is proceeded */
         return buf;
     }
-    inline npy_float64        * const maxes() {
+    inline double        * const maxes() {
         return buf + m;
     }
-    inline npy_float64        * const mins() {
+    inline double        * const mins() {
         return buf + 2 * m;
     }
 
     inline void init_box(const struct nodeinfo * from) {
-        std::memcpy(buf, from->buf, sizeof(npy_float64) * (3 * m));
+        std::memcpy(buf, from->buf, sizeof(double) * (3 * m));
         min_distance = from->min_distance;
     }
 
     inline void init_plain(const struct nodeinfo * from) {
         /* skip copying min and max, because we only need side_distance array in this case. */
-        std::memcpy(buf, from->buf, sizeof(npy_float64) * m);
+        std::memcpy(buf, from->buf, sizeof(double) * m);
         min_distance = from->min_distance;
     }
 
-    inline void update_side_distance(const int d, const npy_float64 new_side_distance, const npy_float64 p) {
-        if (NPY_UNLIKELY(ckdtree_isinf(p))) {
-            min_distance = dmax(min_distance, new_side_distance);
+    inline void update_side_distance(const int d, const double new_side_distance, const double p) {
+        if (CKDTREE_UNLIKELY(ckdtree_isinf(p))) {
+            min_distance = ckdtree_fmax(min_distance, new_side_distance);
         } else {
             min_distance += new_side_distance - side_distances()[d];
         }
@@ -164,14 +151,14 @@ struct nodeinfo_pool {
 
     std::vector<char*> pool;
 
-    npy_intp alloc_size;
-    npy_intp arena_size;
-    npy_intp m;
+    ckdtree_intp_t alloc_size;
+    ckdtree_intp_t arena_size;
+    ckdtree_intp_t m;
     char *arena;
     char *arena_ptr;
 
-    nodeinfo_pool(npy_intp m) {
-        alloc_size = sizeof(nodeinfo) + (3 * m -1)*sizeof(npy_float64);
+    nodeinfo_pool(ckdtree_intp_t m) {
+        alloc_size = sizeof(nodeinfo) + (3 * m -1)*sizeof(double);
         alloc_size = 64*(alloc_size/64)+64;
         arena_size = 4096*((64*alloc_size)/4096)+4096;
         arena = new char[arena_size];
@@ -181,15 +168,15 @@ struct nodeinfo_pool {
     }
 
     ~nodeinfo_pool() {
-        for (npy_intp i = pool.size()-1; i >= 0; --i)
+        for (ckdtree_intp_t i = pool.size()-1; i >= 0; --i)
             delete [] pool[i];
     }
 
     inline nodeinfo *allocate() {
         nodeinfo *ni1;
-        npy_uintp m1 = (npy_uintp)arena_ptr;
-        npy_uintp m0 = (npy_uintp)arena;
-        if ((arena_size-(npy_intp)(m1-m0))<alloc_size) {
+        ckdtree_intp_t m1 = (ckdtree_intp_t)arena_ptr;
+        ckdtree_intp_t m0 = (ckdtree_intp_t)arena;
+        if ((arena_size-(ckdtree_intp_t)(m1-m0))<alloc_size) {
             arena = new char[arena_size];
             arena_ptr = arena;
             pool.push_back(arena);
@@ -205,16 +192,18 @@ struct nodeinfo_pool {
 template <typename MinMaxDist>
 static void
 query_single_point(const ckdtree *self,
-                   npy_float64   *result_distances,
-                   npy_intp      *result_indices,
-                   const npy_float64  *x,
-                   const npy_intp     *k,
-                   const npy_intp     nk,
-                   const npy_intp     kmax,
-                   const npy_float64  eps,
-                   const npy_float64  p,
-                   npy_float64  distance_upper_bound)
+                   double   *result_distances,
+                   ckdtree_intp_t      *result_indices,
+                   const double  *x,
+                   const ckdtree_intp_t     *k,
+                   const ckdtree_intp_t     nk,
+                   const ckdtree_intp_t     kmax,
+                   const double  eps,
+                   const double  p,
+                   double  distance_upper_bound)
 {
+    static double inf = strtod(""INF"", NULL);
+
     /* memory pool to allocate and automatically reclaim nodeinfo structs */
     nodeinfo_pool nipool(self->m);
 
@@ -236,12 +225,12 @@ query_single_point(const ckdtree *self,
      */
     heap neighbors(kmax);
 
-    npy_intp      i;
-    const npy_intp m = self->m;
+    ckdtree_intp_t      i;
+    const ckdtree_intp_t m = self->m;
     nodeinfo      *ni1;
     nodeinfo      *ni2;
-    npy_float64   d;
-    npy_float64   epsfac;
+    double   d;
+    double   epsfac;
     heapitem      it, it2, neighbor;
     const ckdtreenode   *node;
     const ckdtreenode   *inode;
@@ -257,7 +246,7 @@ query_single_point(const ckdtree *self,
         ni1->mins()[i] = self->raw_mins[i];
         ni1->maxes()[i] = self->raw_maxes[i];
 
-        npy_float64 side_distance;
+        double side_distance;
         if(self->raw_boxsize_data != NULL) {
             side_distance = BoxDist1D::side_distance_from_min_max(
                 self, x[i], self->raw_mins[i], self->raw_maxes[i], i);
@@ -272,8 +261,8 @@ query_single_point(const ckdtree *self,
     }
 
     /* fiddle approximation factor */
-    if (NPY_LIKELY(p == 2.0)) {
-        npy_float64 tmp = 1. + eps;
+    if (CKDTREE_LIKELY(p == 2.0)) {
+        double tmp = 1. + eps;
         epsfac = 1. / (tmp*tmp);
     }
     else if (eps == 0.)
@@ -284,11 +273,11 @@ query_single_point(const ckdtree *self,
         epsfac = 1. / std::pow((1. + eps), p);
 
     /* internally we represent all distances as distance**p */
-    if (NPY_LIKELY(p == 2.0)) {
-        npy_float64 tmp = distance_upper_bound;
+    if (CKDTREE_LIKELY(p == 2.0)) {
+        double tmp = distance_upper_bound;
         distance_upper_bound = tmp*tmp;
     }
-    else if ((!ckdtree_isinf(p)) && (!ckdtree_isinf(distance_upper_bound)))
+    else if ((!ckdtree_isinf(p)) && (!isinf(distance_upper_bound)))
         distance_upper_bound = std::pow(distance_upper_bound,p);
 
     for(;;) {
@@ -298,19 +287,19 @@ query_single_point(const ckdtree *self,
 
             /* brute-force */
             {
-                const npy_intp start_idx = node->start_idx;
-                const npy_intp end_idx = node->end_idx;
-                const npy_float64 *data = self->raw_data;
-                const npy_intp *indices = self->raw_indices;
+                const ckdtree_intp_t start_idx = node->start_idx;
+                const ckdtree_intp_t end_idx = node->end_idx;
+                const double *data = self->raw_data;
+                const ckdtree_intp_t *indices = self->raw_indices;
 
-                prefetch_datapoint(data+indices[start_idx]*m, m);
+                CKDTREE_PREFETCH(data+indices[start_idx]*m, 0, m);
                 if (start_idx < end_idx - 1)
-                    prefetch_datapoint(data+indices[start_idx+1]*m, m);
+                    CKDTREE_PREFETCH(data+indices[start_idx+1]*m, 0, m);
 
                 for (i=start_idx; i<end_idx; ++i) {
 
                     if (i < end_idx - 2)
-                        prefetch_datapoint(data+indices[i+2]*m, m);
+                        CKDTREE_PREFETCH(data+indices[i+2]*m, 0, m);
 
                     d = MinMaxDist::point_point_p(self, data+indices[i]*m, x, p, m, distance_upper_bound);
                     if (d < distance_upper_bound) {
@@ -340,8 +329,8 @@ query_single_point(const ckdtree *self,
         }
         else {
             inode = ni1->node;
-            const npy_intp split_dim = inode->split_dim;
-            const npy_float64 split = inode->split;
+            const ckdtree_intp_t split_dim = inode->split_dim;
+            const double split = inode->split;
 
             /*
              * we don't push cells that are too far onto the queue at all,
@@ -357,7 +346,7 @@ query_single_point(const ckdtree *self,
 
             ni2 = nipool.allocate();
 
-            if (NPY_LIKELY(self->raw_boxsize_data == NULL)) {
+            if (CKDTREE_LIKELY(self->raw_boxsize_data == NULL)) {
                 /*
                  * non periodic : the 'near' node is know from the
                  * relative distance to the split, and
@@ -370,7 +359,7 @@ query_single_point(const ckdtree *self,
                  */
                 ni2->init_plain(ni1);
 
-                npy_float64 side_distance;
+                double side_distance;
 
                 if (x[split_dim] < split) {
                     ni1->node = inode->less;
@@ -394,7 +383,7 @@ query_single_point(const ckdtree *self,
                  */
                 ni2->init_box(ni1);
 
-                npy_float64 side_distance;
+                double side_distance;
 
                 ni1->maxes()[split_dim] = split;
                 ni1->node = inode->less;
@@ -453,20 +442,20 @@ query_single_point(const ckdtree *self,
 
     /* heapsort */
     std::vector<heapitem> sorted_neighbors(kmax);
-    npy_intp nnb = neighbors.n;
+    ckdtree_intp_t nnb = neighbors.n;
     for(i = neighbors.n - 1; i >=0; --i) {
         sorted_neighbors[i] = neighbors.pop();
     }
 
     /* fill output arrays with sorted neighbors */
     for (i = 0; i < nk; ++i) {
-        if(NPY_UNLIKELY(k[i] - 1 >= nnb)) {
+        if(CKDTREE_UNLIKELY(k[i] - 1 >= nnb)) {
             result_indices[i] = self->n;
-            result_distances[i] = NPY_INFINITY;
+            result_distances[i] = inf;
         } else {
             neighbor = sorted_neighbors[k[i] - 1];
             result_indices[i] = neighbor.contents.intdata;
-            if (NPY_LIKELY(p == 2.0))
+            if (CKDTREE_LIKELY(p == 2.0))
                 result_distances[i] = std::sqrt(-neighbor.priority);
             else if ((p == 1.) || (ckdtree_isinf(p)))
                 result_distances[i] = -neighbor.priority;
@@ -478,74 +467,56 @@ query_single_point(const ckdtree *self,
 
 /* Query n points for their k nearest neighbors */
 
-extern ""C"" PyObject*
+int
 query_knn(const ckdtree      *self,
-          npy_float64        *dd,
-          npy_intp           *ii,
-          const npy_float64  *xx,
-          const npy_intp     n,
-          const npy_intp*     k,
-          const npy_intp     nk,
-          const npy_intp     kmax,
-          const npy_float64  eps,
-          const npy_float64  p,
-          const npy_float64  distance_upper_bound)
+          double        *dd,
+          ckdtree_intp_t           *ii,
+          const double  *xx,
+          const ckdtree_intp_t     n,
+          const ckdtree_intp_t*     k,
+          const ckdtree_intp_t     nk,
+          const ckdtree_intp_t     kmax,
+          const double  eps,
+          const double  p,
+          const double  distance_upper_bound)
 {
 #define HANDLE(cond, kls) \
     if(cond) { \
         query_single_point<kls>(self, dd_row, ii_row, xx_row, k, nk, kmax, eps, p, distance_upper_bound); \
     } else
 
-    npy_intp m = self->m;
-    npy_intp i;
-
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            if(NPY_LIKELY(!self->raw_boxsize_data)) {
-                for (i=0; i<n; ++i) {
-                    npy_float64 *dd_row = dd + (i*nk);
-                    npy_intp *ii_row = ii + (i*nk);
-                    const npy_float64 *xx_row = xx + (i*m);
-                    HANDLE(NPY_LIKELY(p == 2), MinkowskiDistP2)
-                    HANDLE(p == 1, MinkowskiDistP1)
-                    HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
-                    HANDLE(1, MinkowskiDistPp)
-                    {}
-                }
-            } else {
-                std::vector<npy_float64> row(m);
-                npy_float64 * xx_row = &row[0];
-                int j;
-                for (i=0; i<n; ++i) {
-                    npy_float64 *dd_row = dd + (i*nk);
-                    npy_intp *ii_row = ii + (i*nk);
-                    const npy_float64 *old_xx_row = xx + (i*m);
-                    for(j=0; j<m; ++j) {
-                        xx_row[j] = BoxDist1D::wrap_position(old_xx_row[j], self->raw_boxsize_data[j]);
-                    }
-                    HANDLE(NPY_LIKELY(p == 2), BoxMinkowskiDistP2)
-                    HANDLE(p == 1, BoxMinkowskiDistP1)
-                    HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
-                    HANDLE(1, BoxMinkowskiDistPp) {}
-                }
-
-            }
+    ckdtree_intp_t m = self->m;
+    ckdtree_intp_t i;
+
+    if(CKDTREE_LIKELY(!self->raw_boxsize_data)) {
+        for (i=0; i<n; ++i) {
+            double *dd_row = dd + (i*nk);
+            ckdtree_intp_t *ii_row = ii + (i*nk);
+            const double *xx_row = xx + (i*m);
+            HANDLE(CKDTREE_LIKELY(p == 2), MinkowskiDistP2)
+            HANDLE(p == 1, MinkowskiDistP1)
+            HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
+            HANDLE(1, MinkowskiDistPp)
+            {}
         }
-        catch(...) {
-            translate_cpp_exception_with_gil();
+    } else {
+        std::vector<double> row(m);
+        double * xx_row = &row[0];
+        int j;
+        for (i=0; i<n; ++i) {
+            double *dd_row = dd + (i*nk);
+            ckdtree_intp_t *ii_row = ii + (i*nk);
+            const double *old_xx_row = xx + (i*m);
+            for(j=0; j<m; ++j) {
+                xx_row[j] = BoxDist1D::wrap_position(old_xx_row[j], self->raw_boxsize_data[j]);
+            }
+            HANDLE(CKDTREE_LIKELY(p == 2), BoxMinkowskiDistP2)
+            HANDLE(p == 1, BoxMinkowskiDistP1)
+            HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
+            HANDLE(1, BoxMinkowskiDistPp) {}
         }
+
     }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
-    }
+    return 0;
 }
 
diff --git a/scipy/spatial/ckdtree/src/query_ball_point.cxx b/scipy/spatial/ckdtree/src/query_ball_point.cxx
index d48f058e4610..551d3bed052d 100644
--- a/scipy/spatial/ckdtree/src/query_ball_point.cxx
+++ b/scipy/spatial/ckdtree/src/query_ball_point.cxx
@@ -1,6 +1,3 @@
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -13,145 +10,136 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
-#include ""ckdtree_methods.h""
-#include ""cpp_exc.h""
 #include ""rectangle.h""
 
 
 static void
 traverse_no_checking(const ckdtree *self,
-                     std::vector<npy_intp> *results,
+                     const int return_length,
+                     std::vector<ckdtree_intp_t> *results,
                      const ckdtreenode *node)
 {
-    const npy_intp *indices = self->raw_indices;
+    const ckdtree_intp_t *indices = self->raw_indices;
     const ckdtreenode *lnode;
-    npy_intp i;
+    ckdtree_intp_t i;
 
     if (node->split_dim == -1) {  /* leaf node */
         lnode = node;
-        const npy_intp start = lnode->start_idx;
-        const npy_intp end = lnode->end_idx;
+        const ckdtree_intp_t start = lnode->start_idx;
+        const ckdtree_intp_t end = lnode->end_idx;
         for (i = start; i < end; ++i) {
-            results->push_back(indices[i]);
+            if (return_length) {
+                (*results)[0] ++;
+            } else {
+                results->push_back(indices[i]);
+            }
         }
     }
     else {
-        traverse_no_checking(self, results, node->less);
-        traverse_no_checking(self, results, node->greater);
+        traverse_no_checking(self, return_length, results, node->less);
+        traverse_no_checking(self, return_length, results, node->greater);
     }
 }
 
 
 template <typename MinMaxDist> static void
 traverse_checking(const ckdtree *self,
-                  std::vector<npy_intp> *results,
+                  const int return_length,
+                  std::vector<ckdtree_intp_t> *results,
                   const ckdtreenode *node,
-                  RectRectDistanceTracker<MinMaxDist> *tracker)
+                  RectRectDistanceTracker<MinMaxDist> *tracker
+)
 {
     const ckdtreenode *lnode;
-    npy_float64 d;
-    npy_intp i;
+    double d;
+    ckdtree_intp_t i;
 
     if (tracker->min_distance > tracker->upper_bound * tracker->epsfac) {
         return;
     }
     else if (tracker->max_distance < tracker->upper_bound / tracker->epsfac) {
-        traverse_no_checking(self, results, node);
+        traverse_no_checking(self, return_length, results, node);
     }
     else if (node->split_dim == -1)  { /* leaf node */
 
         /* brute-force */
         lnode = node;
-        const npy_float64 p = tracker->p;
-        const npy_float64 tub = tracker->upper_bound;
-        const npy_float64 *tpt = tracker->rect1.mins();
-        const npy_float64 *data = self->raw_data;
-        const npy_intp *indices = self->raw_indices;
-        const npy_intp m = self->m;
-        const npy_intp start = lnode->start_idx;
-        const npy_intp end = lnode->end_idx;
-
-        prefetch_datapoint(data + indices[start] * m, m);
+        const double p = tracker->p;
+        const double tub = tracker->upper_bound;
+        const double *tpt = tracker->rect1.mins();
+        const double *data = self->raw_data;
+        const ckdtree_intp_t *indices = self->raw_indices;
+        const ckdtree_intp_t m = self->m;
+        const ckdtree_intp_t start = lnode->start_idx;
+        const ckdtree_intp_t end = lnode->end_idx;
+
+        CKDTREE_PREFETCH(data + indices[start] * m, 0, m);
         if (start < end - 1)
-            prefetch_datapoint(data + indices[start+1] * m, m);
+            CKDTREE_PREFETCH(data + indices[start+1] * m, 0, m);
 
         for (i = start; i < end; ++i) {
 
             if (i < end -2 )
-                prefetch_datapoint(data + indices[i+2] * m, m);
+                CKDTREE_PREFETCH(data + indices[i+2] * m, 0, m);
 
             d = MinMaxDist::point_point_p(self, data + indices[i] * m, tpt, p, m, tub);
 
             if (d <= tub) {
-                results->push_back((npy_intp) indices[i]);
+                if(return_length) {
+                    (*results)[0] ++;
+                } else {
+                    results->push_back((ckdtree_intp_t) indices[i]);
+                }
             }
         }
     }
     else {
         tracker->push_less_of(2, node);
-        traverse_checking(self, results, node->less, tracker);
+        traverse_checking(self, return_length, results, node->less, tracker);
         tracker->pop();
 
         tracker->push_greater_of(2, node);
-        traverse_checking(self, results, node->greater, tracker);
+        traverse_checking(self, return_length, results, node->greater, tracker);
         tracker->pop();
     }
 }
 
-
-extern ""C"" PyObject*
-query_ball_point(const ckdtree *self, const npy_float64 *x,
-                 const npy_float64 r, const npy_float64 p, const npy_float64 eps,
-                 const npy_intp n_queries, std::vector<npy_intp> **results)
+int
+query_ball_point(const ckdtree *self, const double *x,
+                 const double *r, const double p, const double eps,
+                 const ckdtree_intp_t n_queries,
+                 std::vector<ckdtree_intp_t> **results, const int return_length)
 {
 #define HANDLE(cond, kls) \
     if(cond) { \
-        RectRectDistanceTracker<kls> tracker(self, point, rect, p, eps, r); \
-        traverse_checking(self, results[i], self->ctree, &tracker); \
+        if(return_length) results[i]->push_back(0); \
+        RectRectDistanceTracker<kls> tracker(self, point, rect, p, eps, r[i]); \
+        traverse_checking(self, return_length, results[i], self->ctree, &tracker); \
     } else
 
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            for (npy_intp i=0; i < n_queries; ++i) {
-                const npy_intp m = self->m;
-                Rectangle rect(m, self->raw_mins, self->raw_maxes);
-                if (NPY_LIKELY(self->raw_boxsize_data == NULL)) {
-                    Rectangle point(m, x + i * m, x + i * m);
-                    HANDLE(NPY_LIKELY(p == 2), MinkowskiDistP2)
-                    HANDLE(p == 1, MinkowskiDistP1)
-                    HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
-                    HANDLE(1, MinkowskiDistPp)
-                    {}
-                } else {
-                    Rectangle point(m, x + i * m, x + i * m);
-                    int j;
-                    for(j=0; j<m; ++j) {
-                        point.maxes()[j] = point.mins()[j] = BoxDist1D::wrap_position(point.mins()[j], self->raw_boxsize_data[j]);
-                    }
-                    HANDLE(NPY_LIKELY(p == 2), BoxMinkowskiDistP2)
-                    HANDLE(p == 1, BoxMinkowskiDistP1)
-                    HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
-                    HANDLE(1, BoxMinkowskiDistPp)
-                    {}
-                }
+    for (ckdtree_intp_t i=0; i < n_queries; ++i) {
+        const ckdtree_intp_t m = self->m;
+        Rectangle rect(m, self->raw_mins, self->raw_maxes);
+        if (CKDTREE_LIKELY(self->raw_boxsize_data == NULL)) {
+            Rectangle point(m, x + i * m, x + i * m);
+            HANDLE(CKDTREE_LIKELY(p == 2), MinkowskiDistP2)
+            HANDLE(p == 1, MinkowskiDistP1)
+            HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
+            HANDLE(1, MinkowskiDistPp)
+            {}
+        } else {
+            Rectangle point(m, x + i * m, x + i * m);
+            int j;
+            for(j=0; j<m; ++j) {
+                point.maxes()[j] = point.mins()[j] = BoxDist1D::wrap_position(point.mins()[j], self->raw_boxsize_data[j]);
             }
+            HANDLE(CKDTREE_LIKELY(p == 2), BoxMinkowskiDistP2)
+            HANDLE(p == 1, BoxMinkowskiDistP1)
+            HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
+            HANDLE(1, BoxMinkowskiDistPp)
+            {}
         }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
     }
+    return 0;
 }
diff --git a/scipy/spatial/ckdtree/src/query_ball_tree.cxx b/scipy/spatial/ckdtree/src/query_ball_tree.cxx
index 8d3fc0102938..b71d257f5445 100644
--- a/scipy/spatial/ckdtree/src/query_ball_tree.cxx
+++ b/scipy/spatial/ckdtree/src/query_ball_tree.cxx
@@ -1,6 +1,3 @@
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -13,24 +10,21 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
-#include ""ckdtree_methods.h""
-#include ""cpp_exc.h""
 #include ""rectangle.h""
 
 
 static void
 traverse_no_checking(const ckdtree *self, const ckdtree *other,
-                     std::vector<npy_intp> **results,
+                     std::vector<ckdtree_intp_t> **results,
                      const ckdtreenode *node1, const ckdtreenode *node2)
 {
     const ckdtreenode *lnode1;
     const ckdtreenode *lnode2;
-    const npy_intp *sindices = self->raw_indices;
-    const npy_intp *oindices = other->raw_indices;
-    std::vector<npy_intp> *results_i;
-    npy_intp i, j;
+    const ckdtree_intp_t *sindices = self->raw_indices;
+    const ckdtree_intp_t *oindices = other->raw_indices;
+    std::vector<ckdtree_intp_t> *results_i;
+    ckdtree_intp_t i, j;
 
     if (node1->split_dim == -1) {   /* leaf node */
         lnode1 = node1;
@@ -38,10 +32,10 @@ traverse_no_checking(const ckdtree *self, const ckdtree *other,
         if (node2->split_dim == -1) {  /* leaf node */
             lnode2 = node2;
 
-            const npy_intp start1 = lnode1->start_idx;
-            const npy_intp start2 = lnode2->start_idx;
-            const npy_intp end1 = lnode1->end_idx;
-            const npy_intp end2 = lnode2->end_idx;
+            const ckdtree_intp_t start1 = lnode1->start_idx;
+            const ckdtree_intp_t start2 = lnode2->start_idx;
+            const ckdtree_intp_t end1 = lnode1->end_idx;
+            const ckdtree_intp_t end2 = lnode2->end_idx;
 
             for (i = start1; i < end1; ++i) {
                 results_i = results[sindices[i]];
@@ -63,15 +57,15 @@ traverse_no_checking(const ckdtree *self, const ckdtree *other,
 
 template <typename MinMaxDist> static void
 traverse_checking(const ckdtree *self, const ckdtree *other,
-                  std::vector<npy_intp> **results,
+                  std::vector<ckdtree_intp_t> **results,
                   const ckdtreenode *node1, const ckdtreenode *node2,
                   RectRectDistanceTracker<MinMaxDist> *tracker)
 {
     const ckdtreenode *lnode1;
     const ckdtreenode *lnode2;
-    std::vector<npy_intp> *results_i;
-    npy_float64 d;
-    npy_intp i, j;
+    std::vector<ckdtree_intp_t> *results_i;
+    double d;
+    ckdtree_intp_t i, j;
 
     if (tracker->min_distance > tracker->upper_bound * tracker->epsfac)
         return;
@@ -84,40 +78,40 @@ traverse_checking(const ckdtree *self, const ckdtree *other,
 
             /* brute-force */
             lnode2 = node2;
-            const npy_float64 p = tracker->p;
-            const npy_float64 tub = tracker->upper_bound;
-            const npy_float64 tmd = tracker->max_distance;
-            const npy_float64 *sdata = self->raw_data;
-            const npy_intp *sindices = self->raw_indices;
-            const npy_float64 *odata = other->raw_data;
-            const npy_intp *oindices = other->raw_indices;
-            const npy_intp m = self->m;
-            const npy_intp start1 = lnode1->start_idx;
-            const npy_intp start2 = lnode2->start_idx;
-            const npy_intp end1 = lnode1->end_idx;
-            const npy_intp end2 = lnode2->end_idx;
-
-            prefetch_datapoint(sdata + sindices[start1] * m, m);
+            const double p = tracker->p;
+            const double tub = tracker->upper_bound;
+            const double tmd = tracker->max_distance;
+            const double *sdata = self->raw_data;
+            const ckdtree_intp_t *sindices = self->raw_indices;
+            const double *odata = other->raw_data;
+            const ckdtree_intp_t *oindices = other->raw_indices;
+            const ckdtree_intp_t m = self->m;
+            const ckdtree_intp_t start1 = lnode1->start_idx;
+            const ckdtree_intp_t start2 = lnode2->start_idx;
+            const ckdtree_intp_t end1 = lnode1->end_idx;
+            const ckdtree_intp_t end2 = lnode2->end_idx;
+
+            CKDTREE_PREFETCH(sdata + sindices[start1] * m, 0, m);
 
             if (start1 < end1 - 1)
-                prefetch_datapoint(sdata + sindices[start1+1] * m, m);
+                CKDTREE_PREFETCH(sdata + sindices[start1+1] * m, 0, m);
 
             for (i = start1; i < end1; ++i) {
 
                 if (i < end1 - 2)
-                    prefetch_datapoint(sdata + sindices[i+2] * m, m);
+                    CKDTREE_PREFETCH(sdata + sindices[i+2] * m, 0, m);
 
-                prefetch_datapoint(odata + oindices[start2] * m, m);
+                CKDTREE_PREFETCH(odata + oindices[start2] * m, 0, m);
 
                 if (start2 < end2 - 1)
-                    prefetch_datapoint(odata + oindices[start2+1] * m, m);
+                    CKDTREE_PREFETCH(odata + oindices[start2+1] * m, 0, m);
 
                 results_i = results[sindices[i]];
 
                 for (j = start2; j < end2; ++j) {
 
                     if (j < end2 - 2)
-                        prefetch_datapoint(odata + oindices[j+2] * m, m);
+                        CKDTREE_PREFETCH(odata + oindices[j+2] * m, 0, m);
 
                     d = MinMaxDist::point_point_p(
                             self,
@@ -186,11 +180,10 @@ traverse_checking(const ckdtree *self, const ckdtree *other,
     }
 }
 
-
-extern ""C"" PyObject*
+int
 query_ball_tree(const ckdtree *self, const ckdtree *other,
-                const npy_float64 r, const npy_float64 p, const npy_float64 eps,
-                std::vector<npy_intp> **results)
+                const double r, const double p, const double eps,
+                std::vector<ckdtree_intp_t> **results)
 {
 
 #define HANDLE(cond, kls) \
@@ -200,39 +193,21 @@ query_ball_tree(const ckdtree *self, const ckdtree *other,
             &tracker); \
     } else
 
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
-            Rectangle r2(other->m, other->raw_mins, other->raw_maxes);
-
-            if(NPY_LIKELY(self->raw_boxsize_data == NULL)) {
-                HANDLE(NPY_LIKELY(p == 2), MinkowskiDistP2)
-                HANDLE(p == 1, MinkowskiDistP1)
-                HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
-                HANDLE(1, MinkowskiDistPp)
-                {}
-            } else {
-                HANDLE(NPY_LIKELY(p == 2), BoxMinkowskiDistP2)
-                HANDLE(p == 1, BoxMinkowskiDistP1)
-                HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
-                HANDLE(1, BoxMinkowskiDistPp)
-                {}
-            }
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
+    Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
+    Rectangle r2(other->m, other->raw_mins, other->raw_maxes);
+
+    if(CKDTREE_LIKELY(self->raw_boxsize_data == NULL)) {
+        HANDLE(CKDTREE_LIKELY(p == 2), MinkowskiDistP2)
+        HANDLE(p == 1, MinkowskiDistP1)
+        HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
+        HANDLE(1, MinkowskiDistPp)
+        {}
+    } else {
+        HANDLE(CKDTREE_LIKELY(p == 2), BoxMinkowskiDistP2)
+        HANDLE(p == 1, BoxMinkowskiDistP1)
+        HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
+        HANDLE(1, BoxMinkowskiDistPp)
+        {}
     }
+    return 0;
 }
diff --git a/scipy/spatial/ckdtree/src/query_pairs.cxx b/scipy/spatial/ckdtree/src/query_pairs.cxx
index 0ae54f8741f1..dd5dab0b9c9d 100644
--- a/scipy/spatial/ckdtree/src/query_pairs.cxx
+++ b/scipy/spatial/ckdtree/src/query_pairs.cxx
@@ -1,6 +1,3 @@
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -13,11 +10,8 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
 #include ""ordered_pair.h""
-#include ""ckdtree_methods.h""
-#include ""cpp_exc.h""
 #include ""rectangle.h""
 
 
@@ -28,8 +22,8 @@ traverse_no_checking(const ckdtree *self,
 {
     const ckdtreenode *lnode1;
     const ckdtreenode *lnode2;
-    npy_intp i, j, min_j;
-    const npy_intp *indices = self->raw_indices;
+    ckdtree_intp_t i, j, min_j;
+    const ckdtree_intp_t *indices = self->raw_indices;
 
     if (node1->split_dim == -1) { /* leaf node */
         lnode1 = node1;
@@ -37,10 +31,10 @@ traverse_no_checking(const ckdtree *self,
         if (node2->split_dim == -1) { /* leaf node */
             lnode2 = node2;
 
-            const npy_intp start1 = lnode1->start_idx;
-            const npy_intp start2 = lnode2->start_idx;
-            const npy_intp end1 = lnode1->end_idx;
-            const npy_intp end2 = lnode2->end_idx;
+            const ckdtree_intp_t start1 = lnode1->start_idx;
+            const ckdtree_intp_t start2 = lnode2->start_idx;
+            const ckdtree_intp_t end1 = lnode1->end_idx;
+            const ckdtree_intp_t end2 = lnode2->end_idx;
 
             for (i = start1; i < end1; ++i) {
 
@@ -87,8 +81,8 @@ traverse_checking(const ckdtree *self,
 {
     const ckdtreenode *lnode1;
     const ckdtreenode *lnode2;
-    npy_float64 d;
-    npy_intp i, j, min_j;
+    double d;
+    ckdtree_intp_t i, j, min_j;
 
     if (tracker->min_distance > tracker->upper_bound * tracker->epsfac)
         return;
@@ -101,24 +95,24 @@ traverse_checking(const ckdtree *self,
             lnode2 = node2;
 
             /* brute-force */
-            const npy_float64 p = tracker->p;
-            const npy_float64 tub = tracker->upper_bound;
-            const npy_float64 *data = self->raw_data;
-            const npy_intp *indices = self->raw_indices;
-            const npy_intp m = self->m;
-            const npy_intp start1 = lnode1->start_idx;
-            const npy_intp start2 = lnode2->start_idx;
-            const npy_intp end1 = lnode1->end_idx;
-            const npy_intp end2 = lnode2->end_idx;
-
-            prefetch_datapoint(data+indices[start1]*m, m);
+            const double p = tracker->p;
+            const double tub = tracker->upper_bound;
+            const double *data = self->raw_data;
+            const ckdtree_intp_t *indices = self->raw_indices;
+            const ckdtree_intp_t m = self->m;
+            const ckdtree_intp_t start1 = lnode1->start_idx;
+            const ckdtree_intp_t start2 = lnode2->start_idx;
+            const ckdtree_intp_t end1 = lnode1->end_idx;
+            const ckdtree_intp_t end2 = lnode2->end_idx;
+
+            CKDTREE_PREFETCH(data+indices[start1]*m, 0, m);
             if (start1 < end1 - 1)
-               prefetch_datapoint(data+indices[start1+1]*m, m);
+               CKDTREE_PREFETCH(data+indices[start1+1]*m, 0, m);
 
             for(i = start1; i < end1; ++i) {
 
                 if (i < end1 - 2)
-                     prefetch_datapoint(data+indices[i+2]*m, m);
+                     CKDTREE_PREFETCH(data+indices[i+2]*m, 0, m);
 
                 /* Special care here to avoid duplicate pairs */
                 if (node1 == node2)
@@ -127,14 +121,14 @@ traverse_checking(const ckdtree *self,
                     min_j = start2;
 
                 if (min_j < end2)
-                    prefetch_datapoint(data+indices[min_j]*m, m);
+                    CKDTREE_PREFETCH(data+indices[min_j]*m, 0, m);
                 if (min_j < end2 - 1)
-                    prefetch_datapoint(data+indices[min_j+1]*m, m);
+                    CKDTREE_PREFETCH(data+indices[min_j+1]*m, 0, m);
 
                 for (j = min_j; j < end2; ++j) {
 
                     if (j < end2 - 2)
-                        prefetch_datapoint(data+indices[j+2]*m, m);
+                        CKDTREE_PREFETCH(data+indices[j+2]*m, 0, m);
 
                     d = MinMaxDist::point_point_p(
                             self,
@@ -204,9 +198,9 @@ traverse_checking(const ckdtree *self,
 
 #include <iostream>
 
-extern ""C"" PyObject*
+int
 query_pairs(const ckdtree *self,
-            const npy_float64 r, const npy_float64 p, const npy_float64 eps,
+            const double r, const double p, const double eps,
             std::vector<ordered_pair> *results)
 {
 
@@ -217,42 +211,23 @@ query_pairs(const ckdtree *self,
             &tracker); \
     } else
 
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-
-            Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
-            Rectangle r2(self->m, self->raw_mins, self->raw_maxes);
-
-            if(NPY_LIKELY(self->raw_boxsize_data == NULL)) {
-                HANDLE(NPY_LIKELY(p == 2), MinkowskiDistP2)
-                HANDLE(p == 1, MinkowskiDistP1)
-                HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
-                HANDLE(1, MinkowskiDistPp)
-                {}
-            } else {
-                HANDLE(NPY_LIKELY(p == 2), BoxMinkowskiDistP2)
-                HANDLE(p == 1, BoxMinkowskiDistP1)
-                HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
-                HANDLE(1, BoxMinkowskiDistPp)
-                {}
-            }
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
+    Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
+    Rectangle r2(self->m, self->raw_mins, self->raw_maxes);
+
+    if(CKDTREE_LIKELY(self->raw_boxsize_data == NULL)) {
+        HANDLE(CKDTREE_LIKELY(p == 2), MinkowskiDistP2)
+        HANDLE(p == 1, MinkowskiDistP1)
+        HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
+        HANDLE(1, MinkowskiDistPp)
+        {}
+    } else {
+        HANDLE(CKDTREE_LIKELY(p == 2), BoxMinkowskiDistP2)
+        HANDLE(p == 1, BoxMinkowskiDistP1)
+        HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
+        HANDLE(1, BoxMinkowskiDistPp)
+        {}
     }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
 
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
-    }
+    return 0;
 }
 
diff --git a/scipy/spatial/ckdtree/src/rectangle.h b/scipy/spatial/ckdtree/src/rectangle.h
index 92bfce3472cc..0a9c46b4b5bd 100644
--- a/scipy/spatial/ckdtree/src/rectangle.h
+++ b/scipy/spatial/ckdtree/src/rectangle.h
@@ -10,46 +10,36 @@
 #include <cstring>
 
 
-#ifndef NPY_UNLIKELY
-#define NPY_UNLIKELY(x) (x)
-#endif
-
-#ifndef NPY_LIKELY
-#define NPY_LIKELY(x) (x)
-#endif
-
-
 /* Interval arithmetic
  * ===================
  */
 
 struct Rectangle {
 
-    const npy_intp m;
+    const ckdtree_intp_t m;
 
     /* the last const is to allow const Rectangle to use these functions;
      * also notice we had to mark buf mutable to avoid writing non const version
      * of the same accessors. */
-    npy_float64 * const maxes() const { return &buf[0]; }
-    npy_float64 * const mins() const { return &buf[0] + m; }
+    double * const maxes() const { return &buf[0]; }
+    double * const mins() const { return &buf[0] + m; }
 
-    Rectangle(const npy_intp _m,
-              const npy_float64 *_mins,
-              const npy_float64 *_maxes) : m(_m), buf(2 * m) {
+    Rectangle(const ckdtree_intp_t _m,
+              const double *_mins,
+              const double *_maxes) : m(_m), buf(2 * m) {
 
         /* copy array data */
         /* FIXME: use std::vector ? */
-        std::memcpy((void*)mins(), (void*)_mins, m*sizeof(npy_float64));
-        std::memcpy((void*)maxes(), (void*)_maxes, m*sizeof(npy_float64));
+        std::memcpy((void*)mins(), (void*)_mins, m*sizeof(double));
+        std::memcpy((void*)maxes(), (void*)_maxes, m*sizeof(double));
     };
 
     Rectangle(const Rectangle& rect) : m(rect.m), buf(rect.buf) {};
 
     private:
-        mutable std::vector<npy_float64> buf;
+        mutable std::vector<double> buf;
 };
 
-#include ""ckdtree_methods.h""
 #include ""distance.h""
 
 /*
@@ -86,16 +76,16 @@ struct Rectangle {
  */
 
 struct RR_stack_item {
-    npy_intp    which;
-    npy_intp    split_dim;
-    npy_float64 min_along_dim;
-    npy_float64 max_along_dim;
-    npy_float64 min_distance;
-    npy_float64 max_distance;
+    ckdtree_intp_t    which;
+    ckdtree_intp_t    split_dim;
+    double min_along_dim;
+    double max_along_dim;
+    double min_distance;
+    double max_distance;
 };
 
-const npy_intp LESS = 1;
-const npy_intp GREATER = 2;
+const ckdtree_intp_t LESS = 1;
+const ckdtree_intp_t GREATER = 2;
 
 template<typename MinMaxDist>
     struct RectRectDistanceTracker {
@@ -103,22 +93,22 @@ template<typename MinMaxDist>
     const ckdtree * tree;
     Rectangle rect1;
     Rectangle rect2;
-    npy_float64 p;
-    npy_float64 epsfac;
-    npy_float64 upper_bound;
-    npy_float64 min_distance;
-    npy_float64 max_distance;
-
-    npy_intp stack_size;
-    npy_intp stack_max_size;
+    double p;
+    double epsfac;
+    double upper_bound;
+    double min_distance;
+    double max_distance;
+
+    ckdtree_intp_t stack_size;
+    ckdtree_intp_t stack_max_size;
     std::vector<RR_stack_item> stack_arr;
     RR_stack_item *stack;
 
     /* if min/max distance / adjustment is less than this,
      * we believe the incremental tracking is inaccurate */
-    npy_float64 inaccurate_distance_limit;
+    double inaccurate_distance_limit;
 
-    void _resize_stack(const npy_intp new_max_size) {
+    void _resize_stack(const ckdtree_intp_t new_max_size) {
         stack_arr.resize(new_max_size);
         stack = &stack_arr[0];
         stack_max_size = new_max_size;
@@ -126,8 +116,8 @@ template<typename MinMaxDist>
 
     RectRectDistanceTracker(const ckdtree *_tree,
                  const Rectangle& _rect1, const Rectangle& _rect2,
-                 const npy_float64 _p, const npy_float64 eps,
-                 const npy_float64 _upper_bound)
+                 const double _p, const double eps,
+                 const double _upper_bound)
         : tree(_tree), rect1(_rect1), rect2(_rect2), stack_arr(8) {
 
         if (rect1.m != rect2.m) {
@@ -138,16 +128,16 @@ template<typename MinMaxDist>
         p = _p;
 
         /* internally we represent all distances as distance ** p */
-        if (NPY_LIKELY(p == 2.0))
+        if (CKDTREE_LIKELY(p == 2.0))
             upper_bound = _upper_bound * _upper_bound;
-        else if ((!ckdtree_isinf(p)) && (!ckdtree_isinf(_upper_bound)))
+        else if ((!ckdtree_isinf(p)) && (!isinf(_upper_bound)))
             upper_bound = std::pow(_upper_bound,p);
         else
             upper_bound = _upper_bound;
 
         /* fiddle approximation factor */
-        if (NPY_LIKELY(p == 2.0)) {
-            npy_float64 tmp = 1. + eps;
+        if (CKDTREE_LIKELY(p == 2.0)) {
+            double tmp = 1. + eps;
             epsfac = 1. / (tmp*tmp);
         }
         else if (eps == 0.)
@@ -173,10 +163,10 @@ template<typename MinMaxDist>
     };
 
 
-    void push(const npy_intp which, const npy_intp direction,
-              const npy_intp split_dim, const npy_float64 split_val) {
+    void push(const ckdtree_intp_t which, const intptr_t direction,
+              const ckdtree_intp_t split_dim, const double split_val) {
 
-        const npy_float64 p = this->p;
+        const double p = this->p;
         /* subnomial is 1 if round-off is expected to taint the incremental distance tracking.
          * in that case we always recompute the distances.
          * Recomputing costs more calls to pow, thus if the round-off error does not seem
@@ -204,8 +194,8 @@ template<typename MinMaxDist>
         item->max_along_dim = rect->maxes()[split_dim];
 
         /* update min/max distances */
-        npy_float64 min1, max1;
-        npy_float64 min2, max2;
+        double min1, max1;
+        double min2, max2;
 
         MinMaxDist::interval_interval_p(tree, rect1, rect2, split_dim, p, &min1, &max1);
 
@@ -222,7 +212,7 @@ template<typename MinMaxDist>
         subnomial = subnomial || ((min2 != 0 && min2 < inaccurate_distance_limit) || max2 < inaccurate_distance_limit);
         subnomial = subnomial || (min_distance < inaccurate_distance_limit || max_distance < inaccurate_distance_limit);
 
-        if (NPY_UNLIKELY(subnomial)) {
+        if (CKDTREE_UNLIKELY(subnomial)) {
             MinMaxDist::rect_rect_p(tree, rect1, rect2, p, &min_distance, &max_distance);
         } else {
             min_distance += (min2 - min1);
@@ -230,12 +220,12 @@ template<typename MinMaxDist>
         }
     };
 
-    inline void push_less_of(const npy_intp which,
+    inline void push_less_of(const ckdtree_intp_t which,
                                  const ckdtreenode *node) {
         push(which, LESS, node->split_dim, node->split);
     };
 
-    inline void push_greater_of(const npy_intp which,
+    inline void push_greater_of(const ckdtree_intp_t which,
                                     const ckdtreenode *node) {
         push(which, GREATER, node->split_dim, node->split);
     };
@@ -245,7 +235,7 @@ template<typename MinMaxDist>
         --stack_size;
 
         /* assert stack_size >= 0 */
-        if (NPY_UNLIKELY(stack_size < 0)) {
+        if (CKDTREE_UNLIKELY(stack_size < 0)) {
             const char *msg = ""Bad stack size. This error should never occur."";
             throw std::logic_error(msg);
         }
diff --git a/scipy/spatial/ckdtree/src/sparse_distances.cxx b/scipy/spatial/ckdtree/src/sparse_distances.cxx
index 6441f4cbe446..6c455b628d61 100644
--- a/scipy/spatial/ckdtree/src/sparse_distances.cxx
+++ b/scipy/spatial/ckdtree/src/sparse_distances.cxx
@@ -1,7 +1,3 @@
-
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -14,10 +10,7 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
-#include ""ckdtree_methods.h""
-#include ""cpp_exc.h""
 #include ""rectangle.h""
 #include ""coo_entries.h""
 
@@ -34,44 +27,44 @@ traverse(const ckdtree *self, const ckdtree *other,
 
         if (node2->split_dim == -1) {  /* 1 & 2 are leaves */
             /* brute-force */
-            const npy_float64 p = tracker->p;
-            const npy_float64 tub = tracker->upper_bound;
-            const npy_float64 *sdata = self->raw_data;
-            const npy_intp *sindices = self->raw_indices;
-            const npy_float64 *odata = other->raw_data;
-            const npy_intp *oindices = other->raw_indices;
-            const npy_intp m = self->m;
-            const npy_intp start1 = node1->start_idx;
-            const npy_intp start2 = node2->start_idx;
-            const npy_intp end1 = node1->end_idx;
-            const npy_intp end2 = node2->end_idx;
-
-            prefetch_datapoint(sdata + sindices[start1] * m, m);
+            const double p = tracker->p;
+            const double tub = tracker->upper_bound;
+            const double *sdata = self->raw_data;
+            const ckdtree_intp_t *sindices = self->raw_indices;
+            const double *odata = other->raw_data;
+            const ckdtree_intp_t *oindices = other->raw_indices;
+            const ckdtree_intp_t m = self->m;
+            const ckdtree_intp_t start1 = node1->start_idx;
+            const ckdtree_intp_t start2 = node2->start_idx;
+            const ckdtree_intp_t end1 = node1->end_idx;
+            const ckdtree_intp_t end2 = node2->end_idx;
+
+            CKDTREE_PREFETCH(sdata + sindices[start1] * m, 0, m);
             if (start1 < end1 - 1)
-               prefetch_datapoint(sdata + sindices[start1+1] * m, m);
+               CKDTREE_PREFETCH(sdata + sindices[start1+1] * m, 0, m);
 
-            for (npy_intp i = start1; i < end1; ++i) {
+            for (ckdtree_intp_t i = start1; i < end1; ++i) {
 
                 if (i < end1 - 2)
-                     prefetch_datapoint(sdata + sindices[i+2] * m, m);
+                     CKDTREE_PREFETCH(sdata + sindices[i+2] * m, 0, m);
 
-                prefetch_datapoint(odata + oindices[start2] * m, m);
+                CKDTREE_PREFETCH(odata + oindices[start2] * m, 0, m);
                 if (start2 < end2 - 1)
-                    prefetch_datapoint(sdata + oindices[start2+1] * m, m);
+                    CKDTREE_PREFETCH(sdata + oindices[start2+1] * m, 0, m);
 
-                for (npy_intp j = start2; j < end2; ++j) {
+                for (ckdtree_intp_t j = start2; j < end2; ++j) {
 
                     if (j < end2 - 2)
-                        prefetch_datapoint(odata + oindices[j+2] * m, m);
+                        CKDTREE_PREFETCH(odata + oindices[j+2] * m, 0, m);
 
-                    npy_float64 d = MinMaxDist::point_point_p(
+                    double d = MinMaxDist::point_point_p(
                             self,
                             sdata + sindices[i] * m,
                             odata + oindices[j] * m,
                             p, m, tub);
 
                     if (d <= tub) {
-                        if (NPY_LIKELY(p == 2.0))
+                        if (CKDTREE_LIKELY(p == 2.0))
                             d = std::sqrt(d);
                         else if ((p != 1) && (!ckdtree_isinf(p)))
                             d = std::pow(d, 1. / p);
@@ -129,10 +122,10 @@ traverse(const ckdtree *self, const ckdtree *other,
 }
 
 
-extern ""C"" PyObject*
+int
 sparse_distance_matrix(const ckdtree *self, const ckdtree *other,
-                       const npy_float64 p,
-                       const npy_float64 max_distance,
+                       const double p,
+                       const double max_distance,
                        std::vector<coo_entry> *results)
 {
 #define HANDLE(cond, kls) \
@@ -141,39 +134,21 @@ sparse_distance_matrix(const ckdtree *self, const ckdtree *other,
         traverse(self, other, results, self->ctree, other->ctree, &tracker); \
     } else
 
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-
-            Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
-            Rectangle r2(other->m, other->raw_mins, other->raw_maxes);
-            if(NPY_LIKELY(self->raw_boxsize_data == NULL)) {
-                HANDLE(NPY_LIKELY(p == 2), MinkowskiDistP2)
-                HANDLE(p == 1, MinkowskiDistP1)
-                HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
-                HANDLE(1, MinkowskiDistPp)
-                {}
-            } else {
-                HANDLE(NPY_LIKELY(p == 2), BoxMinkowskiDistP2)
-                HANDLE(p == 1, BoxMinkowskiDistP1)
-                HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
-                HANDLE(1, BoxMinkowskiDistPp)
-                {}
-            }
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
+    Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
+    Rectangle r2(other->m, other->raw_mins, other->raw_maxes);
+    if(CKDTREE_LIKELY(self->raw_boxsize_data == NULL)) {
+        HANDLE(CKDTREE_LIKELY(p == 2), MinkowskiDistP2)
+        HANDLE(p == 1, MinkowskiDistP1)
+        HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
+        HANDLE(1, MinkowskiDistPp)
+        {}
+    } else {
+        HANDLE(CKDTREE_LIKELY(p == 2), BoxMinkowskiDistP2)
+        HANDLE(p == 1, BoxMinkowskiDistP1)
+        HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
+        HANDLE(1, BoxMinkowskiDistPp)
+        {}
     }
+
+    return 0;
 }
diff --git a/scipy/spatial/setup.py b/scipy/spatial/setup.py
index 9736a541428a..5a6222831115 100644
--- a/scipy/spatial/setup.py
+++ b/scipy/spatial/setup.py
@@ -36,8 +36,6 @@ def configuration(parent_package='', top_path=None):
     # cKDTree
     ckdtree_src = ['query.cxx',
                    'build.cxx',
-                   'globals.cxx',
-                   'cpp_exc.cxx',
                    'query_pairs.cxx',
                    'count_neighbors.cxx',
                    'query_ball_point.cxx',
@@ -47,10 +45,7 @@ def configuration(parent_package='', top_path=None):
     ckdtree_src = [join('ckdtree', 'src', x) for x in ckdtree_src]
 
     ckdtree_headers = ['ckdtree_decl.h',
-                       'ckdtree_methods.h',
                        'coo_entries.h',
-                       'cpp_exc.h',
-                       'cpp_utils.h',
                        'distance_base.h',
                        'distance.h',
                        'ordered_pair.h',
diff --git a/scipy/spatial/tests/test_kdtree.py b/scipy/spatial/tests/test_kdtree.py
index a9737cbc8701..c57517a8db9c 100644
--- a/scipy/spatial/tests/test_kdtree.py
+++ b/scipy/spatial/tests/test_kdtree.py
@@ -1360,6 +1360,35 @@ def test_short_knn():
             [0., 0.01, np.inf, np.inf],
             [0., np.inf, np.inf, np.inf]])
 
+def test_query_ball_point_vector_r():
+
+    np.random.seed(1234)
+    data = np.random.normal(size=(100, 3))
+    query = np.random.normal(size=(100, 3))
+    tree = cKDTree(data)
+    d = np.random.uniform(0, 0.3, size=len(query))
+
+    rvector = tree.query_ball_point(query, d)
+    rscalar = [tree.query_ball_point(qi, di) for qi, di in zip(query, d)]
+    for a, b in zip(rvector, rscalar):
+        assert_array_equal(sorted(a), sorted(b))
+
+def test_query_ball_point_length():
+
+    np.random.seed(1234)
+    data = np.random.normal(size=(100, 3))
+    query = np.random.normal(size=(100, 3))
+    tree = cKDTree(data)
+    d = 0.3
+
+    length = tree.query_ball_point(query, d, return_length=True)
+    length2 = [len(ind) for ind in tree.query_ball_point(query, d, return_length=False)]
+    length3 = [len(tree.query_ball_point(qi, d)) for qi in query]
+    length4 = [tree.query_ball_point(qi, d, return_length=True) for qi in query]
+    assert_array_equal(length, length2)
+    assert_array_equal(length, length3)
+    assert_array_equal(length, length4)
+
 class Test_sorted_query_ball_point(object):
 
     def setup_method(self):
@@ -1372,6 +1401,10 @@ def test_return_sorted_True(self):
         for idxs in idxs_list:
             assert_array_equal(idxs, sorted(idxs))
 
+        for xi in self.x:
+            idxs = self.ckdt.query_ball_point(xi, 1., return_sorted=True)
+            assert_array_equal(idxs, sorted(idxs))
+
     def test_return_sorted_None(self):
         """"""Previous behavior was to sort the returned indices if there were
         multiple points per query but not sort them if there was a single point
"
"Merge pull request #9562 from WarrenWeckesser/pearsonr

MAINT: stats: Rewrite pearsonr.",7baba41fb27f70416b64efc4bd6aba142797a25c,"diff --git a/scipy/stats/__init__.py b/scipy/stats/__init__.py
index 280547cafc98..fb331bd6bf8d 100644
--- a/scipy/stats/__init__.py
+++ b/scipy/stats/__init__.py
@@ -361,6 +361,15 @@
 
    gaussian_kde
 
+Warnings used in :mod:`scipy.stats`
+===================================
+
+.. autosummary::
+   :toctree: generated/
+
+   PearsonRConstantInputWarning
+   PearsonRNearConstantInputWarning
+
 For many more stat related functions install the software R and the
 interface package rpy.
 
diff --git a/scipy/stats/stats.py b/scipy/stats/stats.py
index 89de27731598..1ac6a5ebcb34 100644
--- a/scipy/stats/stats.py
+++ b/scipy/stats/stats.py
@@ -173,9 +173,11 @@
 from scipy._lib._version import NumpyVersion
 from scipy._lib._util import _lazywhere
 import scipy.special as special
+from scipy import linalg
 from . import distributions
 from . import mstats_basic
-from ._stats_mstats_common import _find_repeats, linregress, theilslopes, siegelslopes
+from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,
+                                   siegelslopes)
 from ._stats import _kendall_dis, _toint64, _weightedrankedtau
 from ._rvs_sampling import rvs_ratio_uniforms
 from ._hypotests import epps_singleton_2samp
@@ -189,6 +191,7 @@
            'cumfreq', 'relfreq', 'obrientransform',
            'sem', 'zmap', 'zscore', 'iqr', 'gstd', 'median_absolute_deviation',
            'sigmaclip', 'trimboth', 'trim1', 'trim_mean', 'f_oneway',
+           'PearsonRConstantInputWarning', 'PearsonRNearConstantInputWarning',
            'pearsonr', 'fisher_exact', 'spearmanr', 'pointbiserialr',
            'kendalltau', 'weightedtau',
            'linregress', 'siegelslopes', 'theilslopes', 'ttest_1samp',
@@ -3231,23 +3234,47 @@ def f_oneway(*args):
     return F_onewayResult(f, prob)
 
 
+class PearsonRConstantInputWarning(RuntimeWarning):
+    """"""
+    Warning generated by `pearsonr` when an input is constant.
+    """"""
+
+    def __init__(self, msg=None):
+        if msg is None:
+            msg = (""An input array is constant; the correlation coefficent ""
+                   ""is not defined."")
+        self.args = (msg,)
+
+
+class PearsonRNearConstantInputWarning(RuntimeWarning):
+    """"""
+    Warning generated by `pearsonr` when an input is nearly constant.
+    """"""
+
+    def __init__(self, msg=None):
+        if msg is None:
+            msg = (""An input array is nearly constant; the computed ""
+                   ""correlation coefficent may be inaccurate."")
+        self.args = (msg,)
+
+
 def pearsonr(x, y):
     r""""""
-    Calculate a Pearson correlation coefficient and the p-value for testing
-    non-correlation.
-
-    The Pearson correlation coefficient measures the linear relationship
-    between two datasets. Strictly speaking, Pearson's correlation requires
-    that each dataset be normally distributed, and not necessarily zero-mean.
-    Like other correlation coefficients, this one varies between -1 and +1
-    with 0 implying no correlation. Correlations of -1 or +1 imply an exact
-    linear relationship. Positive correlations imply that as x increases, so
-    does y. Negative correlations imply that as x increases, y decreases.
+    Pearson correlation coefficient and p-value for testing non-correlation.
+
+    The Pearson correlation coefficient [1]_ measures the linear relationship
+    between two datasets.  The calculation of the p-value relies on the
+    assumption that each dataset is normally distributed.  (See Kowalski [3]_
+    for a discussion of the effects of non-normality of the input on the
+    distribution of the correlation coefficient.)  Like other correlation
+    coefficients, this one varies between -1 and +1 with 0 implying no
+    correlation. Correlations of -1 or +1 imply an exact linear relationship.
+    Positive correlations imply that as x increases, so does y. Negative
+    correlations imply that as x increases, y decreases.
 
     The p-value roughly indicates the probability of an uncorrelated system
     producing datasets that have a Pearson correlation at least as extreme
-    as the one computed from these datasets. The p-values are not entirely
-    reliable but are probably reasonable for datasets larger than 500 or so.
+    as the one computed from these datasets.
 
     Parameters
     ----------
@@ -3261,7 +3288,24 @@ def pearsonr(x, y):
     r : float
         Pearson's correlation coefficient
     p-value : float
-        2-tailed p-value
+        two-tailed p-value
+
+    Warns
+    -----
+    PearsonRConstantInputWarning
+        Raised if an input is a constant array.  The correlation coefficient
+        is not defined in this case, so ``np.nan`` is returned.
+
+    PearsonRNearConstantInputWarning
+        Raised if an input is ""nearly"" constant.  The array ``x`` is considered
+        nearly constant if ``norm(x - mean(x)) < 1e-13 * abs(mean(x))``.
+        Numerical errors in the calculation ``x - mean(x)`` in this case might
+        result in an inaccurate calculation of r.
+
+    See Also
+    --------
+    spearmanr : Spearman rank-order correlation coefficient.
+    kendalltau : Kendall's tau, a correlation measure for ordinal data.
 
     Notes
     -----
@@ -3270,16 +3314,58 @@ def pearsonr(x, y):
 
     .. math::
 
-        r_{pb} = \frac{\sum (x - m_x) (y - m_y)}
-                      {\sqrt{\sum (x - m_x)^2 \sum (y - m_y)^2}}
+        r = \frac{\sum (x - m_x) (y - m_y)}
+                 {\sqrt{\sum (x - m_x)^2 \sum (y - m_y)^2}}
 
     where :math:`m_x` is the mean of the vector :math:`x` and :math:`m_y` is
     the mean of the vector :math:`y`.
 
+    Under the assumption that x and y are drawn from independent normal
+    distributions (so the population correlation coefficient is 0), the
+    probability density function of the sample correlation coefficient r
+    is ([1]_, [2]_)::
+
+               (1 - r**2)**(n/2 - 2)
+        f(r) = ---------------------
+                  B(1/2, n/2 - 1)
+
+    where n is the number of samples, and B is the beta function.  This
+    is sometimes referred to as the exact distribution of r.  This is
+    the distribution that is used in `pearsonr` to compute the p-value.
+    The distribution is a beta distribution on the interval [-1, 1],
+    with equal shape parameters a = b = n/2 - 1.  In terms of SciPy's
+    implementation of the beta distribution, the distribution of r is::
+
+        dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)
+
+    The p-value returned by `pearsonr` is a two-sided p-value.  For a
+    given sample with correlation coefficient r, the p-value is
+    the probability that abs(r') of a random sample x' and y' drawn from
+    the population with zero correlation would be greater than or equal
+    to abs(r).  In terms of the object `dist` shown above, the p-value
+    for a given r and length n can be computed as::
+
+        p = 2*dist.cdf(-abs(r))
+
+    When n is 2, the above continuous distribution is not well-defined.
+    One can interpret the limit of the beta distribution as the shape
+    parameters a and b approach a = b = 0 as a discrete distribution with
+    equal probability masses at r = 1 and r = -1.  More directly, one
+    can observe that, given the data x = [x1, x2] and y = [y1, y2], and
+    assuming x1 != x2 and y1 != y2, the only possible values for r are 1
+    and -1.  Because abs(r') for any sample x' and y' with length 2 will
+    be 1, the two-sided p-value for a sample of length 2 is always 1.
 
     References
     ----------
-    http://www.statsoft.com/textbook/glosp.html#Pearson%20Correlation
+    .. [1] ""Pearson correlation coefficient"", Wikipedia,
+           https://en.wikipedia.org/wiki/Pearson_correlation_coefficient
+    .. [2] Student, ""Probable error of a correlation coefficient"",
+           Biometrika, Volume 6, Issue 2-3, 1 September 1908, pp. 302-310.
+    .. [3] C. J. Kowalski, ""On the Effects of Non-Normality on the Distribution
+           of the Sample Product-Moment Correlation Coefficient""
+           Journal of the Royal Statistical Society. Series C (Applied
+           Statistics), Vol. 21, No. 1 (1972), pp. 1-12.
 
     Examples
     --------
@@ -3287,33 +3373,72 @@ def pearsonr(x, y):
     >>> a = np.array([0, 0, 0, 1, 1, 1, 1])
     >>> b = np.arange(7)
     >>> stats.pearsonr(a, b)
-    (0.8660254037844386, 0.011724811003954654)
+    (0.8660254037844386, 0.011724811003954649)
+
+    >>> stats.pearsonr([1, 2, 3, 4, 5], [10, 9, 2.5, 6, 4])
+    (-0.7426106572325057, 0.1505558088534455)
 
-    >>> stats.pearsonr([1,2,3,4,5], [5,6,7,8,7])
-    (0.83205029433784372, 0.080509573298498519)
     """"""
-    # x and y should have same length.
+    n = len(x)
+    if n != len(y):
+        raise ValueError('x and y must have the same length.')
+
+    if n < 2:
+        raise ValueError('x and y must have length at least 2.')
+
     x = np.asarray(x)
     y = np.asarray(y)
-    n = len(x)
-    mx = x.mean()
-    my = y.mean()
-    xm, ym = x - mx, y - my
-    r_num = np.add.reduce(xm * ym)
-    r_den = np.sqrt(_sum_of_squares(xm) * _sum_of_squares(ym))
-    r = r_num / r_den
+
+    # If an input is constant, the correlation coefficient is not defined.
+    if (x == x[0]).all() or (y == y[0]).all():
+        warnings.warn(PearsonRConstantInputWarning())
+        return np.nan, np.nan
+
+    # dtype is the data type for the calculations.  This expression ensures
+    # that the data type is at least 64 bit floating point.  It might have
+    # more precision if the input is, for example, np.longdouble.
+    dtype = type(1.0 + x[0] + y[0])
+
+    if n == 2:
+        return dtype(np.sign(x[1] - x[0])*np.sign(y[1] - y[0])), 1.0
+
+    xmean = x.mean(dtype=dtype)
+    ymean = y.mean(dtype=dtype)
+
+    # By using `astype(dtype)`, we ensure that the intermediate calculations
+    # use at least 64 bit floating point.
+    xm = x.astype(dtype) - xmean
+    ym = y.astype(dtype) - ymean
+
+    # Unlike np.linalg.norm or the expression sqrt((xm*xm).sum()),
+    # scipy.linalg.norm(xm) does not overflow if xm is, for example,
+    # [-5e210, 5e210, 3e200, -3e200]
+    normxm = linalg.norm(xm)
+    normym = linalg.norm(ym)
+
+    threshold = 1e-13
+    if normxm < threshold*abs(xmean) or normym < threshold*abs(ymean):
+        # If all the values in x (likewise y) are very close to the mean,
+        # the loss of precision that occurs in the subtraction xm = x - xmean
+        # might result in large errors in r.
+        warnings.warn(PearsonRNearConstantInputWarning())
+
+    r = np.dot(xm/normxm, ym/normym)
 
     # Presumably, if abs(r) > 1, then it is only some small artifact of
     # floating point arithmetic.
     r = max(min(r, 1.0), -1.0)
-    df = n - 2
-    if abs(r) == 1.0:
-        prob = 0.0
-    else:
-        t_squared = r**2 * (df / ((1.0 - r) * (1.0 + r)))
-        prob = special.betainc(
-            0.5*df, 0.5, np.fmin(np.asarray(df / (df + t_squared)), 1.0)
-        )
+
+    # As explained in the docstring, the p-value can be computed as
+    #     p = 2*dist.cdf(-abs(r))
+    # where dist is the beta distribution on [-1, 1] with shape parameters
+    # a = b = n/2 - 1.  `special.btdtr` is the CDF for the beta distribution
+    # on [0, 1].  To use it, we make the transformation  x = (r + 1)/2; the
+    # shape parameters do not change.  Then -abs(r) used in `cdf(-abs(r))`
+    # becomes x = (-abs(r) + 1)/2 = 0.5*(1 - abs(r)).  (r is cast to float64
+    # to avoid a TypeError raised by btdtr when r is higher precision.)
+    ab = n/2 - 1
+    prob = 2*special.btdtr(ab, ab, 0.5*(1 - abs(np.float64(r))))
 
     return r, prob
 
diff --git a/scipy/stats/tests/test_stats.py b/scipy/stats/tests/test_stats.py
index f17262caf48f..ed705ab84188 100644
--- a/scipy/stats/tests/test_stats.py
+++ b/scipy/stats/tests/test_stats.py
@@ -16,7 +16,7 @@
 from numpy.testing import (assert_, assert_equal,
                            assert_almost_equal, assert_array_almost_equal,
                            assert_array_equal, assert_approx_equal,
-                           assert_allclose)
+                           assert_allclose, assert_warns)
 import pytest
 from pytest import raises as assert_raises
 from scipy._lib._numpy_compat import suppress_warnings
@@ -255,19 +255,23 @@ def test_pROUNDROUND(self):
         r = y[0]
         assert_approx_equal(r,1.0)
 
-    def test_r_exactly_pos1(self):
+    def test_r_almost_exactly_pos1(self):
         a = arange(3.0)
-        b = a
-        r, prob = stats.pearsonr(a,b)
-        assert_equal(r, 1.0)
-        assert_equal(prob, 0.0)
+        r, prob = stats.pearsonr(a, a)
 
-    def test_r_exactly_neg1(self):
+        assert_allclose(r, 1.0, atol=1e-15)
+        # With n = len(a) = 3, the error in prob grows like the
+        # square root of the error in r.
+        assert_allclose(prob, 0.0, atol=np.sqrt(2*np.spacing(1.0)))
+
+    def test_r_almost_exactly_neg1(self):
         a = arange(3.0)
-        b = -a
-        r, prob = stats.pearsonr(a,b)
-        assert_equal(r, -1.0)
-        assert_equal(prob, 0.0)
+        r, prob = stats.pearsonr(a, -a)
+
+        assert_allclose(r, -1.0, atol=1e-15)
+        # With n = len(a) = 3, the error in prob grows like the
+        # square root of the error in r.
+        assert_allclose(prob, 0.0, atol=np.sqrt(2*np.spacing(1.0)))
 
     def test_basic(self):
         # A basic test, with a correlation coefficient
@@ -276,7 +280,106 @@ def test_basic(self):
         b = array([0, 0, 3])
         r, prob = stats.pearsonr(a, b)
         assert_approx_equal(r, np.sqrt(3)/2)
-        assert_approx_equal(prob, 1.0/3)
+        assert_approx_equal(prob, 1/3)
+
+    def test_constant_input(self):
+        # Zero variance input
+        # See https://github.com/scipy/scipy/issues/3728
+        with assert_warns(stats.PearsonRConstantInputWarning):
+            r, p = stats.pearsonr([0.667, 0.667, 0.667], [0.123, 0.456, 0.789])
+            assert_equal(r, np.nan)
+            assert_equal(p, np.nan)
+
+    def test_near_constant_input(self):
+        # Near constant input (but not constant):
+        x = [2, 2, 2 + np.spacing(2)]
+        y = [3, 3, 3 + 6*np.spacing(3)]
+        with assert_warns(stats.PearsonRNearConstantInputWarning):
+            # r and p are garbage, so don't bother checking them in this case.
+            # (The exact value of r would be 1.)
+            r, p = stats.pearsonr(x, y)
+
+    def test_very_small_input_values(self):
+        # Very small values in an input.  A naive implementation will
+        # suffer from underflow.
+        # See https://github.com/scipy/scipy/issues/9353
+        x = [0.004434375, 0.004756007, 0.003911996, 0.0038005, 0.003409971]
+        y = [2.48e-188, 7.41e-181, 4.09e-208, 2.08e-223, 2.66e-245]
+        r, p = stats.pearsonr(x,y)
+
+        # The expected values were computed using mpmath with 80 digits
+        # of precision.
+        assert_allclose(r, 0.7272930540750450)
+        assert_allclose(p, 0.1637805429533202)
+
+    def test_very_large_input_values(self):
+        # Very large values in an input.  A naive implementation will
+        # suffer from overflow.
+        # See https://github.com/scipy/scipy/issues/8980
+        x = 1e90*np.array([0, 0, 0, 1, 1, 1, 1])
+        y = 1e90*np.arange(7)
+
+        r, p = stats.pearsonr(x, y)
+
+        # The expected values were computed using mpmath with 80 digits
+        # of precision.
+        assert_allclose(r, 0.8660254037844386)
+        assert_allclose(p, 0.011724811003954638)
+
+    def test_extremely_large_input_values(self):
+        # Extremely large values in x and y.  These values would cause the
+        # product sigma_x * sigma_y to overflow if the two factors were
+        # computed independently.
+        x = np.array([2.3e200, 4.5e200, 6.7e200, 8e200])
+        y = np.array([1.2e199, 5.5e200, 3.3e201, 1.0e200])
+        r, p = stats.pearsonr(x, y)
+
+        # The expected values were computed using mpmath with 80 digits
+        # of precision.
+        assert_allclose(r, 0.351312332103289)
+        assert_allclose(p, 0.648687667896711)
+
+    def test_length_two_pos1(self):
+        # Inputs with length 2.
+        # See https://github.com/scipy/scipy/issues/7730
+        r, p = stats.pearsonr([1, 2], [3, 5])
+        assert_equal(r, 1)
+        assert_equal(p, 1)
+
+    def test_length_two_neg2(self):
+        # Inputs with length 2.
+        # See https://github.com/scipy/scipy/issues/7730
+        r, p = stats.pearsonr([2, 1], [3, 5])
+        assert_equal(r, -1)
+        assert_equal(p, 1)
+
+    def test_more_basic_examples(self):
+        x = [1, 2, 3, 4]
+        y = [0, 1, 0.5, 1]
+        r, p = stats.pearsonr(x, y)
+
+        # The expected values were computed using mpmath with 80 digits
+        # of precision.
+        assert_allclose(r, 0.674199862463242)
+        assert_allclose(p, 0.325800137536758)
+
+        x = [1, 2, 3]
+        y = [5, -4, -13]
+        r, p = stats.pearsonr(x, y)
+
+        # The expected r and p are exact.
+        assert_allclose(r, -1.0)
+        assert_allclose(p, 0.0)
+
+    def test_unequal_lengths(self):
+        x = [1, 2, 3]
+        y = [4, 5]
+        assert_raises(ValueError, stats.pearsonr, x, y)
+
+    def test_len1(self):
+        x = [1]
+        y = [2]
+        assert_raises(ValueError, stats.pearsonr, x, y)
 
 
 class TestFisherExact(object):
"
"MAINT: stats: Rewrite pearsonr.

The calculation of r in pearsonr(x, y) is rewritten in a more
robust form.

Let

    xm = x - mean(x)
    ym = y - mean(y)

In this commit, the calculation of r is changed from (roughly)

    r = dot(xm, ym)/sqrt((xm**2).sum() * (ym**2).sum())

to

    r = dot(xm/norm(xm), ym/norm(ym))

where the norm is calculated using `scipy.linalg.norm`.

`scipy.linalg.norm` avoids the underflow and overflow of intermediate results
that was the source of a couple bug reports.

The function has the following additional argument validation:

 * A ValueError is raised if the lengths of x and y are not the same.
 * A ValueError is raised if the length is less than 2.

New warnings are generated in the following cases:

 * If an input is *constant*, a PearsonRConstantInputWarning is generated,
   and nan is returned for both r and prob.  The correlation coefficient
   is not defined in this case.
 * If an input is *nearly* constant, a PearsonRNearConstantWarning is generated,
   but the calculation proceeds.  The condition for x being classified as
   near constant is

       norm(xm)/abs(mean(x)) < 1e-13

   (This is a heuristic condition, and it may generate false warnings.)

Another change is that inputs with length 2 are handled as a special case.
The only possible values of r in this case are +1 or -1, and in both cases,
the p-value is 1.

The calculation of the p-value has also been rewritten. It now has the simpler
form

    ab = len(x)/2 - 1
    prob = 2*special.btdtr(ab, ab, 0.5*(1 - abs(r)))

`special.btdtr` is the CDF of the beta distribution.

There were two existing tests that did not pass with the new code.  For the
inputs x = [0.0, 1.0, 2.0] with y = x and y = -x, the previous version of
pearsonr returned *exactly* 1 and -1, respectively, with p-value 0 in both
cases.  With the new code, we have:

    In [14]: x = np.arange(3.0)

    In [15]: pearsonr(x, x)
    Out[15]: (0.9999999999999998, 1.3415758552508151e-08)

    In [16]: pearsonr(x, -x)
    Out[16]: (-0.9999999999999998, 1.3415758552508151e-08)

The r values differ from the exact values by 2 ULPs.  The reason the p-values
are then so large (well, large compared to the exact value 0) is that, for n=3,
the p-value for r near 1 or -1 grows like the square root of 1 - abs(r), and
np.spacing(1) is about 2.22e-16.  When n is larger, the p-value is not so
sensitive to small perturbations in r.

New tests have been added to verify that problems reported with the old
code are now fixed.

Closes gh-3728.
Closes gh-7730.
Closes gh-8980.
Closes gh-9353.
Closes gh-9406.",1acf46f508afa2c6d498e1001ca17e8ad98b46ef,"diff --git a/scipy/stats/__init__.py b/scipy/stats/__init__.py
index 280547cafc98..fb331bd6bf8d 100644
--- a/scipy/stats/__init__.py
+++ b/scipy/stats/__init__.py
@@ -361,6 +361,15 @@
 
    gaussian_kde
 
+Warnings used in :mod:`scipy.stats`
+===================================
+
+.. autosummary::
+   :toctree: generated/
+
+   PearsonRConstantInputWarning
+   PearsonRNearConstantInputWarning
+
 For many more stat related functions install the software R and the
 interface package rpy.
 
diff --git a/scipy/stats/stats.py b/scipy/stats/stats.py
index 89de27731598..1ac6a5ebcb34 100644
--- a/scipy/stats/stats.py
+++ b/scipy/stats/stats.py
@@ -173,9 +173,11 @@
 from scipy._lib._version import NumpyVersion
 from scipy._lib._util import _lazywhere
 import scipy.special as special
+from scipy import linalg
 from . import distributions
 from . import mstats_basic
-from ._stats_mstats_common import _find_repeats, linregress, theilslopes, siegelslopes
+from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,
+                                   siegelslopes)
 from ._stats import _kendall_dis, _toint64, _weightedrankedtau
 from ._rvs_sampling import rvs_ratio_uniforms
 from ._hypotests import epps_singleton_2samp
@@ -189,6 +191,7 @@
            'cumfreq', 'relfreq', 'obrientransform',
            'sem', 'zmap', 'zscore', 'iqr', 'gstd', 'median_absolute_deviation',
            'sigmaclip', 'trimboth', 'trim1', 'trim_mean', 'f_oneway',
+           'PearsonRConstantInputWarning', 'PearsonRNearConstantInputWarning',
            'pearsonr', 'fisher_exact', 'spearmanr', 'pointbiserialr',
            'kendalltau', 'weightedtau',
            'linregress', 'siegelslopes', 'theilslopes', 'ttest_1samp',
@@ -3231,23 +3234,47 @@ def f_oneway(*args):
     return F_onewayResult(f, prob)
 
 
+class PearsonRConstantInputWarning(RuntimeWarning):
+    """"""
+    Warning generated by `pearsonr` when an input is constant.
+    """"""
+
+    def __init__(self, msg=None):
+        if msg is None:
+            msg = (""An input array is constant; the correlation coefficent ""
+                   ""is not defined."")
+        self.args = (msg,)
+
+
+class PearsonRNearConstantInputWarning(RuntimeWarning):
+    """"""
+    Warning generated by `pearsonr` when an input is nearly constant.
+    """"""
+
+    def __init__(self, msg=None):
+        if msg is None:
+            msg = (""An input array is nearly constant; the computed ""
+                   ""correlation coefficent may be inaccurate."")
+        self.args = (msg,)
+
+
 def pearsonr(x, y):
     r""""""
-    Calculate a Pearson correlation coefficient and the p-value for testing
-    non-correlation.
-
-    The Pearson correlation coefficient measures the linear relationship
-    between two datasets. Strictly speaking, Pearson's correlation requires
-    that each dataset be normally distributed, and not necessarily zero-mean.
-    Like other correlation coefficients, this one varies between -1 and +1
-    with 0 implying no correlation. Correlations of -1 or +1 imply an exact
-    linear relationship. Positive correlations imply that as x increases, so
-    does y. Negative correlations imply that as x increases, y decreases.
+    Pearson correlation coefficient and p-value for testing non-correlation.
+
+    The Pearson correlation coefficient [1]_ measures the linear relationship
+    between two datasets.  The calculation of the p-value relies on the
+    assumption that each dataset is normally distributed.  (See Kowalski [3]_
+    for a discussion of the effects of non-normality of the input on the
+    distribution of the correlation coefficient.)  Like other correlation
+    coefficients, this one varies between -1 and +1 with 0 implying no
+    correlation. Correlations of -1 or +1 imply an exact linear relationship.
+    Positive correlations imply that as x increases, so does y. Negative
+    correlations imply that as x increases, y decreases.
 
     The p-value roughly indicates the probability of an uncorrelated system
     producing datasets that have a Pearson correlation at least as extreme
-    as the one computed from these datasets. The p-values are not entirely
-    reliable but are probably reasonable for datasets larger than 500 or so.
+    as the one computed from these datasets.
 
     Parameters
     ----------
@@ -3261,7 +3288,24 @@ def pearsonr(x, y):
     r : float
         Pearson's correlation coefficient
     p-value : float
-        2-tailed p-value
+        two-tailed p-value
+
+    Warns
+    -----
+    PearsonRConstantInputWarning
+        Raised if an input is a constant array.  The correlation coefficient
+        is not defined in this case, so ``np.nan`` is returned.
+
+    PearsonRNearConstantInputWarning
+        Raised if an input is ""nearly"" constant.  The array ``x`` is considered
+        nearly constant if ``norm(x - mean(x)) < 1e-13 * abs(mean(x))``.
+        Numerical errors in the calculation ``x - mean(x)`` in this case might
+        result in an inaccurate calculation of r.
+
+    See Also
+    --------
+    spearmanr : Spearman rank-order correlation coefficient.
+    kendalltau : Kendall's tau, a correlation measure for ordinal data.
 
     Notes
     -----
@@ -3270,16 +3314,58 @@ def pearsonr(x, y):
 
     .. math::
 
-        r_{pb} = \frac{\sum (x - m_x) (y - m_y)}
-                      {\sqrt{\sum (x - m_x)^2 \sum (y - m_y)^2}}
+        r = \frac{\sum (x - m_x) (y - m_y)}
+                 {\sqrt{\sum (x - m_x)^2 \sum (y - m_y)^2}}
 
     where :math:`m_x` is the mean of the vector :math:`x` and :math:`m_y` is
     the mean of the vector :math:`y`.
 
+    Under the assumption that x and y are drawn from independent normal
+    distributions (so the population correlation coefficient is 0), the
+    probability density function of the sample correlation coefficient r
+    is ([1]_, [2]_)::
+
+               (1 - r**2)**(n/2 - 2)
+        f(r) = ---------------------
+                  B(1/2, n/2 - 1)
+
+    where n is the number of samples, and B is the beta function.  This
+    is sometimes referred to as the exact distribution of r.  This is
+    the distribution that is used in `pearsonr` to compute the p-value.
+    The distribution is a beta distribution on the interval [-1, 1],
+    with equal shape parameters a = b = n/2 - 1.  In terms of SciPy's
+    implementation of the beta distribution, the distribution of r is::
+
+        dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)
+
+    The p-value returned by `pearsonr` is a two-sided p-value.  For a
+    given sample with correlation coefficient r, the p-value is
+    the probability that abs(r') of a random sample x' and y' drawn from
+    the population with zero correlation would be greater than or equal
+    to abs(r).  In terms of the object `dist` shown above, the p-value
+    for a given r and length n can be computed as::
+
+        p = 2*dist.cdf(-abs(r))
+
+    When n is 2, the above continuous distribution is not well-defined.
+    One can interpret the limit of the beta distribution as the shape
+    parameters a and b approach a = b = 0 as a discrete distribution with
+    equal probability masses at r = 1 and r = -1.  More directly, one
+    can observe that, given the data x = [x1, x2] and y = [y1, y2], and
+    assuming x1 != x2 and y1 != y2, the only possible values for r are 1
+    and -1.  Because abs(r') for any sample x' and y' with length 2 will
+    be 1, the two-sided p-value for a sample of length 2 is always 1.
 
     References
     ----------
-    http://www.statsoft.com/textbook/glosp.html#Pearson%20Correlation
+    .. [1] ""Pearson correlation coefficient"", Wikipedia,
+           https://en.wikipedia.org/wiki/Pearson_correlation_coefficient
+    .. [2] Student, ""Probable error of a correlation coefficient"",
+           Biometrika, Volume 6, Issue 2-3, 1 September 1908, pp. 302-310.
+    .. [3] C. J. Kowalski, ""On the Effects of Non-Normality on the Distribution
+           of the Sample Product-Moment Correlation Coefficient""
+           Journal of the Royal Statistical Society. Series C (Applied
+           Statistics), Vol. 21, No. 1 (1972), pp. 1-12.
 
     Examples
     --------
@@ -3287,33 +3373,72 @@ def pearsonr(x, y):
     >>> a = np.array([0, 0, 0, 1, 1, 1, 1])
     >>> b = np.arange(7)
     >>> stats.pearsonr(a, b)
-    (0.8660254037844386, 0.011724811003954654)
+    (0.8660254037844386, 0.011724811003954649)
+
+    >>> stats.pearsonr([1, 2, 3, 4, 5], [10, 9, 2.5, 6, 4])
+    (-0.7426106572325057, 0.1505558088534455)
 
-    >>> stats.pearsonr([1,2,3,4,5], [5,6,7,8,7])
-    (0.83205029433784372, 0.080509573298498519)
     """"""
-    # x and y should have same length.
+    n = len(x)
+    if n != len(y):
+        raise ValueError('x and y must have the same length.')
+
+    if n < 2:
+        raise ValueError('x and y must have length at least 2.')
+
     x = np.asarray(x)
     y = np.asarray(y)
-    n = len(x)
-    mx = x.mean()
-    my = y.mean()
-    xm, ym = x - mx, y - my
-    r_num = np.add.reduce(xm * ym)
-    r_den = np.sqrt(_sum_of_squares(xm) * _sum_of_squares(ym))
-    r = r_num / r_den
+
+    # If an input is constant, the correlation coefficient is not defined.
+    if (x == x[0]).all() or (y == y[0]).all():
+        warnings.warn(PearsonRConstantInputWarning())
+        return np.nan, np.nan
+
+    # dtype is the data type for the calculations.  This expression ensures
+    # that the data type is at least 64 bit floating point.  It might have
+    # more precision if the input is, for example, np.longdouble.
+    dtype = type(1.0 + x[0] + y[0])
+
+    if n == 2:
+        return dtype(np.sign(x[1] - x[0])*np.sign(y[1] - y[0])), 1.0
+
+    xmean = x.mean(dtype=dtype)
+    ymean = y.mean(dtype=dtype)
+
+    # By using `astype(dtype)`, we ensure that the intermediate calculations
+    # use at least 64 bit floating point.
+    xm = x.astype(dtype) - xmean
+    ym = y.astype(dtype) - ymean
+
+    # Unlike np.linalg.norm or the expression sqrt((xm*xm).sum()),
+    # scipy.linalg.norm(xm) does not overflow if xm is, for example,
+    # [-5e210, 5e210, 3e200, -3e200]
+    normxm = linalg.norm(xm)
+    normym = linalg.norm(ym)
+
+    threshold = 1e-13
+    if normxm < threshold*abs(xmean) or normym < threshold*abs(ymean):
+        # If all the values in x (likewise y) are very close to the mean,
+        # the loss of precision that occurs in the subtraction xm = x - xmean
+        # might result in large errors in r.
+        warnings.warn(PearsonRNearConstantInputWarning())
+
+    r = np.dot(xm/normxm, ym/normym)
 
     # Presumably, if abs(r) > 1, then it is only some small artifact of
     # floating point arithmetic.
     r = max(min(r, 1.0), -1.0)
-    df = n - 2
-    if abs(r) == 1.0:
-        prob = 0.0
-    else:
-        t_squared = r**2 * (df / ((1.0 - r) * (1.0 + r)))
-        prob = special.betainc(
-            0.5*df, 0.5, np.fmin(np.asarray(df / (df + t_squared)), 1.0)
-        )
+
+    # As explained in the docstring, the p-value can be computed as
+    #     p = 2*dist.cdf(-abs(r))
+    # where dist is the beta distribution on [-1, 1] with shape parameters
+    # a = b = n/2 - 1.  `special.btdtr` is the CDF for the beta distribution
+    # on [0, 1].  To use it, we make the transformation  x = (r + 1)/2; the
+    # shape parameters do not change.  Then -abs(r) used in `cdf(-abs(r))`
+    # becomes x = (-abs(r) + 1)/2 = 0.5*(1 - abs(r)).  (r is cast to float64
+    # to avoid a TypeError raised by btdtr when r is higher precision.)
+    ab = n/2 - 1
+    prob = 2*special.btdtr(ab, ab, 0.5*(1 - abs(np.float64(r))))
 
     return r, prob
 
diff --git a/scipy/stats/tests/test_stats.py b/scipy/stats/tests/test_stats.py
index f17262caf48f..ed705ab84188 100644
--- a/scipy/stats/tests/test_stats.py
+++ b/scipy/stats/tests/test_stats.py
@@ -16,7 +16,7 @@
 from numpy.testing import (assert_, assert_equal,
                            assert_almost_equal, assert_array_almost_equal,
                            assert_array_equal, assert_approx_equal,
-                           assert_allclose)
+                           assert_allclose, assert_warns)
 import pytest
 from pytest import raises as assert_raises
 from scipy._lib._numpy_compat import suppress_warnings
@@ -255,19 +255,23 @@ def test_pROUNDROUND(self):
         r = y[0]
         assert_approx_equal(r,1.0)
 
-    def test_r_exactly_pos1(self):
+    def test_r_almost_exactly_pos1(self):
         a = arange(3.0)
-        b = a
-        r, prob = stats.pearsonr(a,b)
-        assert_equal(r, 1.0)
-        assert_equal(prob, 0.0)
+        r, prob = stats.pearsonr(a, a)
 
-    def test_r_exactly_neg1(self):
+        assert_allclose(r, 1.0, atol=1e-15)
+        # With n = len(a) = 3, the error in prob grows like the
+        # square root of the error in r.
+        assert_allclose(prob, 0.0, atol=np.sqrt(2*np.spacing(1.0)))
+
+    def test_r_almost_exactly_neg1(self):
         a = arange(3.0)
-        b = -a
-        r, prob = stats.pearsonr(a,b)
-        assert_equal(r, -1.0)
-        assert_equal(prob, 0.0)
+        r, prob = stats.pearsonr(a, -a)
+
+        assert_allclose(r, -1.0, atol=1e-15)
+        # With n = len(a) = 3, the error in prob grows like the
+        # square root of the error in r.
+        assert_allclose(prob, 0.0, atol=np.sqrt(2*np.spacing(1.0)))
 
     def test_basic(self):
         # A basic test, with a correlation coefficient
@@ -276,7 +280,106 @@ def test_basic(self):
         b = array([0, 0, 3])
         r, prob = stats.pearsonr(a, b)
         assert_approx_equal(r, np.sqrt(3)/2)
-        assert_approx_equal(prob, 1.0/3)
+        assert_approx_equal(prob, 1/3)
+
+    def test_constant_input(self):
+        # Zero variance input
+        # See https://github.com/scipy/scipy/issues/3728
+        with assert_warns(stats.PearsonRConstantInputWarning):
+            r, p = stats.pearsonr([0.667, 0.667, 0.667], [0.123, 0.456, 0.789])
+            assert_equal(r, np.nan)
+            assert_equal(p, np.nan)
+
+    def test_near_constant_input(self):
+        # Near constant input (but not constant):
+        x = [2, 2, 2 + np.spacing(2)]
+        y = [3, 3, 3 + 6*np.spacing(3)]
+        with assert_warns(stats.PearsonRNearConstantInputWarning):
+            # r and p are garbage, so don't bother checking them in this case.
+            # (The exact value of r would be 1.)
+            r, p = stats.pearsonr(x, y)
+
+    def test_very_small_input_values(self):
+        # Very small values in an input.  A naive implementation will
+        # suffer from underflow.
+        # See https://github.com/scipy/scipy/issues/9353
+        x = [0.004434375, 0.004756007, 0.003911996, 0.0038005, 0.003409971]
+        y = [2.48e-188, 7.41e-181, 4.09e-208, 2.08e-223, 2.66e-245]
+        r, p = stats.pearsonr(x,y)
+
+        # The expected values were computed using mpmath with 80 digits
+        # of precision.
+        assert_allclose(r, 0.7272930540750450)
+        assert_allclose(p, 0.1637805429533202)
+
+    def test_very_large_input_values(self):
+        # Very large values in an input.  A naive implementation will
+        # suffer from overflow.
+        # See https://github.com/scipy/scipy/issues/8980
+        x = 1e90*np.array([0, 0, 0, 1, 1, 1, 1])
+        y = 1e90*np.arange(7)
+
+        r, p = stats.pearsonr(x, y)
+
+        # The expected values were computed using mpmath with 80 digits
+        # of precision.
+        assert_allclose(r, 0.8660254037844386)
+        assert_allclose(p, 0.011724811003954638)
+
+    def test_extremely_large_input_values(self):
+        # Extremely large values in x and y.  These values would cause the
+        # product sigma_x * sigma_y to overflow if the two factors were
+        # computed independently.
+        x = np.array([2.3e200, 4.5e200, 6.7e200, 8e200])
+        y = np.array([1.2e199, 5.5e200, 3.3e201, 1.0e200])
+        r, p = stats.pearsonr(x, y)
+
+        # The expected values were computed using mpmath with 80 digits
+        # of precision.
+        assert_allclose(r, 0.351312332103289)
+        assert_allclose(p, 0.648687667896711)
+
+    def test_length_two_pos1(self):
+        # Inputs with length 2.
+        # See https://github.com/scipy/scipy/issues/7730
+        r, p = stats.pearsonr([1, 2], [3, 5])
+        assert_equal(r, 1)
+        assert_equal(p, 1)
+
+    def test_length_two_neg2(self):
+        # Inputs with length 2.
+        # See https://github.com/scipy/scipy/issues/7730
+        r, p = stats.pearsonr([2, 1], [3, 5])
+        assert_equal(r, -1)
+        assert_equal(p, 1)
+
+    def test_more_basic_examples(self):
+        x = [1, 2, 3, 4]
+        y = [0, 1, 0.5, 1]
+        r, p = stats.pearsonr(x, y)
+
+        # The expected values were computed using mpmath with 80 digits
+        # of precision.
+        assert_allclose(r, 0.674199862463242)
+        assert_allclose(p, 0.325800137536758)
+
+        x = [1, 2, 3]
+        y = [5, -4, -13]
+        r, p = stats.pearsonr(x, y)
+
+        # The expected r and p are exact.
+        assert_allclose(r, -1.0)
+        assert_allclose(p, 0.0)
+
+    def test_unequal_lengths(self):
+        x = [1, 2, 3]
+        y = [4, 5]
+        assert_raises(ValueError, stats.pearsonr, x, y)
+
+    def test_len1(self):
+        x = [1]
+        y = [2]
+        assert_raises(ValueError, stats.pearsonr, x, y)
 
 
 class TestFisherExact(object):
"
"update ckdtree to recent Cython conventions

This is a melded commit of several small changes that
brings the ckdtree code base to recent Cython conventions.

1. Split Python and C kdtree data.

This gets rid of the IMPL macro. The dependency is now simpler,
with C part no longer depending on the Python (I hope).

2. Convert old Cython ndarray to memoryviews.

3. lift the threading routines.

4. Use Cython C++ exception translation.

5. remove the special case handling of scalar query_ball_point.

6. minimize numpy and Python exposure in c++ code.
   and Use scipy's c99compat layer for inf, fmax, fmin.

7. Use cython to handle pickling.

8. Use the front method, and move sorting into c++.",6975656966bd526570af5616096487e10921f163,"diff --git a/scipy/spatial/ckdtree.pyx b/scipy/spatial/ckdtree.pyx
index 863137b9bc73..93d83fb59eee 100644
--- a/scipy/spatial/ckdtree.pyx
+++ b/scipy/spatial/ckdtree.pyx
@@ -13,42 +13,35 @@ import scipy.sparse
 
 cimport numpy as np
 from numpy.math cimport INFINITY
-    
+
 from cpython.mem cimport PyMem_Malloc, PyMem_Realloc, PyMem_Free
 from libc.string cimport memset, memcpy
+from libcpp.vector cimport vector
+from libcpp.algorithm cimport sort
 
 cimport cython
 
 from multiprocessing import cpu_count
 import threading
 
-cdef extern from ""limits.h"":
+cdef extern from ""<limits.h>"":
     long LONG_MAX
 
-cdef extern from ""ckdtree_methods.h"":
-    int number_of_processors
-    
-number_of_processors = cpu_count()
-
-from libcpp.vector cimport vector
-from libc cimport string
+cdef int number_of_processors = cpu_count()
 
 __all__ = ['cKDTree']
 
-    
-# Borrowed references
-# ===================
-
 cdef extern from *:
-    
-    struct ckdtree:
-        pass
-        
     int NPY_LIKELY(int)
     int NPY_UNLIKELY(int)
 
-       
+
+# C++ implementations
+# ===================
+
 cdef extern from ""ckdtree_decl.h"":
+    int ckdtree_isinf(np.float64_t x) nogil
+
     struct ckdtreenode:
         np.intp_t split_dim
         np.intp_t children
@@ -59,8 +52,96 @@ cdef extern from ""ckdtree_decl.h"":
         ckdtreenode *greater
         np.intp_t _less
         np.intp_t _greater
-    
-    
+
+    struct ckdtree:
+        vector[ckdtreenode]  *tree_buffer
+        ckdtreenode   *ctree
+        np.float64_t   *raw_data
+        np.intp_t      n
+        np.intp_t      m
+        np.intp_t      leafsize
+        np.float64_t   *raw_maxes
+        np.float64_t   *raw_mins
+        np.intp_t      *raw_indices
+        np.float64_t   *raw_boxsize_data
+        np.intp_t size
+
+    # External build and query methods in C++. Cython will
+    # release the GIL to avoid locking up the interpreter.
+
+    int build_ckdtree(ckdtree *self,
+                         np.intp_t start_idx,
+                         np.intp_t end_idx,
+                         np.float64_t *maxes,
+                         np.float64_t *mins,
+                         int _median,
+                         int _compact) nogil except +
+
+    int build_weights(ckdtree *self,
+                         np.float64_t *node_weights,
+                         np.float64_t *weights) nogil except +
+
+    int query_knn(const ckdtree *self,
+                     np.float64_t *dd,
+                     np.intp_t    *ii,
+                     const np.float64_t *xx,
+                     const np.intp_t    n,
+                     const np.intp_t    *k,
+                     const np.intp_t    nk,
+                     const np.intp_t    kmax,
+                     const np.float64_t eps,
+                     const np.float64_t p,
+                     const np.float64_t distance_upper_bound) nogil except +
+
+    int query_pairs(const ckdtree *self,
+                       const np.float64_t r,
+                       const np.float64_t p,
+                       const np.float64_t eps,
+                       vector[ordered_pair] *results) nogil except +
+
+    int count_neighbors_unweighted(const ckdtree *self,
+                           const ckdtree *other,
+                           np.intp_t     n_queries,
+                           np.float64_t  *real_r,
+                           np.intp_t     *results,
+                           const np.float64_t p,
+                           int cumulative) nogil except +
+
+    int count_neighbors_weighted(const ckdtree *self,
+                           const ckdtree *other,
+                           np.float64_t  *self_weights,
+                           np.float64_t  *other_weights,
+                           np.float64_t  *self_node_weights,
+                           np.float64_t  *other_node_weights,
+                           np.intp_t     n_queries,
+                           np.float64_t  *real_r,
+                           np.float64_t     *results,
+                           const np.float64_t p,
+                           int cumulative) nogil except +
+
+    int query_ball_point(const ckdtree *self,
+                            const np.float64_t *x,
+                            const np.float64_t *r,
+                            const np.float64_t p,
+                            const np.float64_t eps,
+                            const np.intp_t n_queries,
+                            vector[np.intp_t] **results,
+                            const int return_length) nogil except +
+
+    int query_ball_tree(const ckdtree *self,
+                           const ckdtree *other,
+                           const np.float64_t r,
+                           const np.float64_t p,
+                           const np.float64_t eps,
+                           vector[np.intp_t] **results) nogil except +
+
+    int sparse_distance_matrix(const ckdtree *self,
+                                  const ckdtree *other,
+                                  const np.float64_t p,
+                                  const np.float64_t max_distance,
+                                  vector[coo_entry] *results) nogil except +
+
+
 # C++ helper functions
 # ====================
 
@@ -77,48 +158,32 @@ cdef extern from ""ordered_pair.h"":
         np.intp_t i
         np.intp_t j
 
-def new_object(obj):
-    return obj.__new__(obj)
- 
-cdef extern from ""cpp_utils.h"": 
-    object pickle_tree_buffer(vector[ckdtreenode] *buf)    
-    object unpickle_tree_buffer(vector[ckdtreenode] *buf, object src)
-    ckdtreenode *tree_buffer_root(vector[ckdtreenode] *buf)
-    ordered_pair *ordered_pair_vector_buf(vector[ordered_pair] *buf)
-    coo_entry *coo_entry_vector_buf(vector[coo_entry] *buf)
-    void *tree_buffer_pointer(vector[ckdtreenode] *buf)
-    np.intp_t *npy_intp_vector_buf(vector[np.intp_t] *buf)
-    np.float64_t *npy_float64_vector_buf(vector[np.float64_t] *buf)
-    ctypedef void *intvector_ptr_t 
-
-
-
 # coo_entry wrapper
 # =================
 
 cdef class coo_entries:
 
-    cdef: 
+    cdef:
         readonly object __array_interface__
         vector[coo_entry] *buf
-        
-    def __cinit__(coo_entries self):    
+
+    def __cinit__(coo_entries self):
         self.buf = NULL
 
-    def __init__(coo_entries self):    
+    def __init__(coo_entries self):
         self.buf = new vector[coo_entry]()
-        
+
     def __dealloc__(coo_entries self):
         if self.buf != NULL:
             del self.buf
-            
+
     # The methods ndarray, dict, coo_matrix, and dok_matrix must only
     # be called after the buffer is filled with coo_entry data. This
     # is because std::vector can reallocate its internal buffer when
     # push_back is called.
-            
-    def ndarray(coo_entries self):    
-        cdef: 
+
+    def ndarray(coo_entries self):
+        cdef:
             coo_entry *pr
             np.uintp_t uintptr
             np.intp_t n
@@ -126,9 +191,9 @@ cdef class coo_entries:
         res_dtype = np.dtype(_dtype, align = True)
         n = <np.intp_t> self.buf.size()
         if NPY_LIKELY(n > 0):
-            pr = coo_entry_vector_buf(self.buf) 
+            pr = &self.buf.front()
             uintptr = <np.uintp_t> (<void*> pr)
-            dtype = np.dtype(np.uint8)               
+            dtype = np.dtype(np.uint8)
             self.__array_interface__ = dict(
                 data = (uintptr, False),
                 descr = dtype.descr,
@@ -136,11 +201,11 @@ cdef class coo_entries:
                 strides = (dtype.itemsize,),
                 typestr = dtype.str,
                 version = 3,
-            ) 
+            )
             return np.asarray(self).view(dtype=res_dtype)
         else:
             return np.empty(shape=(0,), dtype=res_dtype)
-        
+
     def dict(coo_entries self):
         cdef:
             np.intp_t i, j, k, n
@@ -149,59 +214,59 @@ cdef class coo_entries:
             dict res_dict
         n = <np.intp_t> self.buf.size()
         if NPY_LIKELY(n > 0):
-            pr = coo_entry_vector_buf(self.buf)        
-            res_dict = dict()           
-            for k in range(n):                    
+            pr = &self.buf.front()
+            res_dict = dict()
+            for k in range(n):
                 i = pr[k].i
                 j = pr[k].j
-                v = pr[k].v                    
+                v = pr[k].v
                 res_dict[(i,j)] = v
             return res_dict
         else:
             return {}
-    
+
     def coo_matrix(coo_entries self, m, n):
         res_arr = self.ndarray()
         return scipy.sparse.coo_matrix(
                        (res_arr['v'], (res_arr['i'], res_arr['j'])),
                                        shape=(m, n))
-        
+
     def dok_matrix(coo_entries self, m, n):
         return self.coo_matrix(m,n).todok()
-        
-        
+
+
 # ordered_pair wrapper
 # ====================
 
 cdef class ordered_pairs:
 
-    cdef: 
+    cdef:
         readonly object __array_interface__
         vector[ordered_pair] *buf
-        
+
     def __cinit__(ordered_pairs self):
         self.buf = NULL
 
     def __init__(ordered_pairs self):
         self.buf = new vector[ordered_pair]()
-        
+
     def __dealloc__(ordered_pairs self):
         if self.buf != NULL:
             del self.buf
-            
-    # The methods ndarray and set must only be called after the buffer 
+
+    # The methods ndarray and set must only be called after the buffer
     # is filled with ordered_pair data.
-    
+
     def ndarray(ordered_pairs self):
-        cdef: 
+        cdef:
             ordered_pair *pr
-            np.uintp_t uintptr 
-            np.intp_t n            
+            np.uintp_t uintptr
+            np.intp_t n
         n = <np.intp_t> self.buf.size()
         if NPY_LIKELY(n > 0):
-            pr = ordered_pair_vector_buf(self.buf) 
-            uintptr = <np.uintp_t> (<void*> pr)       
-            dtype = np.dtype(np.intp)               
+            pr = &self.buf.front()
+            uintptr = <np.uintp_t> (<void*> pr)
+            dtype = np.dtype(np.intp)
             self.__array_interface__ = dict(
                 data = (uintptr, False),
                 descr = dtype.descr,
@@ -213,29 +278,29 @@ cdef class ordered_pairs:
             return np.asarray(self)
         else:
             return np.empty(shape=(0,2), dtype=np.intp)
-        
-    def set(ordered_pairs self):        
-        cdef: 
+
+    def set(ordered_pairs self):
+        cdef:
             ordered_pair *pair
             np.intp_t i, n
             set results
         results = set()
-        pair = ordered_pair_vector_buf(self.buf)
+        pair = &self.buf.front()
         n = <np.intp_t> self.buf.size()
         if sizeof(long) < sizeof(np.intp_t):
             # Needed for Python 2.x on Win64
             for i in range(n):
                 results.add((int(pair.i), int(pair.j)))
-                pair += 1 
+                pair += 1
         else:
             # other platforms
             for i in range(n):
                 results.add((pair.i, pair.j))
                 pair += 1
         return results
-    
-        
-            
+
+
+
 # Tree structure exposed to Python
 # ================================
 
@@ -244,20 +309,20 @@ cdef class cKDTreeNode:
     class cKDTreeNode
 
     This class exposes a Python view of a node in the cKDTree object.
-    
+
     All attributes are read-only.
-    
+
     Attributes
     ----------
     level : int
         The depth of the node. 0 is the level of the root node.
     split_dim : int
-        The dimension along which this node is split. If this value is -1  
+        The dimension along which this node is split. If this value is -1
         the node is a leafnode in the kd-tree. Leafnodes are not split further
         and scanned by brute force.
     split : float
         The value used to separate split this node. Points with value >= split
-        in the split_dim dimension are sorted to the 'greater' subnode 
+        in the split_dim dimension are sorted to the 'greater' subnode
         whereas those with value < split are sorted to the 'lesser' subnode.
     children : int
         The number of data points sorted to this node.
@@ -283,16 +348,16 @@ cdef class cKDTreeNode:
         ckdtreenode           *_node
         np.ndarray            _data
         np.ndarray            _indices
-        
+
     cdef void _setup(cKDTreeNode self):
         self.split_dim = self._node.split_dim
         self.children = self._node.children
         self.split = self._node.split
-        
-    property data_points:   
+
+    property data_points:
         def __get__(cKDTreeNode self):
             return self._data[self.indices,:]
-                     
+
     property indices:
         def __get__(cKDTreeNode self):
             cdef np.intp_t i, start, stop
@@ -301,9 +366,9 @@ cdef class cKDTreeNode:
                 stop = self._node.end_idx
                 return self._indices[start:stop]
             else:
-                return np.hstack([self.lesser.indices, 
+                return np.hstack([self.lesser.indices,
                            self.greater.indices])
-                           
+
     property lesser:
         def __get__(cKDTreeNode self):
             if self.split_dim == -1:
@@ -316,7 +381,7 @@ cdef class cKDTreeNode:
                 n.level = self.level + 1
                 n._setup()
                 return n
-                
+
     property greater:
         def __get__(cKDTreeNode self):
             if self.split_dim == -1:
@@ -330,91 +395,11 @@ cdef class cKDTreeNode:
                 n._setup()
                 return n
 
-    
+
 # Main cKDTree class
 # ==================
 
-cdef extern from ""ckdtree_methods.h"":
-
-    # External build and query methods in C++. These will internally
-    # release the GIL to avoid locking up the interpreter.
-    
-    int ckdtree_isinf(np.float64_t x)
-    
-    object build_ckdtree(ckdtree *self, 
-                         np.intp_t start_idx, 
-                         np.intp_t end_idx,
-                         np.float64_t *maxes, 
-                         np.float64_t *mins, 
-                         int _median, 
-                         int _compact)
-
-    object build_weights(ckdtree *self, 
-                         np.float64_t *node_weights,
-                         np.float64_t *weights)
-       
-    object query_knn(const ckdtree *self, 
-                     np.float64_t *dd, 
-                     np.intp_t    *ii, 
-                     const np.float64_t *xx,
-                     const np.intp_t    n,
-                     const np.intp_t    *k, 
-                     const np.intp_t    nk, 
-                     const np.intp_t    kmax, 
-                     const np.float64_t eps, 
-                     const np.float64_t p, 
-                     const np.float64_t distance_upper_bound) 
-                     
-    object query_pairs(const ckdtree *self, 
-                       const np.float64_t r, 
-                       const np.float64_t p, 
-                       const np.float64_t eps,
-                       vector[ordered_pair] *results)
-
-    object count_neighbors_unweighted(const ckdtree *self,
-                           const ckdtree *other,
-                           np.intp_t     n_queries,
-                           np.float64_t  *real_r,
-                           np.intp_t     *results,
-                           const np.float64_t p,
-                           int cumulative)
-
-    object count_neighbors_weighted(const ckdtree *self,
-                           const ckdtree *other,
-                           np.float64_t  *self_weights,
-                           np.float64_t  *other_weights,
-                           np.float64_t  *self_node_weights,
-                           np.float64_t  *other_node_weights,
-                           np.intp_t     n_queries,
-                           np.float64_t  *real_r,
-                           np.float64_t     *results,
-                           const np.float64_t p,
-                           int cumulative)
-
-    object query_ball_point(const ckdtree *self,
-                            const np.float64_t *x,
-                            const np.float64_t *r,
-                            const np.float64_t p,
-                            const np.float64_t eps,
-                            const np.intp_t n_queries,
-                            vector[np.intp_t] **results,
-                            const int return_length)
-
-    object query_ball_tree(const ckdtree *self,
-                           const ckdtree *other,
-                           const np.float64_t r,
-                           const np.float64_t p,
-                           const np.float64_t eps,
-                           vector[np.intp_t] **results)                     
-     
-    object sparse_distance_matrix(const ckdtree *self,
-                                  const ckdtree *other,
-                                  const np.float64_t p,
-                                  const np.float64_t max_distance,
-                                  vector[coo_entry] *results)                    
-                      
-                      
-cdef public class cKDTree [object ckdtree, type ckdtree_type]:
+cdef class cKDTree:
     """"""
     cKDTree(data, leafsize=16, compact_nodes=True, copy_data=False,
             balanced_tree=True, boxsize=None)
@@ -423,54 +408,54 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
     This class provides an index into a set of k-dimensional points
     which can be used to rapidly look up the nearest neighbors of any
-    point. 
+    point.
 
-    The algorithm used is described in Maneewongvatana and Mount 1999. 
+    The algorithm used is described in Maneewongvatana and Mount 1999.
     The general idea is that the kd-tree is a binary trie, each of whose
     nodes represents an axis-aligned hyperrectangle. Each node specifies
     an axis and splits the set of points based on whether their coordinate
-    along that axis is greater than or less than a particular value. 
+    along that axis is greater than or less than a particular value.
 
-    During construction, the axis and splitting point are chosen by the 
+    During construction, the axis and splitting point are chosen by the
     ""sliding midpoint"" rule, which ensures that the cells do not all
-    become long and thin. 
+    become long and thin.
 
-    The tree can be queried for the r closest neighbors of any given point 
-    (optionally returning only those within some maximum distance of the 
-    point). It can also be queried, with a substantial gain in efficiency, 
+    The tree can be queried for the r closest neighbors of any given point
+    (optionally returning only those within some maximum distance of the
+    point). It can also be queried, with a substantial gain in efficiency,
     for the r approximate closest neighbors.
 
-    For large dimensions (20 is already large) do not expect this to run 
+    For large dimensions (20 is already large) do not expect this to run
     significantly faster than brute force. High-dimensional nearest-neighbor
     queries are a substantial open problem in computer science.
 
     Parameters
     ----------
     data : array_like, shape (n,m)
-        The n data points of dimension m to be indexed. This array is 
-        not copied unless this is necessary to produce a contiguous 
-        array of doubles, and so modifying this data will result in 
+        The n data points of dimension m to be indexed. This array is
+        not copied unless this is necessary to produce a contiguous
+        array of doubles, and so modifying this data will result in
         bogus results. The data are also copied if the kd-tree is built
         with copy_data=True.
     leafsize : positive int, optional
         The number of points at which the algorithm switches over to
         brute-force. Default: 16.
-    compact_nodes : bool, optional    
+    compact_nodes : bool, optional
         If True, the kd-tree is built to shrink the hyperrectangles to
-        the actual data range. This usually gives a more compact tree that 
-        is robust against degenerated input data and gives faster queries 
+        the actual data range. This usually gives a more compact tree that
+        is robust against degenerated input data and gives faster queries
         at the expense of longer build time. Default: True.
     copy_data : bool, optional
-        If True the data is always copied to protect the kd-tree against 
+        If True the data is always copied to protect the kd-tree against
         data corruption. Default: False.
-    balanced_tree : bool, optional    
-        If True, the median is used to split the hyperrectangles instead of 
-        the midpoint. This usually gives a more compact tree and 
+    balanced_tree : bool, optional
+        If True, the median is used to split the hyperrectangles instead of
+        the midpoint. This usually gives a more compact tree and
         faster queries at the expense of longer build time. Default: True.
     boxsize : array_like or scalar, optional
-        Apply a m-d toroidal topology to the KDTree.. The topology is generated 
+        Apply a m-d toroidal topology to the KDTree.. The topology is generated
         by :math:`x_i + n_i L_i` where :math:`n_i` are integers and :math:`L_i`
-        is the boxsize along i-th dimension. The input data shall be wrapped 
+        is the boxsize along i-th dimension. The input data shall be wrapped
         into :math:`[0, L_i)`. A ValueError is raised if any of the data is
         outside of this bound.
 
@@ -503,54 +488,56 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
     """"""
     cdef:
-        vector[ckdtreenode]      *tree_buffer
-        ckdtreenode              *ctree 
-        readonly cKDTreeNode     tree 
+        ckdtree * cself
+        readonly cKDTreeNode     tree
         readonly np.ndarray      data
-        np.float64_t             *raw_data
-        readonly np.intp_t       n, m
-        readonly np.intp_t       leafsize
         readonly np.ndarray      maxes
-        np.float64_t             *raw_maxes
         readonly np.ndarray      mins
-        np.float64_t             *raw_mins
         readonly np.ndarray      indices
-        np.intp_t                *raw_indices
-        np.ndarray               _median_workspace
         readonly object          boxsize
         np.ndarray               boxsize_data
-        np.float64_t             *raw_boxsize_data
-        readonly np.intp_t       size
+
+    property n:
+        def __get__(self): return self.cself.n
+    property m:
+        def __get__(self): return self.cself.m
+    property leafsize:
+        def __get__(self): return self.cself.leafsize
+    property size:
+        def __get__(self): return self.cself.size
 
     def __cinit__(cKDTree self):
-        self.tree_buffer = NULL        
-            
-    def __init__(cKDTree self, data, np.intp_t leafsize=16, compact_nodes=True, 
+        self.cself = <ckdtree * > PyMem_Malloc(sizeof(ckdtree))
+        self.cself.tree_buffer = NULL
+
+    def __init__(cKDTree self, data, np.intp_t leafsize=16, compact_nodes=True,
             copy_data=False, balanced_tree=True, boxsize=None):
-        cdef np.ndarray[np.float64_t, ndim=2] data_arr
-        cdef np.float64_t *tmp
-        cdef int _median, _compact
-        cdef np.ndarray[np.float64_t, ndim=1] boxsize_arr
-        data_arr = np.ascontiguousarray(data, dtype=np.float64)
-        if copy_data and (data_arr is data):
-            data_arr = data_arr.copy()
-        self.data = data_arr
-        self.n = data_arr.shape[0]
-        self.m = data_arr.shape[1]
-        self.leafsize = leafsize
-        if self.leafsize<1:
+        cdef np.float64_t [::1] tmpmaxes, tmpmins
+        cdef ckdtree * cself = self.cself
+
+        data = np.array(data, order='C', copy=copy_data, dtype=np.float64)
+
+        if data.ndim != 2:
+            raise ValueError(""data must be 2 dimensions"")
+
+        self.data = data
+        cself.n = data.shape[0]
+        cself.m = data.shape[1]
+        cself.leafsize = leafsize
+
+        if leafsize<1:
             raise ValueError(""leafsize must be at least 1"")
 
         if boxsize is None:
             self.boxsize = None
             self.boxsize_data = None
         else:
-            boxsize_arr = np.empty(2 * self.m, dtype=np.float64)
-            boxsize_arr[:self.m] = boxsize
-            boxsize_arr[self.m:] = 0.5 * boxsize_arr[:self.m]
-            # FIXME: how to use a matching del if new is used?
-            self.boxsize_data = boxsize_arr
-            self.boxsize = boxsize_arr[:self.m].copy()
+            self.boxsize_data = np.empty(2 * self.m, dtype=np.float64)
+            boxsize = np.float64(np.broadcast_to(boxsize, self.m))
+            self.boxsize_data[:self.m] = boxsize
+            self.boxsize_data[self.m:] = 0.5 * boxsize
+
+            self.boxsize = boxsize
             periodic_mask = self.boxsize > 0
             if ((self.data >= self.boxsize[None, :])[:, periodic_mask]).any():
                 raise ValueError(""Some input data are greater than the size of the periodic box."")
@@ -563,61 +550,55 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
         self._pre_init()
 
-        _compact = 1 if compact_nodes else 0
-        _median = 1 if balanced_tree else 0
-        if _median:
-            self._median_workspace = np.zeros(self.n)
+        compact = 1 if compact_nodes else 0
+        median = 1 if balanced_tree else 0
 
-        self.tree_buffer = new vector[ckdtreenode]()
-        
-        try:
-            tmp = <np.float64_t*> PyMem_Malloc(self.m*2*sizeof(np.float64_t))
-            if tmp == NULL: raise MemoryError()            
-            memcpy(tmp, self.raw_maxes, self.m*sizeof(np.float64_t))
-            memcpy(tmp + self.m, self.raw_mins, self.m*sizeof(np.float64_t))
-            build_ckdtree(<ckdtree*> self, 0, self.n, tmp, tmp + self.m, 
-                _median, _compact)
-        finally:
-            PyMem_Free(tmp)
+        cself.tree_buffer = new vector[ckdtreenode]()
+
+        tmpmaxes = np.copy(self.maxes)
+        tmpmins = np.copy(self.mins)
+
+        build_ckdtree(cself, 0, cself.n, &tmpmaxes[0], &tmpmins[0], median, compact)
 
-        self._median_workspace = None
-        
         # set up the tree structure pointers
         self._post_init()
-        
-        # make the tree viewable from Python
-        self.tree = cKDTreeNode()
-        self.tree._node = self.ctree
-        self.tree._data = self.data
-        self.tree._indices = self.indices
-        self.tree.level = 0
-        self.tree._setup()
 
-    cdef int _pre_init(cKDTree self) except -1:
+    cdef _pre_init(cKDTree self):
+        cself = self.cself
 
         # finalize the pointers from array attributes
 
-        self.raw_data = <np.float64_t*> np.PyArray_DATA(self.data)
-        self.raw_maxes = <np.float64_t*> np.PyArray_DATA(self.maxes)
-        self.raw_mins = <np.float64_t*> np.PyArray_DATA(self.mins)
-        self.raw_indices = <np.intp_t*> np.PyArray_DATA(self.indices)
+        cself.raw_data = <np.float64_t*> np.PyArray_DATA(self.data)
+        cself.raw_maxes = <np.float64_t*> np.PyArray_DATA(self.maxes)
+        cself.raw_mins = <np.float64_t*> np.PyArray_DATA(self.mins)
+        cself.raw_indices = <np.intp_t*> np.PyArray_DATA(self.indices)
 
         if self.boxsize_data is not None:
-            self.raw_boxsize_data = <np.float64_t*>np.PyArray_DATA(self.boxsize_data)
-
-        return 0        
+            cself.raw_boxsize_data = <np.float64_t*>np.PyArray_DATA(self.boxsize_data)
+        else:
+            cself.raw_boxsize_data = NULL
 
-    cdef int _post_init(cKDTree self) except -1:
+    cdef _post_init(cKDTree self):
+        cself = self.cself
         # finalize the tree points, this calls _post_init_traverse
-        
-        self.ctree = tree_buffer_root(self.tree_buffer)
+
+        cself.ctree = &cself.tree_buffer.front()
 
         # set the size attribute after tree_buffer is built
-        self.size = self.tree_buffer.size()
+        cself.size = cself.tree_buffer.size()
+
+        self._post_init_traverse(cself.ctree)
+
+        # make the tree viewable from Python
+        self.tree = cKDTreeNode()
+        self.tree._node = cself.ctree
+        self.tree._data = self.data
+        self.tree._indices = self.indices
+        self.tree.level = 0
+        self.tree._setup()
 
-        return self._post_init_traverse(self.ctree)
-         
-    cdef int _post_init_traverse(cKDTree self, ckdtreenode *node) except -1:
+    cdef _post_init_traverse(cKDTree self, ckdtreenode *node):
+        cself = self.cself
         # recurse the tree and re-initialize
         # ""less"" and ""greater"" fields
         if node.split_dim == -1:
@@ -625,22 +606,21 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             node.less = NULL
             node.greater = NULL
         else:
-            node.less = self.ctree + node._less
-            node.greater = self.ctree + node._greater
+            node.less = cself.ctree + node._less
+            node.greater = cself.ctree + node._greater
             self._post_init_traverse(node.less)
             self._post_init_traverse(node.greater)
-                
-        return 0
-        
 
     def __dealloc__(cKDTree self):
-        if self.tree_buffer != NULL:
-            del self.tree_buffer
+        cself = self.cself
+        if cself.tree_buffer != NULL:
+            del cself.tree_buffer
+        PyMem_Free(cself)
 
     # -----
     # query
     # -----
-    
+
     @cython.boundscheck(False)
     def query(cKDTree self, object x, object k=1, np.float64_t eps=0,
               np.float64_t p=2, np.float64_t distance_upper_bound=INFINITY,
@@ -655,15 +635,15 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         x : array_like, last dimension self.m
             An array of points to query.
         k : list of integer or integer
-            The list of k-th nearest neighbors to return. If k is an 
+            The list of k-th nearest neighbors to return. If k is an
             integer it is treated as a list of [1, ... k] (range(1, k+1)).
             Note that the counting starts from 1.
         eps : non-negative float
-            Return approximate nearest neighbors; the k-th returned value 
-            is guaranteed to be no further than (1+eps) times the 
+            Return approximate nearest neighbors; the k-th returned value
+            is guaranteed to be no further than (1+eps) times the
             distance to the real k-th nearest neighbor.
         p : float, 1<=p<=infinity
-            Which Minkowski p-norm to use. 
+            Which Minkowski p-norm to use.
             1 is the sum-of-absolute-values ""Manhattan"" distance
             2 is the usual Euclidean distance
             infinity is the maximum-coordinate-difference distance
@@ -676,11 +656,11 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         n_jobs : int, optional
             Number of jobs to schedule for parallel processing. If -1 is given
             all processors are used. Default: 1.
-                        
+
         Returns
         -------
         d : array of floats
-            The distances to the nearest neighbors. 
+            The distances to the nearest neighbors.
             If ``x`` has shape ``tuple+(self.m,)``, then ``d`` has shape ``tuple+(k,)``.
             When k == 1, the last dimension of the output is squeezed.
             Missing neighbors are indicated with infinite distances.
@@ -694,9 +674,9 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         -----
         If the KD-Tree is periodic, the position ``x`` is wrapped into the
         box.
-        
+
         When the input k is a list, a query for arange(max(k)) is performed, but
-        only columns that store the requested values of k are preserved. This is 
+        only columns that store the requested values of k are preserved. This is
         implemented in a manner that reduces memory usage.
 
         Examples
@@ -746,11 +726,11 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
          [13 12]]
 
         """"""
-        
+
         cdef:
             np.intp_t n, i, j
             int overflown
-        
+
         x_arr = np.asarray(x, dtype=np.float64)
         if x_arr.ndim == 0 or x_arr.shape[x_arr.ndim - 1] != self.m:
             raise ValueError(""x must consist of vectors of length %d but ""
@@ -768,55 +748,31 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             if k == 1:
                 nearest = True
             k = np.arange(1, k + 1)
-    
+
         retshape = np.shape(x)[:-1]
         n = <np.intp_t> np.prod(retshape)
-        xx = np.ascontiguousarray(x_arr).reshape(n, self.m)
+        cdef np.float64_t [:, ::1] xx = np.ascontiguousarray(x_arr).reshape(n, self.m)
 
         # The C++ function touches all dd and ii entries,
         # setting the missing values.
 
-        dd = np.empty((n,len(k)),dtype=np.float64)
-        ii = np.empty((n,len(k)),dtype=np.intp)
+        cdef np.float64_t [:, ::1] dd = np.empty((n,len(k)),dtype=np.float64)
+        cdef np.intp_t [:, ::1] ii = np.empty((n,len(k)),dtype=np.intp)
+        cdef np.intp_t [::1] kk = np.array(k, dtype=np.intp)
 
-        # Do the query in an external C++ function. 
+        cdef np.intp_t kmax = np.max(k)
+
+        # Do the query in an external C++ function.
         # The GIL will be released in the external query function.
-        def _thread_func(self, np.intp_t start, np.intp_t stop):
-            cdef: 
-                np.ndarray[np.intp_t,ndim=2] _ii = ii
-                np.ndarray[np.float64_t,ndim=2] _dd = dd
-                np.ndarray[np.float64_t,ndim=2] _xx = xx
-                np.ndarray[np.intp_t,ndim=1] _k = np.array(k, dtype=np.intp)
-            
-            kmax = np.max(k)
-
-            query_knn(<ckdtree*>self, &_dd[start,0], &_ii[start,0], 
-                &_xx[start,0], stop-start, &_k[0], len(k), kmax, eps, p, distance_upper_bound)
-        
-        if (n_jobs == -1): 
+        def _thread_func(np.intp_t start, np.intp_t stop):
+            query_knn(self.cself, &dd[start,0], &ii[start,0],
+                &xx[start,0], stop-start, &kk[0], kk.shape[0], kmax, eps, p, distance_upper_bound)
+
+        if (n_jobs == -1):
             n_jobs = number_of_processors
-        
-        if n_jobs > 1:
-            # static scheduling without load balancing is good enough
-                             
-            ranges = [(j * n // n_jobs, (j + 1) * n // n_jobs)
-                            for j in range(n_jobs)]
-            
-            # There might be n_jobs+1 threads spawned here, but only n_jobs of 
-            # them will do significant work.
-            threads = [threading.Thread(target=_thread_func,
-                                args=(self, start, stop)) for start, stop in ranges]
-
-            # Set the daemon flag so the process can be aborted, 
-            # start all threads and wait for completion.
-            for t in threads:
-                t.daemon = True
-                t.start()
-            for t in threads: 
-                t.join()
-        else:
-            _thread_func(self, 0, n)
-                
+
+        _run_threads(_thread_func, n, n_jobs)
+
         # massage the output in conformabity to the documented behavior
 
         if sizeof(long) < sizeof(np.intp_t):
@@ -828,7 +784,7 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                         # C long overlow, return array of dtype=np.int_p
                         overflown = True
                         break
-                if overflown: 
+                if overflown:
                     break
 
             if overflown:
@@ -836,8 +792,8 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                 iiret = np.reshape(ii,retshape+(len(k),))
             else:
                 ddret = np.reshape(dd,retshape+(len(k),))
-                iiret = np.reshape(ii,retshape+(len(k),)).astype(int) 
-                        
+                iiret = np.reshape(ii,retshape+(len(k),)).astype(int)
+
         else:
             # ... most other platforms
             ddret = np.reshape(dd,retshape+(len(k),))
@@ -850,7 +806,7 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             if single:
                 ddret = float(ddret)
                 iiret = int(iiret)
-            
+
         return ddret, iiret
 
     # ----------------
@@ -863,7 +819,7 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                          return_length=False):
         """"""
         query_ball_point(self, x, r, p=2., eps=0)
-        
+
         Find all points within distance r of point(s) x.
 
         Parameters
@@ -920,62 +876,27 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         """"""
 
         cdef:
-            np.float64_t[::1] xx
-            np.float64_t rr
-            vector[np.intp_t] *vres
-
             np.float64_t[::1] vrr
             np.float64_t[:, ::1] vxx
             object[::1] vout
             np.intp_t[::1] vlen
-            np.uintp_t vvres_uintp
-            np.intp_t *cur
             list tmp
             np.intp_t i, j, n, m
-
-        vres = NULL
+            np.intp_t xndim
 
         x = np.asarray(x, dtype=np.float64)
         if x.shape[-1] != self.m:
             raise ValueError(""Searching for a %d-dimensional point in a ""
-                             ""%d-dimensional KDTree"" % 
+                             ""%d-dimensional KDTree"" %
                                  (int(x.shape[-1]), int(self.m)))
 
         r = np.array(np.broadcast_to(r, x.shape[:-1]), order='C', dtype=np.float64)
 
-        if len(x.shape) == 1:
-            try:
-                # special case: query a single point
-                rr = r
-                vres = new vector[np.intp_t]()
-                xx = np.ascontiguousarray(x, dtype=np.float64)
-                query_ball_point(<ckdtree*> self, &xx[0], &rr, p, eps, 1, &vres, return_length)
-
-                cur = npy_intp_vector_buf(vres)
-
-                if return_length:
-                    return cur[0]
-
-                n = <np.intp_t> vres.size()
-
-                tmp = n * [None]
-                if NPY_LIKELY(n > 0):
-                    for i in range(n):
-                        tmp[i] = cur[0]
-                        cur += 1
-                if return_sorted:
-                    tmp = sorted(tmp)
-
-                result = tmp
-
-                return result
-            finally:
-                if vres != NULL:
-                    del vres
-
-        # query many points
         retshape = x.shape[:-1]
 
+        # scalar query if xndim == 1
+        xndim = x.ndim
+
         # allocate an array of std::vector<npy_intp>
         n = np.prod(retshape)
 
@@ -989,40 +910,42 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         vxx = np.reshape(x, (-1, x.shape[-1]))
         vrr = np.reshape(r, (-1))
 
-        # multithreading logic is similar to cKDTree.query
-        if (n_jobs == -1):
-            n_jobs = number_of_processors
-
         def _thread_func(np.intp_t start, np.intp_t stop):
             cdef vector[np.intp_t] **vvres
-
+            cdef np.intp_t i
+            cdef np.intp_t *cur
             try:
                 vvres = (<vector[np.intp_t] **>
-                    PyMem_Malloc((stop-start) * sizeof(intvector_ptr_t)))
+                    PyMem_Malloc((stop-start) * sizeof(void*)))
                 if vvres == NULL:
                     raise MemoryError()
 
-                memset(<void*> vvres, 0, (stop-start) * sizeof(intvector_ptr_t))
+                memset(<void*> vvres, 0, (stop-start) * sizeof(void*))
 
                 for i in range(stop - start):
                     vvres[i] = new vector[np.intp_t]()
 
-                query_ball_point(<ckdtree*>self, &vxx[start, 0],
+                query_ball_point(self.cself, &vxx[start, 0],
                     &vrr[start + 0], p, eps, stop - start, vvres, return_length)
 
                 for i in range(stop - start):
-                    cur = npy_intp_vector_buf(vvres[i])
                     if return_length:
-                        vlen[start + i] = cur[0]
+                        vlen[start + i] = vvres[i].front()
                         continue
 
+                    if return_sorted:
+                        sort(vvres[i].begin(), vvres[i].end())
+                    elif return_sorted is None and xndim > 1:
+                        # compatibility with the old bug not sorting scalar queries.
+                        sort(vvres[i].begin(), vvres[i].end())
+
                     m = <np.intp_t> (vvres[i].size())
                     tmp = m * [None]
+
+                    cur = &vvres[i].front()
                     for j in range(m):
                         tmp[j] = cur[0]
                         cur += 1
-                    if return_sorted or return_sorted is None:
-                        tmp = sorted(tmp)
                     vout[start + i] = tmp
             finally:
                 if vvres != NULL:
@@ -1031,28 +954,20 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                             del vvres[i]
                     PyMem_Free(vvres)
 
-        if n_jobs > 1:
-            ranges = [(j * n // n_jobs, (j + 1) * n // n_jobs)
-                            for j in range(n_jobs)]
-
-            threads = [threading.Thread(target=_thread_func,
-                       args=(start, end))
-                       for start, end in ranges]
-            for t in threads:
-                t.daemon = True
-                t.start()
-            for t in threads:
-                t.join()
+        # multithreading logic is similar to cKDTree.query
+        if n_jobs == -1:
+            n_jobs = number_of_processors
 
-        else:
-            _thread_func(0, n)
+        _run_threads(_thread_func, n, n_jobs)
 
+        if xndim == 1: # scalar query, unpack result.
+            result = result[()]
         return result
 
     # ---------------
     # query_ball_tree
     # ---------------
-    
+
     def query_ball_tree(cKDTree self, cKDTree other,
                         np.float64_t r, np.float64_t p=2., np.float64_t eps=0):
         """"""
@@ -1083,8 +998,8 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             list of the indices of its neighbors in ``other.data``.
 
         """"""
-        
-        cdef: 
+
+        cdef:
             vector[np.intp_t] **vvres
             np.intp_t i, j, n, m
             np.intp_t *cur
@@ -1095,46 +1010,46 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         if self.m != other.m:
             raise ValueError(""Trees passed to query_ball_tree have different ""
                              ""dimensionality"")
-     
+
         n = self.n
-        
+
         try:
-        
+
             # allocate an array of std::vector<npy_intp>
-            vvres = (<vector[np.intp_t] **> 
-                PyMem_Malloc(n * sizeof(intvector_ptr_t)))
+            vvres = (<vector[np.intp_t] **>
+                PyMem_Malloc(n * sizeof(void*)))
             if vvres == NULL:
                 raise MemoryError()
-                
-            memset(<void*> vvres, 0, n * sizeof(intvector_ptr_t))      
-            
+
+            memset(<void*> vvres, 0, n * sizeof(void*))
+
             for i in range(n):
                 vvres[i] = new vector[np.intp_t]()
-        
+
             # query in C++
             # the GIL will be released in the C++ code
-            query_ball_tree(
-                <ckdtree*> self, <ckdtree*> other, r, p, eps, vvres)
-                          
-            # store the results in a list of lists                                        
+            query_ball_tree(self.cself, other.cself, r, p, eps, vvres)
+
+            # store the results in a list of lists
             results = n * [None]
             for i in range(n):
                 m = <np.intp_t> (vvres[i].size())
                 if NPY_LIKELY(m > 0):
                     tmp = m * [None]
-                    cur = npy_intp_vector_buf(vvres[i]) 
+                    sort(vvres[i].begin(), vvres[i].end())
+                    cur = &vvres[i].front()
                     for j in range(m):
                         tmp[j] = cur[0]
                         cur += 1
-                    results[i] = sorted(tmp)
+                    results[i] = tmp
                 else:
-                    results[i] = []    
-                                  
+                    results[i] = []
+
         finally:
             if vvres != NULL:
                 for i in range(n):
                     if vvres[i] != NULL:
-                        del vvres[i]     
+                        del vvres[i]
                 PyMem_Free(vvres)
 
         return results
@@ -1142,7 +1057,7 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
     # -----------
     # query_pairs
     # -----------
-    
+
     def query_pairs(cKDTree self, np.float64_t r, np.float64_t p=2.,
                     np.float64_t eps=0, output_type='set'):
         """"""
@@ -1170,22 +1085,22 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         -------
         results : set or ndarray
             Set of pairs ``(i,j)``, with ``i < j``, for which the corresponding
-            positions are close. If output_type is 'ndarray', an ndarry is 
+            positions are close. If output_type is 'ndarray', an ndarry is
             returned instead of a set.
 
         """"""
-                 
+
         cdef ordered_pairs results
 
         results = ordered_pairs()
-        query_pairs(<ckdtree*> self, r, p, eps, results.buf)
-        
+        query_pairs(self.cself, r, p, eps, results.buf)
+
         if output_type == 'set':
             return results.set()
         elif output_type == 'ndarray':
             return results.ndarray()
         else:
-            raise ValueError(""Invalid output type"") 
+            raise ValueError(""Invalid output type"")
 
     def _build_weights(cKDTree self, object weights):
         """"""
@@ -1208,20 +1123,19 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
         """"""
         cdef np.intp_t num_of_nodes
-        cdef np.ndarray[np.float64_t, ndim=1, mode=""c""] node_weights
-        cdef np.ndarray[np.float64_t, ndim=1, mode=""c""] proper_weights
+        cdef np.float64_t [::1] node_weights
+        cdef np.float64_t [::1] proper_weights
 
-        num_of_nodes = self.tree_buffer.size();
+        num_of_nodes = self.cself.tree_buffer.size();
         node_weights = np.empty(num_of_nodes, dtype=np.float64)
 
-        # FIXME: use templates to avoid the type conversion 
+        # FIXME: use templates to avoid the type conversion
         proper_weights = np.ascontiguousarray(weights, dtype=np.float64)
 
         if len(proper_weights) != self.n:
             raise ValueError('Number of weights differ from the number of data points')
 
-        build_weights(<ckdtree*> self, <np.float64_t*>np.PyArray_DATA(node_weights),
-                            <np.float64_t*> np.PyArray_DATA(proper_weights))
+        build_weights(self.cself, &node_weights[0], &proper_weights[0])
 
         return node_weights
 
@@ -1230,7 +1144,7 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
     # ---------------
 
     @cython.boundscheck(False)
-    def count_neighbors(cKDTree self, cKDTree other, object r, np.float64_t p=2., 
+    def count_neighbors(cKDTree self, cKDTree other, object r, np.float64_t p=2.,
                         object weights=None, int cumulative=True):
         """"""
         count_neighbors(self, other, r, p=2., weights=None, cumulative=True)
@@ -1252,18 +1166,18 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             The other tree to draw points from, can be the same tree as self.
         r : float or one-dimensional array of floats
             The radius to produce a count for. Multiple radii are searched with
-            a single tree traversal. 
-            If the count is non-cumulative(``cumulative=False``), ``r`` defines 
+            a single tree traversal.
+            If the count is non-cumulative(``cumulative=False``), ``r`` defines
             the edges of the bins, and must be non-decreasing.
-        p : float, optional 
-            1<=p<=infinity. 
+        p : float, optional
+            1<=p<=infinity.
             Which Minkowski p-norm to use.
             Default 2.0.
             A finite large p may cause a ValueError if overflow can occur.
         weights : tuple, array_like, or None, optional
             If None, the pair-counting is unweighted.
             If given as a tuple, weights[0] is the weights of points in ``self``, and
-            weights[1] is the weights of points in ``other``; either can be None to 
+            weights[1] is the weights of points in ``other``; either can be None to
             indicate the points are unweighted.
             If given as an array_like, weights is the weights of points in ``self``
             and ``other``. For this to make sense, ``self`` and ``other`` must be the
@@ -1353,18 +1267,18 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         .. [5] https://github.com/scipy/scipy/pull/5647#issuecomment-168474926
 
         """"""
-        cdef: 
+        cdef:
             int r_ndim
             np.intp_t n_queries, i
-            np.ndarray[np.float64_t, ndim=1, mode=""c""] real_r
-            np.ndarray[np.float64_t, ndim=1, mode=""c""] fresults
-            np.ndarray[np.intp_t, ndim=1, mode=""c""] iresults
-            np.ndarray[np.float64_t, ndim=1, mode=""c""] w1, w1n
-            np.ndarray[np.float64_t, ndim=1, mode=""c""] w2, w2n
-            np.float64_t *w1p
-            np.float64_t *w1np
-            np.float64_t *w2p
-            np.float64_t *w2np
+            np.float64_t[::1] real_r
+            np.float64_t[::1] fresults
+            np.intp_t[::1] iresults
+            np.float64_t[::1] w1, w1n
+            np.float64_t[::1] w2, w2n
+            np.float64_t *w1p = NULL
+            np.float64_t *w1np = NULL
+            np.float64_t *w2p = NULL
+            np.float64_t *w2np = NULL
 
         # Make sure trees are compatible
         if self.m != other.m:
@@ -1379,8 +1293,9 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                              ""one-dimensional array of values"")
         real_r = np.array(r, ndmin=1, dtype=np.float64, copy=True)
         if not cumulative:
-            if (real_r[:-1] > real_r[1:]).any():
-                raise ValueError(""r must be non-decreasing for non-cumulative counting."");
+            for i in range(real_r.shape[0] - 1):
+                if real_r[i] > real_r[i + 1]:
+                    raise ValueError(""r must be non-decreasing for non-cumulative counting."");
         real_r, uind, inverse = np.unique(real_r, return_inverse=True, return_index=True)
         n_queries = real_r.shape[0]
 
@@ -1405,32 +1320,27 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             results = np.zeros(n_queries + 1, dtype=np.intp)
 
             iresults = results
-            count_neighbors_unweighted(<ckdtree*> self, <ckdtree*> other, n_queries,
+            count_neighbors_unweighted(self.cself, other.cself, n_queries,
                             &real_r[0], &iresults[0], p, cumulative)
 
         else:
             int_result = False
+
             # weighted / half weighted, use the floating point arithmetics
             if self_weights is not None:
                 w1 = np.ascontiguousarray(self_weights, dtype=np.float64)
                 w1n = self._build_weights(w1)
-                w1p = <np.float64_t*> np.PyArray_DATA(w1)
-                w1np = <np.float64_t*> np.PyArray_DATA(w1n)
-            else:
-                w1p = NULL
-                w1np = NULL
+                w1p = &w1[0]
+                w1np = &w1n[0]
             if other_weights is not None:
                 w2 = np.ascontiguousarray(other_weights, dtype=np.float64)
                 w2n = other._build_weights(w2)
-                w2p = <np.float64_t*> np.PyArray_DATA(w2)
-                w2np = <np.float64_t*> np.PyArray_DATA(w2n)
-            else:
-                w2p = NULL
-                w2np = NULL
+                w2p = &w2[0]
+                w2np = &w2n[0]
 
             results = np.zeros(n_queries + 1, dtype=np.float64)
             fresults = results
-            count_neighbors_weighted(<ckdtree*> self, <ckdtree*> other,
+            count_neighbors_weighted(self.cself, other.cself,
                                     w1p, w2p, w1np, w2np,
                                     n_queries,
                                     &real_r[0], &fresults[0], p, cumulative)
@@ -1452,11 +1362,11 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                 return results[0]
         else:
             return results
-    
+
     # ----------------------
     # sparse_distance_matrix
     # ----------------------
-    
+
     def sparse_distance_matrix(cKDTree self, cKDTree other,
                                np.float64_t max_distance,
                                np.float64_t p=2.,
@@ -1474,11 +1384,11 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         other : cKDTree
 
         max_distance : positive float
-        
+
         p : float, 1<=p<=infinity
             Which Minkowski p-norm to use.
             A finite large p may cause a ValueError if overflow can occur.
-        
+
         output_type : string, optional
             Which container to use for output data. Options: 'dok_matrix',
             'coo_matrix', 'dict', or 'ndarray'. Default: 'dok_matrix'.
@@ -1486,29 +1396,29 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         Returns
         -------
         result : dok_matrix, coo_matrix, dict or ndarray
-            Sparse matrix representing the results in ""dictionary of keys"" 
+            Sparse matrix representing the results in ""dictionary of keys""
             format. If a dict is returned the keys are (i,j) tuples of indices.
             If output_type is 'ndarray' a record array with fields 'i', 'j',
             and 'k' is returned,
         """"""
-        
+
         cdef coo_entries res
 
         # Make sure trees are compatible
         if self.m != other.m:
             raise ValueError(""Trees passed to sparse_distance_matrix have ""
-                             ""different dimensionality"")                                      
+                             ""different dimensionality"")
         # do the query
         res = coo_entries()
         sparse_distance_matrix(
-                <ckdtree*> self, <ckdtree*> other, p, max_distance, res.buf)
-                
+                self.cself, other.cself, p, max_distance, res.buf)
+
         if output_type == 'dict':
             return res.dict()
         elif output_type == 'ndarray':
             return res.ndarray()
         elif output_type == 'coo_matrix':
-            return res.coo_matrix(self.n, other.n)            
+            return res.coo_matrix(self.n, other.n)
         elif output_type == 'dok_matrix':
             return res.dok_matrix(self.n, other.n)
         else:
@@ -1517,42 +1427,58 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
     # ----------------------
     # pickle
-    # ----------------------    
-
-        
-    def __reduce__(self):
-        return (new_object, (cKDTree,), self.__getstate__())
+    # ----------------------
 
     def __getstate__(cKDTree self):
         cdef object state
-        cdef object tree = pickle_tree_buffer(self.tree_buffer)
-        state = (tree, self.data.copy(), self.n, self.m, self.leafsize,
-                      self.maxes, self.mins, self.indices.copy(), 
+        cdef np.intp_t size
+        cdef ckdtree * cself = self.cself
+        size = cself.tree_buffer.size() * sizeof(ckdtreenode)
+
+        cdef np.ndarray tree = np.asarray(<char[:size]> <char*> &cself.tree_buffer.front())
+
+        state = (tree.copy(), self.data.copy(), self.n, self.m, self.leafsize,
+                      self.maxes, self.mins, self.indices.copy(),
                       self.boxsize, self.boxsize_data)
         return state
-            
+
     def __setstate__(cKDTree self, state):
-        cdef object tree
-        self.tree_buffer = new vector[ckdtreenode]()
-        
+        cdef np.ndarray tree
+        cdef ckdtree * cself = self.cself
+        cdef np.ndarray mytree
+
         # unpack the state
-        (tree, self.data, self.n, self.m, self.leafsize, 
+        (tree, self.data, self.cself.n, self.cself.m, self.cself.leafsize,
             self.maxes, self.mins, self.indices, self.boxsize, self.boxsize_data) = state
 
+        cself.tree_buffer = new vector[ckdtreenode]()
+        cself.tree_buffer.resize(tree.size // sizeof(ckdtreenode))
+
+        mytree = np.asarray(<char[:tree.size]> <char*> &cself.tree_buffer.front())
+
         # set raw pointers
         self._pre_init()
-        
-        # copy kd-tree buffer 
-        unpickle_tree_buffer(self.tree_buffer, tree)    
-        
+
+        # copy the tree data
+        mytree[:] = tree
+
+
         # set up the tree structure pointers
         self._post_init()
-        
-        # make the tree viewable from Python
-        self.tree = cKDTreeNode()
-        self.tree._node = self.ctree
-        self.tree._data = self.data
-        self.tree._indices = self.indices
-        self.tree.level = 0
-        self.tree._setup() 
 
+def _run_threads(_thread_func, n, n_jobs):
+    if n_jobs > 1:
+        ranges = [(j * n // n_jobs, (j + 1) * n // n_jobs)
+                        for j in range(n_jobs)]
+
+        threads = [threading.Thread(target=_thread_func,
+                   args=(start, end))
+                   for start, end in ranges]
+        for t in threads:
+            t.daemon = True
+            t.start()
+        for t in threads:
+            t.join()
+
+    else:
+        _thread_func(0, n)
diff --git a/scipy/spatial/ckdtree/src/build.cxx b/scipy/spatial/ckdtree/src/build.cxx
index 2990ee5a3809..7fb96d896f20 100644
--- a/scipy/spatial/ckdtree/src/build.cxx
+++ b/scipy/spatial/ckdtree/src/build.cxx
@@ -1,6 +1,3 @@
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -13,30 +10,26 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
 #include ""ordered_pair.h""
-#include ""ckdtree_methods.h""
-#include ""cpp_exc.h""
-#include ""cpp_utils.h""
 #include ""partial_sort.h""
 
+#define tree_buffer_root(buf) (&(buf)[0][0])
 
-
-static npy_intp
-build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
-      npy_float64 *maxes, npy_float64 *mins,
+static ckdtree_intp_t
+build(ckdtree *self, ckdtree_intp_t start_idx, intptr_t end_idx,
+      double *maxes, double *mins,
       const int _median, const int _compact)
 {
 
-    const npy_intp m = self->m;
-    const npy_float64 *data = self->raw_data;
-    npy_intp *indices = (npy_intp *)(self->raw_indices);
+    const ckdtree_intp_t m = self->m;
+    const double *data = self->raw_data;
+    ckdtree_intp_t *indices = (intptr_t *)(self->raw_indices);
 
     ckdtreenode new_node, *n, *root;
-    npy_intp node_index, _less, _greater;
-    npy_intp i, j, p, q, d;
-    npy_float64 size, split, minval, maxval;
+    ckdtree_intp_t node_index, _less, _greater;
+    ckdtree_intp_t i, j, p, q, d;
+    double size, split, minval, maxval;
 
     /* put a new node into the node stack */
     self->tree_buffer->push_back(new_node);
@@ -56,13 +49,13 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
     }
     else {
 
-        if (NPY_LIKELY(_compact)) {
+        if (CKDTREE_LIKELY(_compact)) {
             /* Recompute hyperrectangle bounds. This should lead to a more
              * compact kd-tree but comes at the expense of larger construction
              * time. However, construction time is usually dwarfed by the
              * query time by orders of magnitude.
              */
-            const npy_float64 *tmp_data_point;
+            const double *tmp_data_point;
             tmp_data_point = data + indices[start_idx] * m;
             for(i=0; i<m; ++i) {
                 maxes[i] = tmp_data_point[i];
@@ -71,7 +64,7 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
             for (j = start_idx + 1; j < end_idx; ++j) {
                 tmp_data_point = data + indices[j] * m;
                 for(i=0; i<m; ++i) {
-                    npy_float64 tmp = tmp_data_point[i];
+                    double tmp = tmp_data_point[i];
                     maxes[i] = maxes[i] > tmp ? maxes[i] : tmp;
                     mins[i] = mins[i] < tmp ? mins[i] : tmp;
                 }
@@ -99,7 +92,7 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
 
         /* construct new inner node */
 
-        if (NPY_LIKELY(_median)) {
+        if (CKDTREE_LIKELY(_median)) {
             /* split on median to create a balanced tree
              * adopted from scikit-learn
              */
@@ -122,7 +115,7 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
             else if (data[indices[q] * m + d] >= split)
                 --q;
             else {
-                npy_intp t = indices[p];
+                ckdtree_intp_t t = indices[p];
                 indices[p] = indices[q];
                 indices[q] = t;
                 ++p;
@@ -140,7 +133,7 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
                     split = data[indices[j] * m + d];
                 }
             }
-            npy_intp t = indices[start_idx];
+            ckdtree_intp_t t = indices[start_idx];
             indices[start_idx] = indices[j];
             indices[j] = t;
             p = start_idx + 1;
@@ -156,21 +149,21 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
                     split = data[indices[j] * m + d];
                 }
             }
-            npy_intp t = indices[end_idx-1];
+            ckdtree_intp_t t = indices[end_idx-1];
             indices[end_idx-1] = indices[j];
             indices[j] = t;
             p = end_idx - 1;
             q = end_idx - 2;
         }
 
-        if (NPY_LIKELY(_compact)) {
+        if (CKDTREE_LIKELY(_compact)) {
             _less = build(self, start_idx, p, maxes, mins, _median, _compact);
             _greater = build(self, p, end_idx, maxes, mins, _median, _compact);
         }
         else
         {
-            std::vector<npy_float64> tmp(m);
-            npy_float64 *mids = &tmp[0];
+            std::vector<double> tmp(m);
+            double *mids = &tmp[0];
 
             for (i=0; i<m; ++i) mids[i] = maxes[i];
             mids[d] = split;
@@ -200,42 +193,22 @@ build(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
 
 
 
-extern ""C"" PyObject*
-build_ckdtree(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
-              npy_float64 *maxes, npy_float64 *mins, int _median, int _compact)
+int build_ckdtree(ckdtree *self, ckdtree_intp_t start_idx, intptr_t end_idx,
+              double *maxes, double *mins, int _median, int _compact)
 
 {
-
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            build(self, start_idx, end_idx, maxes, mins, _median, _compact);
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
-    }
+    build(self, start_idx, end_idx, maxes, mins, _median, _compact);
+    return 0;
 }
 
-static npy_float64
+static double
 add_weights(ckdtree *self,
-           npy_float64 *node_weights,
-           npy_intp node_index,
-           npy_float64 *weights)
+           double *node_weights,
+           ckdtree_intp_t node_index,
+           double *weights)
 {
 
-    npy_intp *indices = (npy_intp *)(self->raw_indices);
+    ckdtree_intp_t *indices = (intptr_t *)(self->raw_indices);
 
     ckdtreenode *n, *root;
 
@@ -243,16 +216,16 @@ add_weights(ckdtree *self,
 
     n = root + node_index;
 
-    npy_float64 sum = 0;
+    double sum = 0;
 
     if (n->split_dim != -1) {
         /* internal nodes; recursively calculate the total weight */
-        npy_float64 left, right;
+        double left, right;
         left = add_weights(self, node_weights, n->_less, weights);
         right = add_weights(self, node_weights, n->_greater, weights);
         sum = left + right;
     } else {
-        npy_intp i;
+        ckdtree_intp_t i;
 
         /* Leaf nodes */
         for (i = n->start_idx; i < n->end_idx; ++i) {
@@ -264,30 +237,11 @@ add_weights(ckdtree *self,
     return sum;
 }
 
-
-extern ""C"" PyObject*
-build_weights (ckdtree *self, npy_float64 *node_weights, npy_float64 *weights)
+int
+build_weights (ckdtree *self, double *node_weights, double *weights)
 {
 
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            add_weights(self, node_weights, 0, weights);
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
-    }
+    add_weights(self, node_weights, 0, weights);
+    return 0;
 }
 
diff --git a/scipy/spatial/ckdtree/src/ckdtree_decl.h b/scipy/spatial/ckdtree/src/ckdtree_decl.h
index fc9f85adf346..0ae3a93dce35 100644
--- a/scipy/spatial/ckdtree/src/ckdtree_decl.h
+++ b/scipy/spatial/ckdtree/src/ckdtree_decl.h
@@ -2,55 +2,131 @@
 #define CKDTREE_CPP_DECL
 
 /*
- * Make sure that these declarations are correct
- * by looking at the header file ckdtree.h which
- * is generated by running
- *
- * $ cython ckdtree.pyx
- *
- * Unless you add fields to cKDTree there will be
- * no change in struct ckdtree. The fields are laid
- * out in the same order they are defined in Cython.
- */
+ * Use numpy to provide some platform independency.
+ * Define these functions for your platform
+ * */
+#include <cmath> /* needed for isinf / sc_inf from c99compat under CLANG */
+#include ""_c99compat.h""
+#include <numpy/npy_common.h>
+#define CKDTREE_LIKELY(x) NPY_LIKELY(x)
+#define CKDTREE_UNLIKELY(x)  NPY_UNLIKELY(x)
+#define CKDTREE_PREFETCH(x, rw, loc)  NPY_PREFETCH(x, rw, loc)
+
+#define ckdtree_intp_t npy_intp
+#define ckdtree_isinf(x)   sc_isinf(x)
+#define ckdtree_fmin(x, y)   fmin(x, y)
+#define ckdtree_fmax(x, y)   fmax(x, y)
+#define ckdtree_fabs(x)   fabs(x)
+
+#include ""ordered_pair.h""
+#include ""coo_entries.h""
 
 struct ckdtreenode {
-    npy_intp      split_dim;
-    npy_intp      children;
-    npy_float64   split;
-    npy_intp      start_idx;
-    npy_intp      end_idx;
+    ckdtree_intp_t      split_dim;
+    ckdtree_intp_t      children;
+    double   split;
+    ckdtree_intp_t      start_idx;
+    ckdtree_intp_t      end_idx;
     ckdtreenode   *less;
     ckdtreenode   *greater;
-    npy_intp      _less;
-    npy_intp      _greater;
+    ckdtree_intp_t      _less;
+    ckdtree_intp_t      _greater;
 };
 
-#ifdef CKDTREE_METHODS_IMPL
 struct ckdtree {
-    PyObject_HEAD
-    // vtab pointer is present as long as cKDTree has cdef methods
-    const void          *vtab;
     // tree structure
     std::vector<ckdtreenode>  *tree_buffer;
-    const ckdtreenode   *ctree;
-    const PyObject      *dummy;
+    ckdtreenode   *ctree;
     // meta data
-    const PyArrayObject *data;
-    const npy_float64   *raw_data;
-    const npy_intp      n;
-    const npy_intp      m;
-    const npy_intp      leafsize;
-    const PyArrayObject *maxes;
-    const npy_float64   *raw_maxes;
-    const PyArrayObject *mins;
-    const npy_float64   *raw_mins;
-    const PyArrayObject *indices;
-    const npy_intp      *raw_indices;
-    const PyArrayObject *_median_workspace;
-    const PyObject      *boxsize;
-    const PyArrayObject *boxsize_data;
-    const npy_float64   *raw_boxsize_data;
-    const npy_intp size;
+    double   *raw_data;
+    ckdtree_intp_t      n;
+    ckdtree_intp_t      m;
+    ckdtree_intp_t      leafsize;
+    double   *raw_maxes;
+    double   *raw_mins;
+    ckdtree_intp_t      *raw_indices;
+    double   *raw_boxsize_data;
+    ckdtree_intp_t size;
 };
-#endif
+
+/* Build methods in C++ for better speed and GIL release */
+
+int
+build_ckdtree(ckdtree *self, ckdtree_intp_t start_idx, intptr_t end_idx,
+              double *maxes, double *mins, int _median, int _compact);
+
+int
+build_weights (ckdtree *self, double *node_weights, double *weights);
+
+/* Query methods in C++ for better speed and GIL release */
+
+int
+query_knn(const ckdtree     *self,
+          double       *dd,
+          ckdtree_intp_t          *ii,
+          const double *xx,
+          const ckdtree_intp_t     n,
+          const ckdtree_intp_t     *k,
+          const ckdtree_intp_t     nk,
+          const ckdtree_intp_t     kmax,
+          const double  eps,
+          const double  p,
+          const double  distance_upper_bound);
+
+int
+query_pairs(const ckdtree *self,
+            const double r,
+            const double p,
+            const double eps,
+            std::vector<ordered_pair> *results);
+
+int
+count_neighbors_unweighted(const ckdtree *self,
+                const ckdtree *other,
+                ckdtree_intp_t n_queries,
+                double *real_r,
+                ckdtree_intp_t *results,
+                const double p,
+                int cumulative);
+
+int
+count_neighbors_weighted(const ckdtree *self,
+                const ckdtree *other,
+                double *self_weights,
+                double *other_weights,
+                double *self_node_weights,
+                double *other_node_weights,
+                ckdtree_intp_t n_queries,
+                double *real_r,
+                double *results,
+                const double p,
+                int cumulative);
+
+int
+query_ball_point(const ckdtree *self,
+                 const double *x,
+                 const double *r,
+                 const double p,
+                 const double eps,
+                 const ckdtree_intp_t n_queries,
+                 std::vector<ckdtree_intp_t> **results,
+                 const int return_length);
+
+int
+query_ball_tree(const ckdtree *self,
+                const ckdtree *other,
+                const double r,
+                const double p,
+                const double eps,
+                std::vector<ckdtree_intp_t> **results
+                );
+
+int
+sparse_distance_matrix(const ckdtree *self,
+                       const ckdtree *other,
+                       const double p,
+                       const double max_distance,
+                       std::vector<coo_entry> *results);
+
+
 #endif
diff --git a/scipy/spatial/ckdtree/src/ckdtree_methods.h b/scipy/spatial/ckdtree/src/ckdtree_methods.h
deleted file mode 100644
index 0f3755efed51..000000000000
--- a/scipy/spatial/ckdtree/src/ckdtree_methods.h
+++ /dev/null
@@ -1,218 +0,0 @@
-
-#ifndef CKDTREE_CPP_METHODS
-#define CKDTREE_CPP_METHODS
-
-#ifdef CKDTREE_METHODS_IMPL
-#define CKDTREE_EXTERN extern ""C""
-#else
-#define CKDTREE_EXTERN extern ""C""
-struct ckdtree;
-#endif
-
-extern int number_of_processors;
-
-#ifndef NPY_LIKELY
-#define NPY_LIKELY(x) (x)
-#endif
-
-#ifndef NPY_UNLIKELY
-#define NPY_UNLIKELY(x) (x)
-#endif
-
-#include <cmath>
-#include <vector>
-#include ""numpy/npy_math.h""
-#include ""ordered_pair.h""
-#include ""coo_entries.h""
-
-#if defined(__GNUC__)
-
-inline void
-prefetch_datapoint(const npy_float64 *x, const npy_intp m)
-{
-    const int cache_line = 64;  // x86, amd64
-    char *cur = (char*)x;
-    char *end = (char*)(x+m);
-    while (cur < end) {
-        __builtin_prefetch((void*)cur);
-        cur += cache_line;
-    }
-}
-
-#else
-
-#if defined(_WIN32)
-
-#include <xmmintrin.h>
-
-inline void
-prefetch_datapoint(const npy_float64 *x, const npy_intp m)
-{
-    const int cache_line = 64;  // x86, amd64
-    char *cur = (char*)x;
-    char *end = (char*)(x+m);
-    while (cur < end) {
-        _mm_prefetch((const char*)cur,_MM_HINT_T0);
-        cur += cache_line;
-    }
-}
-
-#else
-
-#define prefetch_datapoint(x,y)
-
-#endif // _WIN32
-#endif // __GNUC__
-
-/*
- * Utility functions
- * =================
- */
-
-#define ckdtree_isinf(x) (x == NPY_INFINITY)
-
-inline npy_float64
-dmax(const npy_float64 x, const npy_float64 y)
-{
-    if (x > y)
-        return x;
-    else
-        return y;
-};
-
-inline npy_float64
-dmin(const npy_float64 x, const npy_float64 y)
-{
-    if (x < y)
-        return x;
-    else
-        return y;
-};
-
-
-inline npy_float64
-dabs(const npy_float64 x)
-{
-    if (x > 0)
-        return x;
-    else
-        return -x;
-}
-
-/*
- * Measuring distances
- * ===================
- */
-inline npy_float64
-sqeuclidean_distance_double(const npy_float64 *u, const npy_float64 *v, npy_intp n)
-{
-    npy_float64 s;
-    npy_intp i;
-    // manually unrolled loop, might be vectorized
-    npy_float64 acc[4] = {0., 0., 0., 0.};
-    for (i = 0; i < n/4; i += 4) {
-        npy_float64 _u[4] = {u[i], u[i + 1], u[i + 2], u[i + 3]};
-        npy_float64 _v[4] = {v[i], v[i + 1], v[i + 2], v[i + 3]};
-        npy_float64 diff[4] = {_u[0] - _v[0],
-                               _u[1] - _v[1],
-                               _u[2] - _v[2],
-                               _u[3] - _v[3]};
-        acc[0] += diff[0] * diff[0];
-        acc[1] += diff[1] * diff[1];
-        acc[2] += diff[2] * diff[2];
-        acc[3] += diff[3] * diff[3];
-    }
-    s = acc[0] + acc[1] + acc[2] + acc[3];
-    if (i < n) {
-        for(; i<n; ++i) {
-            npy_float64 d = u[i] - v[i];
-            s += d * d;
-        }
-    }
-    return s;
-}
-
-
-/* Build methods in C++ for better speed and GIL release */
-
-CKDTREE_EXTERN PyObject*
-build_ckdtree(ckdtree *self, npy_intp start_idx, npy_intp end_idx,
-              npy_float64 *maxes, npy_float64 *mins, int _median, int _compact);
-
-extern ""C"" PyObject*
-build_weights (ckdtree *self, npy_float64 *node_weights, npy_float64 *weights);
-
-/* Query methods in C++ for better speed and GIL release */
-
-CKDTREE_EXTERN PyObject*
-query_knn(const ckdtree     *self,
-          npy_float64       *dd,
-          npy_intp          *ii,
-          const npy_float64 *xx,
-          const npy_intp     n,
-          const npy_intp     *k,
-          const npy_intp     nk,
-          const npy_intp     kmax,
-          const npy_float64  eps,
-          const npy_float64  p,
-          const npy_float64  distance_upper_bound);
-
-CKDTREE_EXTERN PyObject*
-query_pairs(const ckdtree *self,
-            const npy_float64 r,
-            const npy_float64 p,
-            const npy_float64 eps,
-            std::vector<ordered_pair> *results);
-
-CKDTREE_EXTERN PyObject*
-count_neighbors_unweighted(const ckdtree *self,
-                const ckdtree *other,
-                npy_intp n_queries,
-                npy_float64 *real_r,
-                npy_intp *results,
-                const npy_float64 p,
-                int cumulative);
-
-CKDTREE_EXTERN PyObject*
-count_neighbors_weighted(const ckdtree *self,
-                const ckdtree *other,
-                npy_float64 *self_weights,
-                npy_float64 *other_weights,
-                npy_float64 *self_node_weights,
-                npy_float64 *other_node_weights,
-                npy_intp n_queries,
-                npy_float64 *real_r,
-                npy_float64 *results,
-                const npy_float64 p,
-                int cumulative);
-
-CKDTREE_EXTERN PyObject*
-query_ball_point(const ckdtree *self,
-                 const npy_float64 *x,
-                 const npy_float64 *r,
-                 const npy_float64 p,
-                 const npy_float64 eps,
-                 const npy_intp n_queries,
-                 std::vector<npy_intp> **results,
-                 const int return_length);
-
-CKDTREE_EXTERN PyObject*
-query_ball_tree(const ckdtree *self,
-                const ckdtree *other,
-                const npy_float64 r,
-                const npy_float64 p,
-                const npy_float64 eps,
-                std::vector<npy_intp> **results
-                );
-
-CKDTREE_EXTERN PyObject*
-sparse_distance_matrix(const ckdtree *self,
-                       const ckdtree *other,
-                       const npy_float64 p,
-                       const npy_float64 max_distance,
-                       std::vector<coo_entry> *results);
-
-
-#endif
-
-
diff --git a/scipy/spatial/ckdtree/src/coo_entries.h b/scipy/spatial/ckdtree/src/coo_entries.h
index 4f0f368e125c..b2edd7797d7c 100644
--- a/scipy/spatial/ckdtree/src/coo_entries.h
+++ b/scipy/spatial/ckdtree/src/coo_entries.h
@@ -1,13 +1,10 @@
 #ifndef CKDTREE_COO_ENTRIES
 #define CKDTREE_COO_ENTRIES
 
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 struct coo_entry {
-    npy_intp i;
-    npy_intp j;
-    npy_float64 v;
+    ckdtree_intp_t i;
+    ckdtree_intp_t j;
+    double v;
 };
 
 #endif
diff --git a/scipy/spatial/ckdtree/src/count_neighbors.cxx b/scipy/spatial/ckdtree/src/count_neighbors.cxx
index 5f79f80bf2ac..4847606a18b1 100644
--- a/scipy/spatial/ckdtree/src/count_neighbors.cxx
+++ b/scipy/spatial/ckdtree/src/count_neighbors.cxx
@@ -1,6 +1,3 @@
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -14,21 +11,18 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
-#include ""ckdtree_methods.h""
-#include ""cpp_exc.h""
 #include ""rectangle.h""
 
 struct WeightedTree {
     const ckdtree *tree;
-    npy_float64 *weights;
-    npy_float64 *node_weights;
+    double *weights;
+    double *node_weights;
 };
 
 struct CNBParams
 {
-    npy_float64 *r;
+    double *r;
     void * results; /* will be casted inside */
     WeightedTree self, other;
     int cumulative;
@@ -38,13 +32,13 @@ template <typename MinMaxDist, typename WeightType, typename ResultType> static
 traverse(
     RectRectDistanceTracker<MinMaxDist> *tracker,
     const CNBParams *params,
-    npy_float64 *start, npy_float64 *end,
+    double *start, double *end,
     const ckdtreenode *node1,
     const ckdtreenode *node2)
 {
     static void (* const next)(RectRectDistanceTracker<MinMaxDist> *tracker,
             const CNBParams *params,
-            npy_float64 *start, npy_float64 *end,
+            double *start, double *end,
             const ckdtreenode *node1,
             const ckdtreenode *node2) = traverse<MinMaxDist, WeightType, ResultType>;
 
@@ -55,13 +49,13 @@ traverse(
      * and see if any work remains to be done
      */
 
-    npy_float64 * new_start = std::lower_bound(start, end, tracker->min_distance);
-    npy_float64 * new_end = std::lower_bound(start, end, tracker->max_distance);
+    double * new_start = std::lower_bound(start, end, tracker->min_distance);
+    double * new_end = std::lower_bound(start, end, tracker->max_distance);
 
 
     /* since max_distance >= min_distance, end < start never happens */
     if (params->cumulative) {
-        npy_float64 * i;
+        double * i;
         if (new_end != end) {
             ResultType nn = WeightType::get_weight(&params->self, node1)
                           * WeightType::get_weight(&params->other, node2);
@@ -93,41 +87,41 @@ traverse(
     /* OK, need to probe a bit deeper */
     if (node1->split_dim == -1) {  /* 1 is leaf node */
         if (node2->split_dim == -1) {  /* 1 & 2 are leaves */
-            npy_intp i, j;
-            const npy_float64 p = tracker->p;
-            const npy_float64 tmd = tracker->max_distance;
-            const npy_float64 *sdata = params->self.tree->raw_data;
-            const npy_intp *sindices = params->self.tree->raw_indices;
-            const npy_float64 *odata = params->other.tree->raw_data;
-            const npy_intp *oindices = params->other.tree->raw_indices;
-            const npy_intp m = params->self.tree->m;
-            const npy_intp start1 = node1->start_idx;
-            const npy_intp start2 = node2->start_idx;
-            const npy_intp end1 = node1->end_idx;
-            const npy_intp end2 = node2->end_idx;
-
-            prefetch_datapoint(sdata + sindices[start1] * m, m);
+            ckdtree_intp_t i, j;
+            const double p = tracker->p;
+            const double tmd = tracker->max_distance;
+            const double *sdata = params->self.tree->raw_data;
+            const ckdtree_intp_t *sindices = params->self.tree->raw_indices;
+            const double *odata = params->other.tree->raw_data;
+            const ckdtree_intp_t *oindices = params->other.tree->raw_indices;
+            const ckdtree_intp_t m = params->self.tree->m;
+            const ckdtree_intp_t start1 = node1->start_idx;
+            const ckdtree_intp_t start2 = node2->start_idx;
+            const ckdtree_intp_t end1 = node1->end_idx;
+            const ckdtree_intp_t end2 = node2->end_idx;
+
+            CKDTREE_PREFETCH(sdata + sindices[start1] * m, 0, m);
 
             if (start1 < end1 - 1)
-                prefetch_datapoint(sdata + sindices[start1+1] * m, m);
+                CKDTREE_PREFETCH(sdata + sindices[start1+1] * m, 0, m);
 
             /* brute-force */
             for (i = start1; i < end1; ++i) {
 
                 if (i < end1 - 2)
-                    prefetch_datapoint(sdata + sindices[i+2] * m, m);
+                    CKDTREE_PREFETCH(sdata + sindices[i+2] * m, 0, m);
 
-                prefetch_datapoint(odata + oindices[start2] * m, m);
+                CKDTREE_PREFETCH(odata + oindices[start2] * m, 0, m);
 
                 if (start2 < end2 - 1)
-                    prefetch_datapoint(odata + oindices[start2+1] * m, m);
+                    CKDTREE_PREFETCH(odata + oindices[start2+1] * m, 0, m);
 
                 for (j = start2; j < end2; ++j) {
 
                     if (j < end2 - 2)
-                        prefetch_datapoint(odata + oindices[j+2] * m, m);
+                        CKDTREE_PREFETCH(odata + oindices[j+2] * m, 0, m);
 
-                    npy_float64 d = MinMaxDist::point_point_p(params->self.tree,
+                    double d = MinMaxDist::point_point_p(params->self.tree,
                             sdata + sindices[i] * m,
                             odata + oindices[j] * m,
                             p, m, tmd);
@@ -138,7 +132,7 @@ traverse(
                          * r's than to generate a distance array, sort it, then
                          * search for all r's via binary search
                          */
-                        npy_float64 * l;
+                        double * l;
                         for (l = start; l < end; ++l) {
                             if (d <= *l) {
                                 results[l - params->r] += WeightType::get_weight(&params->self, sindices[i])
@@ -146,7 +140,7 @@ traverse(
                             }
                         }
                     } else {
-                        const npy_float64 *l = std::lower_bound(start, end, d);
+                        const double *l = std::lower_bound(start, end, d);
                         results[l - params->r] += WeightType::get_weight(&params->self, sindices[i])
                                                 * WeightType::get_weight(&params->other, sindices[j]);
                     }
@@ -200,7 +194,7 @@ traverse(
 
 template <typename WeightType, typename ResultType> void
 count_neighbors(struct CNBParams *params,
-                npy_intp n_queries, const npy_float64 p)
+                ckdtree_intp_t n_queries, const double p)
 {
 
     const ckdtree *self = params->self.tree;
@@ -216,14 +210,14 @@ count_neighbors(struct CNBParams *params,
     Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
     Rectangle r2(other->m, other->raw_mins, other->raw_maxes);
 
-    if (NPY_LIKELY(self->raw_boxsize_data == NULL)) {
-        HANDLE(NPY_LIKELY(p == 2), MinkowskiDistP2)
+    if (CKDTREE_LIKELY(self->raw_boxsize_data == NULL)) {
+        HANDLE(CKDTREE_LIKELY(p == 2), MinkowskiDistP2)
         HANDLE(p == 1, MinkowskiDistP1)
         HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
         HANDLE(1, MinkowskiDistPp)
         {}
     } else {
-        HANDLE(NPY_LIKELY(p == 2), BoxMinkowskiDistP2)
+        HANDLE(CKDTREE_LIKELY(p == 2), BoxMinkowskiDistP2)
         HANDLE(p == 1, BoxMinkowskiDistP1)
         HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
         HANDLE(1, BoxMinkowskiDistPp)
@@ -233,22 +227,23 @@ count_neighbors(struct CNBParams *params,
 
 struct Unweighted {
     /* the interface for accessing weights of unweighted data. */
-    static inline npy_intp
+    static inline ckdtree_intp_t
     get_weight(const WeightedTree *wt, const ckdtreenode * node)
     {
         return node->children;
     }
-    static inline npy_intp
-    get_weight(const WeightedTree *wt, const npy_intp i)
+    static inline ckdtree_intp_t
+    get_weight(const WeightedTree *wt, const ckdtree_intp_t i)
     {
         return 1;
     }
 };
 
-extern ""C"" PyObject*
+
+int
 count_neighbors_unweighted(const ckdtree *self, const ckdtree *other,
-                npy_intp n_queries, npy_float64 *real_r, npy_intp *results,
-                const npy_float64 p, int cumulative) {
+                ckdtree_intp_t n_queries, double *real_r, intptr_t *results,
+                const double p, int cumulative) {
 
     CNBParams params = {0};
 
@@ -258,51 +253,33 @@ count_neighbors_unweighted(const ckdtree *self, const ckdtree *other,
     params.other.tree = other;
     params.cumulative = cumulative;
 
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            count_neighbors<Unweighted, npy_intp>(&params, n_queries, p);
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
-    }
+    count_neighbors<Unweighted, ckdtree_intp_t>(&params, n_queries, p);
+
+    return 0;
 }
 
 struct Weighted {
     /* the interface for accessing weights of weighted data. */
-    static inline npy_float64
+    static inline double
     get_weight(const WeightedTree *wt, const ckdtreenode * node)
     {
         return (wt->weights != NULL)
            ? wt->node_weights[node - wt->tree->ctree]
            : node->children;
     }
-    static inline npy_float64
-    get_weight(const WeightedTree *wt, const npy_intp i)
+    static inline double
+    get_weight(const WeightedTree *wt, const ckdtree_intp_t i)
     {
         return (wt->weights != NULL)?wt->weights[i]:1;
     }
 };
 
-
-extern ""C"" PyObject*
+int
 count_neighbors_weighted(const ckdtree *self, const ckdtree *other,
-                npy_float64 *self_weights, npy_float64 *other_weights,
-                npy_float64 *self_node_weights, npy_float64 *other_node_weights,
-                npy_intp n_queries, npy_float64 *real_r, npy_float64 *results,
-                const npy_float64 p, int cumulative)
+                double *self_weights, double *other_weights,
+                double *self_node_weights, double *other_node_weights,
+                ckdtree_intp_t n_queries, double *real_r, double *results,
+                const double p, int cumulative)
 {
 
     CNBParams params = {0};
@@ -321,25 +298,9 @@ count_neighbors_weighted(const ckdtree *self, const ckdtree *other,
         params.other.weights = other_weights;
         params.other.node_weights = other_node_weights;
     }
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            count_neighbors<Weighted, npy_float64>(&params, n_queries, p);
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
-    }
+
+    count_neighbors<Weighted, double>(&params, n_queries, p);
+
+    return 0;
 }
 
diff --git a/scipy/spatial/ckdtree/src/cpp_exc.cxx b/scipy/spatial/ckdtree/src/cpp_exc.cxx
deleted file mode 100644
index 824abee56a6d..000000000000
--- a/scipy/spatial/ckdtree/src/cpp_exc.cxx
+++ /dev/null
@@ -1,67 +0,0 @@
-/*
- * Catch C++ standard exceptions and raise corresponding
- * Python exceptions. Use simplified GIL API to ensure
- * we have the GIL.
- */
-
-#include <new>
-#include <typeinfo>
-#include <stdexcept>
-#include <ios>
-
-#include <Python.h>
-
-extern ""C"" void
-translate_cpp_exception()
-{
-    try {
-        if (PyErr_Occurred())
-            return;
-        else
-            throw;
-    }
-    catch (const std::bad_alloc &exn) {
-        PyErr_NoMemory();
-    }
-    catch (const std::bad_cast &exn) {
-        PyErr_SetString(PyExc_TypeError, exn.what());
-    }
-    catch (const std::domain_error &exn) {
-        PyErr_SetString(PyExc_ValueError, exn.what());
-    }
-    catch (const std::invalid_argument &exn) {
-        PyErr_SetString(PyExc_ValueError, exn.what());
-    }
-    catch (const std::ios_base::failure &exn) {
-        PyErr_SetString(PyExc_IOError, exn.what());
-    }
-    catch (const std::out_of_range &exn) {
-        PyErr_SetString(PyExc_IndexError, exn.what());
-    }
-    catch (const std::overflow_error &exn) {
-        PyErr_SetString(PyExc_OverflowError, exn.what());
-    }
-    catch (const std::range_error &exn) {
-        PyErr_SetString(PyExc_ArithmeticError, exn.what());
-    }
-    catch (const std::underflow_error &exn) {
-        PyErr_SetString(PyExc_ArithmeticError, exn.what());
-    }
-    catch (const std::logic_error &exn) {
-        PyErr_SetString(PyExc_RuntimeError, exn.what());
-    }
-    catch (const std::exception& exn) {
-        PyErr_SetString(PyExc_RuntimeError, exn.what());
-    }
-    catch (...) {
-        PyErr_SetString(PyExc_RuntimeError, ""Unknown exception"");
-    }
-}
-
-extern ""C"" void
-translate_cpp_exception_with_gil()
-{
-    PyGILState_STATE state = PyGILState_Ensure();
-    translate_cpp_exception();
-    PyGILState_Release(state);
-}
diff --git a/scipy/spatial/ckdtree/src/cpp_exc.h b/scipy/spatial/ckdtree/src/cpp_exc.h
deleted file mode 100644
index 557caf21d5a0..000000000000
--- a/scipy/spatial/ckdtree/src/cpp_exc.h
+++ /dev/null
@@ -1,18 +0,0 @@
-/*
- * Catch C++ standard exceptions and raise corresponding
- * Python exceptions. Use simplified GIL API to ensure
- * we have the GIL.
- */
-
-
-#ifndef CKDTREE_CPP_EXC_H
-#define CKDTREE_CPP_EXC_H
-
-extern ""C"" void
-translate_cpp_exception();
-
-extern ""C"" void
-translate_cpp_exception_with_gil();
-
-#endif
-
diff --git a/scipy/spatial/ckdtree/src/cpp_utils.h b/scipy/spatial/ckdtree/src/cpp_utils.h
deleted file mode 100644
index 51be061dcf39..000000000000
--- a/scipy/spatial/ckdtree/src/cpp_utils.h
+++ /dev/null
@@ -1,109 +0,0 @@
-#include <vector>
-#include <cstring>
-#include <Python.h>
-
-#include ""ordered_pair.h""
-#include ""ckdtree_decl.h""
-#include ""cpp_exc.h""
-#include ""coo_entries.h""
-
-
-#if PY_MAJOR_VERSION < 3
-    #define ckdtree_PyBytes_FromStringAndSize(v,len) PyString_FromStringAndSize(v,len)
-    #define ckdtree_PyBytes_Size(o) PyString_Size(o)
-    #define ckdtree_PyBytes_AsString(o) PyString_AsString(o)
-#else
-    #define ckdtree_PyBytes_FromStringAndSize(v,len) PyBytes_FromStringAndSize(v,len)
-    #define ckdtree_PyBytes_Size(o) PyBytes_Size(o)
-    #define ckdtree_PyBytes_AsString(o) PyBytes_AsString(o)
-#endif
-
-
-inline void*
-tree_buffer_pointer(std::vector<ckdtreenode> *buf)
-{
-    std::vector<ckdtreenode> &tmp = *buf;
-    if (NPY_UNLIKELY(tmp.size() == 0))
-        return NULL;
-    return (void*)&tmp[0];
-}
-
-
-inline ckdtreenode*
-tree_buffer_root(std::vector<ckdtreenode> *buf)
-{
-    std::vector<ckdtreenode> &tmp = *buf;
-    if (NPY_UNLIKELY(tmp.size() == 0))
-        return NULL;
-    return &tmp[0];
-}
-
-inline ordered_pair *
-ordered_pair_vector_buf(std::vector<ordered_pair> *buf)
-{
-    std::vector<ordered_pair> &tmp = *buf;
-    if (NPY_UNLIKELY(tmp.size() == 0))
-        return NULL;
-    return &tmp[0];
-}
-
-
-typedef std::vector<npy_intp> *intvector_ptr_t;
-
-inline npy_intp *
-npy_intp_vector_buf(std::vector<npy_intp> *buf)
-{
-    std::vector<npy_intp> &tmp = *buf;
-    if (NPY_UNLIKELY(tmp.size() == 0))
-        return NULL;
-    return &tmp[0];
-}
-
-inline npy_float64 *
-npy_float64_vector_buf(std::vector<npy_float64> *buf)
-{
-    std::vector<npy_float64> &tmp = *buf;
-    if (NPY_UNLIKELY(tmp.size() == 0))
-        return NULL;
-    return &tmp[0];
-}
-
-inline coo_entry *
-coo_entry_vector_buf(std::vector<coo_entry> *buf)
-{
-    std::vector<coo_entry> &tmp = *buf;
-    if (NPY_UNLIKELY(tmp.size() == 0))
-        return NULL;
-    return &tmp[0];
-}
-
-
-static PyObject *
-pickle_tree_buffer(std::vector<ckdtreenode> *buf)
-{
-    char *v = (char*) &(buf->front());
-    Py_ssize_t len = buf->size() * sizeof(ckdtreenode);
-    return ckdtree_PyBytes_FromStringAndSize(v,len);
-}
-
-
-static PyObject *
-unpickle_tree_buffer(std::vector<ckdtreenode> *buf, PyObject *src)
-{
-    Py_ssize_t s, n;
-    ckdtreenode *target, *cur;
-    s = ckdtree_PyBytes_Size(src);
-    if (PyErr_Occurred()) return NULL;
-    n = s / sizeof(ckdtreenode);
-    cur = (ckdtreenode *)ckdtree_PyBytes_AsString(src);
-    if (PyErr_Occurred()) return NULL;
-    try {
-        buf->resize(n);
-        target = &(buf->front());
-        std::memcpy((void*)target,(void*)cur,s);
-    } catch (...) {
-        translate_cpp_exception();
-        return NULL;
-    }
-    Py_RETURN_NONE;
-}
diff --git a/scipy/spatial/ckdtree/src/distance.h b/scipy/spatial/ckdtree/src/distance.h
index 8920b422bb18..03b52a579046 100644
--- a/scipy/spatial/ckdtree/src/distance.h
+++ b/scipy/spatial/ckdtree/src/distance.h
@@ -1,15 +1,15 @@
 #include ""distance_base.h""
-#include ""_c99compat.h""
+
 
 struct PlainDist1D {
-    static inline const npy_float64 side_distance_from_min_max(
-        const ckdtree * tree, const npy_float64 x,
-        const npy_float64 min,
-        const npy_float64 max,
-        const npy_intp k
+    static inline const double side_distance_from_min_max(
+        const ckdtree * tree, const double x,
+        const double min,
+        const double max,
+        const ckdtree_intp_t k
         )
     {
-        npy_float64 s, t;
+        double s, t;
         s = 0;
         t = x - max;
         if (t > s) {
@@ -23,23 +23,23 @@ struct PlainDist1D {
     static inline void
     interval_interval(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_intp k,
-                        npy_float64 *min, npy_float64 *max)
+                        const ckdtree_intp_t k,
+                        double *min, double *max)
     {
         /* Compute the minimum/maximum distance along dimension k between points in
          * two hyperrectangles.
          */
-        *min = dmax(0, dmax(rect1.mins()[k] - rect2.maxes()[k],
+        *min = ckdtree_fmax(0., fmax(rect1.mins()[k] - rect2.maxes()[k],
                               rect2.mins()[k] - rect1.maxes()[k]));
-        *max = dmax(rect1.maxes()[k] - rect2.mins()[k],
+        *max = ckdtree_fmax(rect1.maxes()[k] - rect2.mins()[k],
                               rect2.maxes()[k] - rect1.mins()[k]);
     }
 
-    static inline npy_float64
+    static inline double
     point_point(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-                 const npy_intp k) {
-        return dabs(x[k] - y[k]);
+               const double *x, const double *y,
+                 const ckdtree_intp_t k) {
+        return ckdtree_fabs(x[k] - y[k]);
     }
 };
 
@@ -48,12 +48,46 @@ typedef BaseMinkowskiDistPinf<PlainDist1D> MinkowskiDistPinf;
 typedef BaseMinkowskiDistP1<PlainDist1D> MinkowskiDistP1;
 typedef BaseMinkowskiDistP2<PlainDist1D> NonOptimizedMinkowskiDistP2;
 
+/*
+ * Measuring distances
+ * ===================
+ */
+inline double
+sqeuclidean_distance_double(const double *u, const double *v, ckdtree_intp_t n)
+{
+    double s;
+    ckdtree_intp_t i;
+    // manually unrolled loop, might be vectorized
+    double acc[4] = {0., 0., 0., 0.};
+    for (i = 0; i < n/4; i += 4) {
+        double _u[4] = {u[i], u[i + 1], u[i + 2], u[i + 3]};
+        double _v[4] = {v[i], v[i + 1], v[i + 2], v[i + 3]};
+        double diff[4] = {_u[0] - _v[0],
+                               _u[1] - _v[1],
+                               _u[2] - _v[2],
+                               _u[3] - _v[3]};
+        acc[0] += diff[0] * diff[0];
+        acc[1] += diff[1] * diff[1];
+        acc[2] += diff[2] * diff[2];
+        acc[3] += diff[3] * diff[3];
+    }
+    s = acc[0] + acc[1] + acc[2] + acc[3];
+    if (i < n) {
+        for(; i<n; ++i) {
+            double d = u[i] - v[i];
+            s += d * d;
+        }
+    }
+    return s;
+}
+
+
 struct MinkowskiDistP2: NonOptimizedMinkowskiDistP2 {
-    static inline npy_float64
+    static inline double
     point_point_p(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-               const npy_float64 p, const npy_intp k,
-               const npy_float64 upperbound)
+               const double *x, const double *y,
+               const double p, const ckdtree_intp_t k,
+               const double upperbound)
     {
         return sqeuclidean_distance_double(x, y, k);
     }
@@ -61,9 +95,9 @@ struct MinkowskiDistP2: NonOptimizedMinkowskiDistP2 {
 
 struct BoxDist1D {
     static inline void _interval_interval_1d (
-        npy_float64 min, npy_float64 max,
-        npy_float64 *realmin, npy_float64 *realmax,
-        const npy_float64 full, const npy_float64 half
+        double min, double max,
+        double *realmin, double *realmax,
+        const double full, const double half
     )
     {
         /* Minimum and maximum distance of two intervals in a periodic box
@@ -83,13 +117,13 @@ struct BoxDist1D {
          *
          * We will fix the convention later.
          * */
-        if (NPY_UNLIKELY(full <= 0)) {
+        if (CKDTREE_UNLIKELY(full <= 0)) {
             /* A non-periodic dimension */
             /* \/     */
             if(max <= 0 || min >= 0) {
                 /* do not pass though 0 */
-                min = dabs(min);
-                max = dabs(max);
+                min = ckdtree_fabs(min);
+                max = ckdtree_fabs(max);
                 if(min < max) {
                     *realmin = min;
                     *realmax = max;
@@ -98,9 +132,9 @@ struct BoxDist1D {
                     *realmax = min;
                 }
             } else {
-                min = dabs(min);
-                max = dabs(max);
-                *realmax = fmax(max, min);
+                min = ckdtree_fabs(min);
+                max = ckdtree_fabs(max);
+                *realmax = ckdtree_fmax(max, min);
                 *realmin = 0;
             }
             /* done with non-periodic dimension */
@@ -108,8 +142,8 @@ struct BoxDist1D {
         }
         if(max <= 0 || min >= 0) {
             /* do not pass through 0 */
-            min = dabs(min);
-            max = dabs(max);
+            min = ckdtree_fabs(min);
+            max = ckdtree_fabs(max);
             if(min > max) {
                 double t = min;
                 min = max;
@@ -126,7 +160,7 @@ struct BoxDist1D {
             } else {
                 /* min below, max above */
                 *realmax = half;
-                *realmin = dmin(min, full - max);
+                *realmin = ckdtree_fmin(min, full - max);
             }
         } else {
             /* pass though 0 */
@@ -140,8 +174,8 @@ struct BoxDist1D {
     static inline void
     interval_interval(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_intp k,
-                        npy_float64 *min, npy_float64 *max)
+                        const ckdtree_intp_t k,
+                        double *min, double *max)
     {
         /* Compute the minimum/maximum distance along dimension k between points in
          * two hyperrectangles.
@@ -151,39 +185,39 @@ struct BoxDist1D {
                     tree->raw_boxsize_data[k], tree->raw_boxsize_data[k + rect1.m]);
     }
 
-    static inline npy_float64
+    static inline double
     point_point(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-               const npy_intp k)
+               const double *x, const double *y,
+               const ckdtree_intp_t k)
     {
-        npy_float64 r1;
+        double r1;
         r1 = wrap_distance(x[k] - y[k], tree->raw_boxsize_data[k + tree->m], tree->raw_boxsize_data[k]);
-        r1 = dabs(r1);
+        r1 = ckdtree_fabs(r1);
         return r1;
     }
 
-    static inline const npy_float64
-    wrap_position(const npy_float64 x, const npy_float64 boxsize)
+    static inline const double
+    wrap_position(const double x, const double boxsize)
     {
         if (boxsize <= 0) return x;
-        const npy_float64 r = std::floor(x / boxsize);
-        npy_float64 x1 = x - r * boxsize;
+        const double r = std::floor(x / boxsize);
+        double x1 = x - r * boxsize;
         /* ensure result is within the box. */
         while(x1 >= boxsize) x1 -= boxsize;
         while(x1 < 0) x1 += boxsize;
         return x1;
     }
 
-    static inline const npy_float64 side_distance_from_min_max(
-        const ckdtree * tree, const npy_float64 x,
-        const npy_float64 min,
-        const npy_float64 max,
-        const npy_intp k
+    static inline const double side_distance_from_min_max(
+        const ckdtree * tree, const double x,
+        const double min,
+        const double max,
+        const ckdtree_intp_t k
         )
     {
-        npy_float64 s, t, tmin, tmax;
-        npy_float64 fb = tree->raw_boxsize_data[k];
-        npy_float64 hb = tree->raw_boxsize_data[k + tree->m];
+        double s, t, tmin, tmax;
+        double fb = tree->raw_boxsize_data[k];
+        double hb = tree->raw_boxsize_data[k + tree->m];
 
         if (fb <= 0) {
             /* non-periodic dimension */
@@ -196,14 +230,14 @@ struct BoxDist1D {
         tmax = x - max;
         tmin = x - min;
         /* is the test point in this range */
-        if(NPY_LIKELY(tmax < 0 && tmin > 0)) {
+        if(CKDTREE_LIKELY(tmax < 0 && tmin > 0)) {
             /* yes. min distance is 0 */
             return 0;
         }
 
         /* no */
-        tmax = dabs(tmax);
-        tmin = dabs(tmin);
+        tmax = ckdtree_fabs(tmax);
+        tmin = ckdtree_fabs(tmin);
 
         /* make tmin the closer edge */
         if(tmin > tmax) { t = tmin; tmin = tmax; tmax = t; }
@@ -224,15 +258,15 @@ struct BoxDist1D {
     }
 
     private:
-    static inline npy_float64
-    wrap_distance(const npy_float64 x, const npy_float64 hb, const npy_float64 fb)
+    static inline double
+    wrap_distance(const double x, const double hb, const double fb)
     {
-        npy_float64 x1;
-        if (NPY_UNLIKELY(x < -hb)) x1 = fb + x;
-        else if (NPY_UNLIKELY(x > hb)) x1 = x - fb;
+        double x1;
+        if (CKDTREE_UNLIKELY(x < -hb)) x1 = fb + x;
+        else if (CKDTREE_UNLIKELY(x > hb)) x1 = x - fb;
         else x1 = x;
     #if 0
-        printf(""dabs_b x : %g x1 %g\n"", x, x1);
+        printf(""ckdtree_fabs_b x : %g x1 %g\n"", x, x1);
     #endif
         return x1;
     }
diff --git a/scipy/spatial/ckdtree/src/distance_base.h b/scipy/spatial/ckdtree/src/distance_base.h
index c88e05b5dd60..9321a2931fed 100644
--- a/scipy/spatial/ckdtree/src/distance_base.h
+++ b/scipy/spatial/ckdtree/src/distance_base.h
@@ -7,8 +7,8 @@ struct BaseMinkowskiDistPp {
     static inline void
     interval_interval_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_intp k, const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const ckdtree_intp_t k, const double p,
+                        double *min, double *max)
     {
         /* Compute the minimum/maximum distance along dimension k between points in
          * two hyperrectangles.
@@ -21,13 +21,13 @@ struct BaseMinkowskiDistPp {
     static inline void
     rect_rect_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const double p,
+                        double *min, double *max)
     {
         *min = 0.;
         *max = 0.;
-        for(npy_intp i=0; i<rect1.m; ++i) {
-            npy_float64 min_, max_;
+        for(ckdtree_intp_t i=0; i<rect1.m; ++i) {
+            double min_, max_;
 
             Dist1D::interval_interval(tree, rect1, rect2, i, &min_, &max_);
 
@@ -36,11 +36,11 @@ struct BaseMinkowskiDistPp {
         }
     }
 
-    static inline npy_float64
+    static inline double
     point_point_p(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-               const npy_float64 p, const npy_intp k,
-               const npy_float64 upperbound)
+               const double *x, const double *y,
+               const double p, const ckdtree_intp_t k,
+               const double upperbound)
     {
        /*
         * Compute the distance between x and y
@@ -50,8 +50,8 @@ struct BaseMinkowskiDistPp {
         * than upperbound may be returned (the calculation is truncated).
         */
 
-        npy_intp i;
-        npy_float64 r, r1;
+        ckdtree_intp_t i;
+        double r, r1;
         r = 0;
         for (i=0; i<k; ++i) {
             r1 = Dist1D::point_point(tree, x, y, i);
@@ -62,8 +62,8 @@ struct BaseMinkowskiDistPp {
         return r;
     }
 
-    static inline npy_float64
-    distance_p(const npy_float64 s, const npy_float64 p)
+    static inline double
+    distance_p(const double s, const double p)
     {
         return std::pow(s,p);
     }
@@ -75,8 +75,8 @@ struct BaseMinkowskiDistP1 : public BaseMinkowskiDistPp<Dist1D> {
     static inline void
     interval_interval_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_intp k, const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const ckdtree_intp_t k, const double p,
+                        double *min, double *max)
     {
         /* Compute the minimum/maximum distance along dimension k between points in
          * two hyperrectangles.
@@ -87,13 +87,13 @@ struct BaseMinkowskiDistP1 : public BaseMinkowskiDistPp<Dist1D> {
     static inline void
     rect_rect_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const double p,
+                        double *min, double *max)
     {
         *min = 0.;
         *max = 0.;
-        for(npy_intp i=0; i<rect1.m; ++i) {
-            npy_float64 min_, max_;
+        for(ckdtree_intp_t i=0; i<rect1.m; ++i) {
+            double min_, max_;
 
             Dist1D::interval_interval(tree, rect1, rect2, i, &min_, &max_);
 
@@ -102,14 +102,14 @@ struct BaseMinkowskiDistP1 : public BaseMinkowskiDistPp<Dist1D> {
         }
     }
 
-    static inline npy_float64
+    static inline double
     point_point_p(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-               const npy_float64 p, const npy_intp k,
-               const npy_float64 upperbound)
+               const double *x, const double *y,
+               const double p, const ckdtree_intp_t k,
+               const double upperbound)
     {
-        npy_intp i;
-        npy_float64 r;
+        ckdtree_intp_t i;
+        double r;
         r = 0;
         for (i=0; i<k; ++i) {
             r += Dist1D::point_point(tree, x, y, i);
@@ -119,8 +119,8 @@ struct BaseMinkowskiDistP1 : public BaseMinkowskiDistPp<Dist1D> {
         return r;
     }
 
-    static inline npy_float64
-    distance_p(const npy_float64 s, const npy_float64 p)
+    static inline double
+    distance_p(const double s, const double p)
     {
         return s;
     }
@@ -131,8 +131,8 @@ struct BaseMinkowskiDistPinf : public BaseMinkowskiDistPp<Dist1D> {
     static inline void
     interval_interval_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_intp k, npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const ckdtree_intp_t k, double p,
+                        double *min, double *max)
     {
         return rect_rect_p(tree, rect1, rect2, p, min, max);
     }
@@ -140,39 +140,39 @@ struct BaseMinkowskiDistPinf : public BaseMinkowskiDistPp<Dist1D> {
     static inline void
     rect_rect_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const double p,
+                        double *min, double *max)
     {
         *min = 0.;
         *max = 0.;
-        for(npy_intp i=0; i<rect1.m; ++i) {
-            npy_float64 min_, max_;
+        for(ckdtree_intp_t i=0; i<rect1.m; ++i) {
+            double min_, max_;
 
             Dist1D::interval_interval(tree, rect1, rect2, i, &min_, &max_);
 
-            *min = dmax(*min, min_);
-            *max = dmax(*max, max_);
+            *min = ckdtree_fmax(*min, min_);
+            *max = ckdtree_fmax(*max, max_);
         }
     }
 
-    static inline npy_float64
+    static inline double
     point_point_p(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-               const npy_float64 p, const npy_intp k,
-               const npy_float64 upperbound)
+               const double *x, const double *y,
+               const double p, const ckdtree_intp_t k,
+               const double upperbound)
     {
-        npy_intp i;
-        npy_float64 r;
+        ckdtree_intp_t i;
+        double r;
         r = 0;
         for (i=0; i<k; ++i) {
-            r = dmax(r,Dist1D::point_point(tree, x, y, i));
+            r = ckdtree_fmax(r,Dist1D::point_point(tree, x, y, i));
             if (r>upperbound)
                 return r;
         }
         return r;
     }
-    static inline npy_float64
-    distance_p(const npy_float64 s, const npy_float64 p)
+    static inline double
+    distance_p(const double s, const double p)
     {
         return s;
     }
@@ -183,8 +183,8 @@ struct BaseMinkowskiDistP2 : public BaseMinkowskiDistPp<Dist1D> {
     static inline void
     interval_interval_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_intp k, const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const ckdtree_intp_t k, const double p,
+                        double *min, double *max)
     {
         /* Compute the minimum/maximum distance along dimension k between points in
          * two hyperrectangles.
@@ -197,13 +197,13 @@ struct BaseMinkowskiDistP2 : public BaseMinkowskiDistPp<Dist1D> {
     static inline void
     rect_rect_p(const ckdtree * tree,
                         const Rectangle& rect1, const Rectangle& rect2,
-                        const npy_float64 p,
-                        npy_float64 *min, npy_float64 *max)
+                        const double p,
+                        double *min, double *max)
     {
         *min = 0.;
         *max = 0.;
-        for(npy_intp i=0; i<rect1.m; ++i) {
-            npy_float64 min_, max_;
+        for(ckdtree_intp_t i=0; i<rect1.m; ++i) {
+            double min_, max_;
 
             Dist1D::interval_interval(tree, rect1, rect2, i, &min_, &max_);
             min_ *= min_;
@@ -213,26 +213,26 @@ struct BaseMinkowskiDistP2 : public BaseMinkowskiDistPp<Dist1D> {
             *max += max_;
         }
     }
-    static inline npy_float64
+    static inline double
 
     point_point_p(const ckdtree * tree,
-               const npy_float64 *x, const npy_float64 *y,
-               const npy_float64 p, const npy_intp k,
-               const npy_float64 upperbound)
+               const double *x, const double *y,
+               const double p, const ckdtree_intp_t k,
+               const double upperbound)
     {
-        npy_intp i;
-        npy_float64 r;
+        ckdtree_intp_t i;
+        double r;
         r = 0;
         for (i=0; i<k; ++i) {
-            npy_float64 r1 = Dist1D::point_point(tree, x, y, i);
+            double r1 = Dist1D::point_point(tree, x, y, i);
             r += r1 * r1;
             if (r>upperbound)
                 return r;
         }
         return r;
     }
-    static inline npy_float64
-    distance_p(const npy_float64 s, const npy_float64 p)
+    static inline double
+    distance_p(const double s, const double p)
     {
         return s * s;
     }
diff --git a/scipy/spatial/ckdtree/src/globals.cxx b/scipy/spatial/ckdtree/src/globals.cxx
deleted file mode 100644
index 690ea42b2de9..000000000000
--- a/scipy/spatial/ckdtree/src/globals.cxx
+++ /dev/null
@@ -1 +0,0 @@
-int number_of_processors;
diff --git a/scipy/spatial/ckdtree/src/ordered_pair.h b/scipy/spatial/ckdtree/src/ordered_pair.h
index f6b90607e12a..353d59088829 100644
--- a/scipy/spatial/ckdtree/src/ordered_pair.h
+++ b/scipy/spatial/ckdtree/src/ordered_pair.h
@@ -3,13 +3,13 @@
 #define CKDTREE_ORDERED_PAIR
 
 struct ordered_pair {
-    npy_intp i;
-    npy_intp j;
+    ckdtree_intp_t i;
+    ckdtree_intp_t j;
 };
 
 inline void
 add_ordered_pair(std::vector<ordered_pair> *results,
-                       const npy_intp i, const npy_intp j)
+                       const ckdtree_intp_t i, const intptr_t j)
 {
     if (i > j) {
         ordered_pair p = {j,i};
diff --git a/scipy/spatial/ckdtree/src/partial_sort.h b/scipy/spatial/ckdtree/src/partial_sort.h
index 155b04c6affa..502dc7ef4eef 100644
--- a/scipy/spatial/ckdtree/src/partial_sort.h
+++ b/scipy/spatial/ckdtree/src/partial_sort.h
@@ -2,30 +2,27 @@
 #ifndef CKDTREE_PARTIAL_SORT
 #define CKDTREE_PARTIAL_SORT
 
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 /* Splitting routines for a balanced kd-tree
  * Code originally written by Jake Vanderplas for scikit-learn
  *
  */
 
 inline void
-index_swap(npy_intp *arr, npy_intp i1, npy_intp i2)
+index_swap(ckdtree_intp_t *arr, intptr_t i1, intptr_t i2)
 {
     /* swap the values at index i1 and i2 of arr */
-    npy_intp tmp = arr[i1];
+    ckdtree_intp_t tmp = arr[i1];
     arr[i1] = arr[i2];
     arr[i2] = tmp;
 }
 
 static void
-partition_node_indices(const npy_float64 *data,
-                       npy_intp *node_indices,
-                       npy_intp split_dim,
-                       npy_intp split_index,
-                       npy_intp n_features,
-                       npy_intp n_points)
+partition_node_indices(const double *data,
+                       ckdtree_intp_t *node_indices,
+                       ckdtree_intp_t split_dim,
+                       ckdtree_intp_t split_index,
+                       ckdtree_intp_t n_features,
+                       ckdtree_intp_t n_points)
 {
     /* Partition points in the node into two equal-sized groups
      * Upon return, the values in node_indices will be rearranged such that
@@ -64,8 +61,8 @@ partition_node_indices(const npy_float64 *data,
      *    modified as noted above.
      */
 
-    npy_intp left, right, midindex, i;
-    npy_float64 d1, d2;
+    ckdtree_intp_t left, right, midindex, i;
+    double d1, d2;
     left = 0;
     right = n_points - 1;
     for(;;) {
diff --git a/scipy/spatial/ckdtree/src/query.cxx b/scipy/spatial/ckdtree/src/query.cxx
index 582e9fcd548a..5595826b6580 100644
--- a/scipy/spatial/ckdtree/src/query.cxx
+++ b/scipy/spatial/ckdtree/src/query.cxx
@@ -1,13 +1,3 @@
-/*
- * This would break SciPy with NumPy 1.6 so just accept the compiler
- * warning for now.
- * #define NPY_NO_DEPRECATED_API NPY_1_9_API_VERSION
- *
- */
-
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -20,12 +10,9 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
 #include ""ordered_pair.h""
-#include ""ckdtree_methods.h""
 #include ""rectangle.h""
-#include ""cpp_exc.h""
 
 /*
  * Priority queue
@@ -33,28 +20,28 @@
  */
 
 union heapcontents {
-    npy_intp intdata;
+    ckdtree_intp_t intdata;
     void     *ptrdata;
 };
 
 struct heapitem {
-    npy_float64 priority;
+    double priority;
     heapcontents contents;
 };
 
 struct heap {
 
     std::vector<heapitem> _heap;
-    npy_intp n;
-    npy_intp space;
+    ckdtree_intp_t n;
+    ckdtree_intp_t space;
 
-    heap (npy_intp initial_size) : _heap(initial_size) {
+    heap (ckdtree_intp_t initial_size) : _heap(initial_size) {
         space = initial_size;
         n = 0;
     }
 
     inline void push(heapitem &item) {
-        npy_intp i;
+        ckdtree_intp_t i;
         heapitem t;
         n++;
 
@@ -75,7 +62,7 @@ struct heap {
 
     inline void remove() {
         heapitem t;
-        npy_intp i, j, k, l, nn;
+        ckdtree_intp_t i, j, k, l, nn;
         _heap[0] = _heap[n-1];
         n--;
         /*
@@ -118,36 +105,36 @@ struct heap {
 
 struct nodeinfo {
     const ckdtreenode  *node;
-    npy_intp     m;
-    npy_float64  min_distance; /* full min distance */
-    npy_float64        buf[1]; // the good old struct hack
+    ckdtree_intp_t     m;
+    double  min_distance; /* full min distance */
+    double        buf[1]; // the good old struct hack
     /* accessors to 'packed' attributes */
-    inline npy_float64        * const side_distances() {
+    inline double        * const side_distances() {
         /* min distance to the query per side; we
          * update this as the query is proceeded */
         return buf;
     }
-    inline npy_float64        * const maxes() {
+    inline double        * const maxes() {
         return buf + m;
     }
-    inline npy_float64        * const mins() {
+    inline double        * const mins() {
         return buf + 2 * m;
     }
 
     inline void init_box(const struct nodeinfo * from) {
-        std::memcpy(buf, from->buf, sizeof(npy_float64) * (3 * m));
+        std::memcpy(buf, from->buf, sizeof(double) * (3 * m));
         min_distance = from->min_distance;
     }
 
     inline void init_plain(const struct nodeinfo * from) {
         /* skip copying min and max, because we only need side_distance array in this case. */
-        std::memcpy(buf, from->buf, sizeof(npy_float64) * m);
+        std::memcpy(buf, from->buf, sizeof(double) * m);
         min_distance = from->min_distance;
     }
 
-    inline void update_side_distance(const int d, const npy_float64 new_side_distance, const npy_float64 p) {
-        if (NPY_UNLIKELY(ckdtree_isinf(p))) {
-            min_distance = dmax(min_distance, new_side_distance);
+    inline void update_side_distance(const int d, const double new_side_distance, const double p) {
+        if (CKDTREE_UNLIKELY(ckdtree_isinf(p))) {
+            min_distance = ckdtree_fmax(min_distance, new_side_distance);
         } else {
             min_distance += new_side_distance - side_distances()[d];
         }
@@ -164,14 +151,14 @@ struct nodeinfo_pool {
 
     std::vector<char*> pool;
 
-    npy_intp alloc_size;
-    npy_intp arena_size;
-    npy_intp m;
+    ckdtree_intp_t alloc_size;
+    ckdtree_intp_t arena_size;
+    ckdtree_intp_t m;
     char *arena;
     char *arena_ptr;
 
-    nodeinfo_pool(npy_intp m) {
-        alloc_size = sizeof(nodeinfo) + (3 * m -1)*sizeof(npy_float64);
+    nodeinfo_pool(ckdtree_intp_t m) {
+        alloc_size = sizeof(nodeinfo) + (3 * m -1)*sizeof(double);
         alloc_size = 64*(alloc_size/64)+64;
         arena_size = 4096*((64*alloc_size)/4096)+4096;
         arena = new char[arena_size];
@@ -181,15 +168,15 @@ struct nodeinfo_pool {
     }
 
     ~nodeinfo_pool() {
-        for (npy_intp i = pool.size()-1; i >= 0; --i)
+        for (ckdtree_intp_t i = pool.size()-1; i >= 0; --i)
             delete [] pool[i];
     }
 
     inline nodeinfo *allocate() {
         nodeinfo *ni1;
-        npy_uintp m1 = (npy_uintp)arena_ptr;
-        npy_uintp m0 = (npy_uintp)arena;
-        if ((arena_size-(npy_intp)(m1-m0))<alloc_size) {
+        ckdtree_intp_t m1 = (ckdtree_intp_t)arena_ptr;
+        ckdtree_intp_t m0 = (ckdtree_intp_t)arena;
+        if ((arena_size-(ckdtree_intp_t)(m1-m0))<alloc_size) {
             arena = new char[arena_size];
             arena_ptr = arena;
             pool.push_back(arena);
@@ -205,16 +192,18 @@ struct nodeinfo_pool {
 template <typename MinMaxDist>
 static void
 query_single_point(const ckdtree *self,
-                   npy_float64   *result_distances,
-                   npy_intp      *result_indices,
-                   const npy_float64  *x,
-                   const npy_intp     *k,
-                   const npy_intp     nk,
-                   const npy_intp     kmax,
-                   const npy_float64  eps,
-                   const npy_float64  p,
-                   npy_float64  distance_upper_bound)
+                   double   *result_distances,
+                   ckdtree_intp_t      *result_indices,
+                   const double  *x,
+                   const ckdtree_intp_t     *k,
+                   const ckdtree_intp_t     nk,
+                   const ckdtree_intp_t     kmax,
+                   const double  eps,
+                   const double  p,
+                   double  distance_upper_bound)
 {
+    static double inf = strtod(""INF"", NULL);
+
     /* memory pool to allocate and automatically reclaim nodeinfo structs */
     nodeinfo_pool nipool(self->m);
 
@@ -236,12 +225,12 @@ query_single_point(const ckdtree *self,
      */
     heap neighbors(kmax);
 
-    npy_intp      i;
-    const npy_intp m = self->m;
+    ckdtree_intp_t      i;
+    const ckdtree_intp_t m = self->m;
     nodeinfo      *ni1;
     nodeinfo      *ni2;
-    npy_float64   d;
-    npy_float64   epsfac;
+    double   d;
+    double   epsfac;
     heapitem      it, it2, neighbor;
     const ckdtreenode   *node;
     const ckdtreenode   *inode;
@@ -257,7 +246,7 @@ query_single_point(const ckdtree *self,
         ni1->mins()[i] = self->raw_mins[i];
         ni1->maxes()[i] = self->raw_maxes[i];
 
-        npy_float64 side_distance;
+        double side_distance;
         if(self->raw_boxsize_data != NULL) {
             side_distance = BoxDist1D::side_distance_from_min_max(
                 self, x[i], self->raw_mins[i], self->raw_maxes[i], i);
@@ -272,8 +261,8 @@ query_single_point(const ckdtree *self,
     }
 
     /* fiddle approximation factor */
-    if (NPY_LIKELY(p == 2.0)) {
-        npy_float64 tmp = 1. + eps;
+    if (CKDTREE_LIKELY(p == 2.0)) {
+        double tmp = 1. + eps;
         epsfac = 1. / (tmp*tmp);
     }
     else if (eps == 0.)
@@ -284,11 +273,11 @@ query_single_point(const ckdtree *self,
         epsfac = 1. / std::pow((1. + eps), p);
 
     /* internally we represent all distances as distance**p */
-    if (NPY_LIKELY(p == 2.0)) {
-        npy_float64 tmp = distance_upper_bound;
+    if (CKDTREE_LIKELY(p == 2.0)) {
+        double tmp = distance_upper_bound;
         distance_upper_bound = tmp*tmp;
     }
-    else if ((!ckdtree_isinf(p)) && (!ckdtree_isinf(distance_upper_bound)))
+    else if ((!ckdtree_isinf(p)) && (!isinf(distance_upper_bound)))
         distance_upper_bound = std::pow(distance_upper_bound,p);
 
     for(;;) {
@@ -298,19 +287,19 @@ query_single_point(const ckdtree *self,
 
             /* brute-force */
             {
-                const npy_intp start_idx = node->start_idx;
-                const npy_intp end_idx = node->end_idx;
-                const npy_float64 *data = self->raw_data;
-                const npy_intp *indices = self->raw_indices;
+                const ckdtree_intp_t start_idx = node->start_idx;
+                const ckdtree_intp_t end_idx = node->end_idx;
+                const double *data = self->raw_data;
+                const ckdtree_intp_t *indices = self->raw_indices;
 
-                prefetch_datapoint(data+indices[start_idx]*m, m);
+                CKDTREE_PREFETCH(data+indices[start_idx]*m, 0, m);
                 if (start_idx < end_idx - 1)
-                    prefetch_datapoint(data+indices[start_idx+1]*m, m);
+                    CKDTREE_PREFETCH(data+indices[start_idx+1]*m, 0, m);
 
                 for (i=start_idx; i<end_idx; ++i) {
 
                     if (i < end_idx - 2)
-                        prefetch_datapoint(data+indices[i+2]*m, m);
+                        CKDTREE_PREFETCH(data+indices[i+2]*m, 0, m);
 
                     d = MinMaxDist::point_point_p(self, data+indices[i]*m, x, p, m, distance_upper_bound);
                     if (d < distance_upper_bound) {
@@ -340,8 +329,8 @@ query_single_point(const ckdtree *self,
         }
         else {
             inode = ni1->node;
-            const npy_intp split_dim = inode->split_dim;
-            const npy_float64 split = inode->split;
+            const ckdtree_intp_t split_dim = inode->split_dim;
+            const double split = inode->split;
 
             /*
              * we don't push cells that are too far onto the queue at all,
@@ -357,7 +346,7 @@ query_single_point(const ckdtree *self,
 
             ni2 = nipool.allocate();
 
-            if (NPY_LIKELY(self->raw_boxsize_data == NULL)) {
+            if (CKDTREE_LIKELY(self->raw_boxsize_data == NULL)) {
                 /*
                  * non periodic : the 'near' node is know from the
                  * relative distance to the split, and
@@ -370,7 +359,7 @@ query_single_point(const ckdtree *self,
                  */
                 ni2->init_plain(ni1);
 
-                npy_float64 side_distance;
+                double side_distance;
 
                 if (x[split_dim] < split) {
                     ni1->node = inode->less;
@@ -394,7 +383,7 @@ query_single_point(const ckdtree *self,
                  */
                 ni2->init_box(ni1);
 
-                npy_float64 side_distance;
+                double side_distance;
 
                 ni1->maxes()[split_dim] = split;
                 ni1->node = inode->less;
@@ -453,20 +442,20 @@ query_single_point(const ckdtree *self,
 
     /* heapsort */
     std::vector<heapitem> sorted_neighbors(kmax);
-    npy_intp nnb = neighbors.n;
+    ckdtree_intp_t nnb = neighbors.n;
     for(i = neighbors.n - 1; i >=0; --i) {
         sorted_neighbors[i] = neighbors.pop();
     }
 
     /* fill output arrays with sorted neighbors */
     for (i = 0; i < nk; ++i) {
-        if(NPY_UNLIKELY(k[i] - 1 >= nnb)) {
+        if(CKDTREE_UNLIKELY(k[i] - 1 >= nnb)) {
             result_indices[i] = self->n;
-            result_distances[i] = NPY_INFINITY;
+            result_distances[i] = inf;
         } else {
             neighbor = sorted_neighbors[k[i] - 1];
             result_indices[i] = neighbor.contents.intdata;
-            if (NPY_LIKELY(p == 2.0))
+            if (CKDTREE_LIKELY(p == 2.0))
                 result_distances[i] = std::sqrt(-neighbor.priority);
             else if ((p == 1.) || (ckdtree_isinf(p)))
                 result_distances[i] = -neighbor.priority;
@@ -478,74 +467,56 @@ query_single_point(const ckdtree *self,
 
 /* Query n points for their k nearest neighbors */
 
-extern ""C"" PyObject*
+int
 query_knn(const ckdtree      *self,
-          npy_float64        *dd,
-          npy_intp           *ii,
-          const npy_float64  *xx,
-          const npy_intp     n,
-          const npy_intp*     k,
-          const npy_intp     nk,
-          const npy_intp     kmax,
-          const npy_float64  eps,
-          const npy_float64  p,
-          const npy_float64  distance_upper_bound)
+          double        *dd,
+          ckdtree_intp_t           *ii,
+          const double  *xx,
+          const ckdtree_intp_t     n,
+          const ckdtree_intp_t*     k,
+          const ckdtree_intp_t     nk,
+          const ckdtree_intp_t     kmax,
+          const double  eps,
+          const double  p,
+          const double  distance_upper_bound)
 {
 #define HANDLE(cond, kls) \
     if(cond) { \
         query_single_point<kls>(self, dd_row, ii_row, xx_row, k, nk, kmax, eps, p, distance_upper_bound); \
     } else
 
-    npy_intp m = self->m;
-    npy_intp i;
-
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            if(NPY_LIKELY(!self->raw_boxsize_data)) {
-                for (i=0; i<n; ++i) {
-                    npy_float64 *dd_row = dd + (i*nk);
-                    npy_intp *ii_row = ii + (i*nk);
-                    const npy_float64 *xx_row = xx + (i*m);
-                    HANDLE(NPY_LIKELY(p == 2), MinkowskiDistP2)
-                    HANDLE(p == 1, MinkowskiDistP1)
-                    HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
-                    HANDLE(1, MinkowskiDistPp)
-                    {}
-                }
-            } else {
-                std::vector<npy_float64> row(m);
-                npy_float64 * xx_row = &row[0];
-                int j;
-                for (i=0; i<n; ++i) {
-                    npy_float64 *dd_row = dd + (i*nk);
-                    npy_intp *ii_row = ii + (i*nk);
-                    const npy_float64 *old_xx_row = xx + (i*m);
-                    for(j=0; j<m; ++j) {
-                        xx_row[j] = BoxDist1D::wrap_position(old_xx_row[j], self->raw_boxsize_data[j]);
-                    }
-                    HANDLE(NPY_LIKELY(p == 2), BoxMinkowskiDistP2)
-                    HANDLE(p == 1, BoxMinkowskiDistP1)
-                    HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
-                    HANDLE(1, BoxMinkowskiDistPp) {}
-                }
-
-            }
+    ckdtree_intp_t m = self->m;
+    ckdtree_intp_t i;
+
+    if(CKDTREE_LIKELY(!self->raw_boxsize_data)) {
+        for (i=0; i<n; ++i) {
+            double *dd_row = dd + (i*nk);
+            ckdtree_intp_t *ii_row = ii + (i*nk);
+            const double *xx_row = xx + (i*m);
+            HANDLE(CKDTREE_LIKELY(p == 2), MinkowskiDistP2)
+            HANDLE(p == 1, MinkowskiDistP1)
+            HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
+            HANDLE(1, MinkowskiDistPp)
+            {}
         }
-        catch(...) {
-            translate_cpp_exception_with_gil();
+    } else {
+        std::vector<double> row(m);
+        double * xx_row = &row[0];
+        int j;
+        for (i=0; i<n; ++i) {
+            double *dd_row = dd + (i*nk);
+            ckdtree_intp_t *ii_row = ii + (i*nk);
+            const double *old_xx_row = xx + (i*m);
+            for(j=0; j<m; ++j) {
+                xx_row[j] = BoxDist1D::wrap_position(old_xx_row[j], self->raw_boxsize_data[j]);
+            }
+            HANDLE(CKDTREE_LIKELY(p == 2), BoxMinkowskiDistP2)
+            HANDLE(p == 1, BoxMinkowskiDistP1)
+            HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
+            HANDLE(1, BoxMinkowskiDistPp) {}
         }
+
     }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
-    }
+    return 0;
 }
 
diff --git a/scipy/spatial/ckdtree/src/query_ball_point.cxx b/scipy/spatial/ckdtree/src/query_ball_point.cxx
index 528a0c6c4e4b..551d3bed052d 100644
--- a/scipy/spatial/ckdtree/src/query_ball_point.cxx
+++ b/scipy/spatial/ckdtree/src/query_ball_point.cxx
@@ -1,6 +1,3 @@
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -13,27 +10,24 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
-#include ""ckdtree_methods.h""
-#include ""cpp_exc.h""
 #include ""rectangle.h""
 
 
 static void
 traverse_no_checking(const ckdtree *self,
                      const int return_length,
-                     std::vector<npy_intp> *results,
+                     std::vector<ckdtree_intp_t> *results,
                      const ckdtreenode *node)
 {
-    const npy_intp *indices = self->raw_indices;
+    const ckdtree_intp_t *indices = self->raw_indices;
     const ckdtreenode *lnode;
-    npy_intp i;
+    ckdtree_intp_t i;
 
     if (node->split_dim == -1) {  /* leaf node */
         lnode = node;
-        const npy_intp start = lnode->start_idx;
-        const npy_intp end = lnode->end_idx;
+        const ckdtree_intp_t start = lnode->start_idx;
+        const ckdtree_intp_t end = lnode->end_idx;
         for (i = start; i < end; ++i) {
             if (return_length) {
                 (*results)[0] ++;
@@ -52,14 +46,14 @@ traverse_no_checking(const ckdtree *self,
 template <typename MinMaxDist> static void
 traverse_checking(const ckdtree *self,
                   const int return_length,
-                  std::vector<npy_intp> *results,
+                  std::vector<ckdtree_intp_t> *results,
                   const ckdtreenode *node,
                   RectRectDistanceTracker<MinMaxDist> *tracker
 )
 {
     const ckdtreenode *lnode;
-    npy_float64 d;
-    npy_intp i;
+    double d;
+    ckdtree_intp_t i;
 
     if (tracker->min_distance > tracker->upper_bound * tracker->epsfac) {
         return;
@@ -71,23 +65,23 @@ traverse_checking(const ckdtree *self,
 
         /* brute-force */
         lnode = node;
-        const npy_float64 p = tracker->p;
-        const npy_float64 tub = tracker->upper_bound;
-        const npy_float64 *tpt = tracker->rect1.mins();
-        const npy_float64 *data = self->raw_data;
-        const npy_intp *indices = self->raw_indices;
-        const npy_intp m = self->m;
-        const npy_intp start = lnode->start_idx;
-        const npy_intp end = lnode->end_idx;
-
-        prefetch_datapoint(data + indices[start] * m, m);
+        const double p = tracker->p;
+        const double tub = tracker->upper_bound;
+        const double *tpt = tracker->rect1.mins();
+        const double *data = self->raw_data;
+        const ckdtree_intp_t *indices = self->raw_indices;
+        const ckdtree_intp_t m = self->m;
+        const ckdtree_intp_t start = lnode->start_idx;
+        const ckdtree_intp_t end = lnode->end_idx;
+
+        CKDTREE_PREFETCH(data + indices[start] * m, 0, m);
         if (start < end - 1)
-            prefetch_datapoint(data + indices[start+1] * m, m);
+            CKDTREE_PREFETCH(data + indices[start+1] * m, 0, m);
 
         for (i = start; i < end; ++i) {
 
             if (i < end -2 )
-                prefetch_datapoint(data + indices[i+2] * m, m);
+                CKDTREE_PREFETCH(data + indices[i+2] * m, 0, m);
 
             d = MinMaxDist::point_point_p(self, data + indices[i] * m, tpt, p, m, tub);
 
@@ -95,7 +89,7 @@ traverse_checking(const ckdtree *self,
                 if(return_length) {
                     (*results)[0] ++;
                 } else {
-                    results->push_back((npy_intp) indices[i]);
+                    results->push_back((ckdtree_intp_t) indices[i]);
                 }
             }
         }
@@ -111,12 +105,11 @@ traverse_checking(const ckdtree *self,
     }
 }
 
-
-extern ""C"" PyObject*
-query_ball_point(const ckdtree *self, const npy_float64 *x,
-                 const npy_float64 *r, const npy_float64 p, const npy_float64 eps,
-                 const npy_intp n_queries,
-                 std::vector<npy_intp> **results, const int return_length)
+int
+query_ball_point(const ckdtree *self, const double *x,
+                 const double *r, const double p, const double eps,
+                 const ckdtree_intp_t n_queries,
+                 std::vector<ckdtree_intp_t> **results, const int return_length)
 {
 #define HANDLE(cond, kls) \
     if(cond) { \
@@ -125,46 +118,28 @@ query_ball_point(const ckdtree *self, const npy_float64 *x,
         traverse_checking(self, return_length, results[i], self->ctree, &tracker); \
     } else
 
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            for (npy_intp i=0; i < n_queries; ++i) {
-                const npy_intp m = self->m;
-                Rectangle rect(m, self->raw_mins, self->raw_maxes);
-                if (NPY_LIKELY(self->raw_boxsize_data == NULL)) {
-                    Rectangle point(m, x + i * m, x + i * m);
-                    HANDLE(NPY_LIKELY(p == 2), MinkowskiDistP2)
-                    HANDLE(p == 1, MinkowskiDistP1)
-                    HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
-                    HANDLE(1, MinkowskiDistPp)
-                    {}
-                } else {
-                    Rectangle point(m, x + i * m, x + i * m);
-                    int j;
-                    for(j=0; j<m; ++j) {
-                        point.maxes()[j] = point.mins()[j] = BoxDist1D::wrap_position(point.mins()[j], self->raw_boxsize_data[j]);
-                    }
-                    HANDLE(NPY_LIKELY(p == 2), BoxMinkowskiDistP2)
-                    HANDLE(p == 1, BoxMinkowskiDistP1)
-                    HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
-                    HANDLE(1, BoxMinkowskiDistPp)
-                    {}
-                }
+    for (ckdtree_intp_t i=0; i < n_queries; ++i) {
+        const ckdtree_intp_t m = self->m;
+        Rectangle rect(m, self->raw_mins, self->raw_maxes);
+        if (CKDTREE_LIKELY(self->raw_boxsize_data == NULL)) {
+            Rectangle point(m, x + i * m, x + i * m);
+            HANDLE(CKDTREE_LIKELY(p == 2), MinkowskiDistP2)
+            HANDLE(p == 1, MinkowskiDistP1)
+            HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
+            HANDLE(1, MinkowskiDistPp)
+            {}
+        } else {
+            Rectangle point(m, x + i * m, x + i * m);
+            int j;
+            for(j=0; j<m; ++j) {
+                point.maxes()[j] = point.mins()[j] = BoxDist1D::wrap_position(point.mins()[j], self->raw_boxsize_data[j]);
             }
+            HANDLE(CKDTREE_LIKELY(p == 2), BoxMinkowskiDistP2)
+            HANDLE(p == 1, BoxMinkowskiDistP1)
+            HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
+            HANDLE(1, BoxMinkowskiDistPp)
+            {}
         }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
     }
+    return 0;
 }
diff --git a/scipy/spatial/ckdtree/src/query_ball_tree.cxx b/scipy/spatial/ckdtree/src/query_ball_tree.cxx
index 8d3fc0102938..b71d257f5445 100644
--- a/scipy/spatial/ckdtree/src/query_ball_tree.cxx
+++ b/scipy/spatial/ckdtree/src/query_ball_tree.cxx
@@ -1,6 +1,3 @@
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -13,24 +10,21 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
-#include ""ckdtree_methods.h""
-#include ""cpp_exc.h""
 #include ""rectangle.h""
 
 
 static void
 traverse_no_checking(const ckdtree *self, const ckdtree *other,
-                     std::vector<npy_intp> **results,
+                     std::vector<ckdtree_intp_t> **results,
                      const ckdtreenode *node1, const ckdtreenode *node2)
 {
     const ckdtreenode *lnode1;
     const ckdtreenode *lnode2;
-    const npy_intp *sindices = self->raw_indices;
-    const npy_intp *oindices = other->raw_indices;
-    std::vector<npy_intp> *results_i;
-    npy_intp i, j;
+    const ckdtree_intp_t *sindices = self->raw_indices;
+    const ckdtree_intp_t *oindices = other->raw_indices;
+    std::vector<ckdtree_intp_t> *results_i;
+    ckdtree_intp_t i, j;
 
     if (node1->split_dim == -1) {   /* leaf node */
         lnode1 = node1;
@@ -38,10 +32,10 @@ traverse_no_checking(const ckdtree *self, const ckdtree *other,
         if (node2->split_dim == -1) {  /* leaf node */
             lnode2 = node2;
 
-            const npy_intp start1 = lnode1->start_idx;
-            const npy_intp start2 = lnode2->start_idx;
-            const npy_intp end1 = lnode1->end_idx;
-            const npy_intp end2 = lnode2->end_idx;
+            const ckdtree_intp_t start1 = lnode1->start_idx;
+            const ckdtree_intp_t start2 = lnode2->start_idx;
+            const ckdtree_intp_t end1 = lnode1->end_idx;
+            const ckdtree_intp_t end2 = lnode2->end_idx;
 
             for (i = start1; i < end1; ++i) {
                 results_i = results[sindices[i]];
@@ -63,15 +57,15 @@ traverse_no_checking(const ckdtree *self, const ckdtree *other,
 
 template <typename MinMaxDist> static void
 traverse_checking(const ckdtree *self, const ckdtree *other,
-                  std::vector<npy_intp> **results,
+                  std::vector<ckdtree_intp_t> **results,
                   const ckdtreenode *node1, const ckdtreenode *node2,
                   RectRectDistanceTracker<MinMaxDist> *tracker)
 {
     const ckdtreenode *lnode1;
     const ckdtreenode *lnode2;
-    std::vector<npy_intp> *results_i;
-    npy_float64 d;
-    npy_intp i, j;
+    std::vector<ckdtree_intp_t> *results_i;
+    double d;
+    ckdtree_intp_t i, j;
 
     if (tracker->min_distance > tracker->upper_bound * tracker->epsfac)
         return;
@@ -84,40 +78,40 @@ traverse_checking(const ckdtree *self, const ckdtree *other,
 
             /* brute-force */
             lnode2 = node2;
-            const npy_float64 p = tracker->p;
-            const npy_float64 tub = tracker->upper_bound;
-            const npy_float64 tmd = tracker->max_distance;
-            const npy_float64 *sdata = self->raw_data;
-            const npy_intp *sindices = self->raw_indices;
-            const npy_float64 *odata = other->raw_data;
-            const npy_intp *oindices = other->raw_indices;
-            const npy_intp m = self->m;
-            const npy_intp start1 = lnode1->start_idx;
-            const npy_intp start2 = lnode2->start_idx;
-            const npy_intp end1 = lnode1->end_idx;
-            const npy_intp end2 = lnode2->end_idx;
-
-            prefetch_datapoint(sdata + sindices[start1] * m, m);
+            const double p = tracker->p;
+            const double tub = tracker->upper_bound;
+            const double tmd = tracker->max_distance;
+            const double *sdata = self->raw_data;
+            const ckdtree_intp_t *sindices = self->raw_indices;
+            const double *odata = other->raw_data;
+            const ckdtree_intp_t *oindices = other->raw_indices;
+            const ckdtree_intp_t m = self->m;
+            const ckdtree_intp_t start1 = lnode1->start_idx;
+            const ckdtree_intp_t start2 = lnode2->start_idx;
+            const ckdtree_intp_t end1 = lnode1->end_idx;
+            const ckdtree_intp_t end2 = lnode2->end_idx;
+
+            CKDTREE_PREFETCH(sdata + sindices[start1] * m, 0, m);
 
             if (start1 < end1 - 1)
-                prefetch_datapoint(sdata + sindices[start1+1] * m, m);
+                CKDTREE_PREFETCH(sdata + sindices[start1+1] * m, 0, m);
 
             for (i = start1; i < end1; ++i) {
 
                 if (i < end1 - 2)
-                    prefetch_datapoint(sdata + sindices[i+2] * m, m);
+                    CKDTREE_PREFETCH(sdata + sindices[i+2] * m, 0, m);
 
-                prefetch_datapoint(odata + oindices[start2] * m, m);
+                CKDTREE_PREFETCH(odata + oindices[start2] * m, 0, m);
 
                 if (start2 < end2 - 1)
-                    prefetch_datapoint(odata + oindices[start2+1] * m, m);
+                    CKDTREE_PREFETCH(odata + oindices[start2+1] * m, 0, m);
 
                 results_i = results[sindices[i]];
 
                 for (j = start2; j < end2; ++j) {
 
                     if (j < end2 - 2)
-                        prefetch_datapoint(odata + oindices[j+2] * m, m);
+                        CKDTREE_PREFETCH(odata + oindices[j+2] * m, 0, m);
 
                     d = MinMaxDist::point_point_p(
                             self,
@@ -186,11 +180,10 @@ traverse_checking(const ckdtree *self, const ckdtree *other,
     }
 }
 
-
-extern ""C"" PyObject*
+int
 query_ball_tree(const ckdtree *self, const ckdtree *other,
-                const npy_float64 r, const npy_float64 p, const npy_float64 eps,
-                std::vector<npy_intp> **results)
+                const double r, const double p, const double eps,
+                std::vector<ckdtree_intp_t> **results)
 {
 
 #define HANDLE(cond, kls) \
@@ -200,39 +193,21 @@ query_ball_tree(const ckdtree *self, const ckdtree *other,
             &tracker); \
     } else
 
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-            Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
-            Rectangle r2(other->m, other->raw_mins, other->raw_maxes);
-
-            if(NPY_LIKELY(self->raw_boxsize_data == NULL)) {
-                HANDLE(NPY_LIKELY(p == 2), MinkowskiDistP2)
-                HANDLE(p == 1, MinkowskiDistP1)
-                HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
-                HANDLE(1, MinkowskiDistPp)
-                {}
-            } else {
-                HANDLE(NPY_LIKELY(p == 2), BoxMinkowskiDistP2)
-                HANDLE(p == 1, BoxMinkowskiDistP1)
-                HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
-                HANDLE(1, BoxMinkowskiDistPp)
-                {}
-            }
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
+    Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
+    Rectangle r2(other->m, other->raw_mins, other->raw_maxes);
+
+    if(CKDTREE_LIKELY(self->raw_boxsize_data == NULL)) {
+        HANDLE(CKDTREE_LIKELY(p == 2), MinkowskiDistP2)
+        HANDLE(p == 1, MinkowskiDistP1)
+        HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
+        HANDLE(1, MinkowskiDistPp)
+        {}
+    } else {
+        HANDLE(CKDTREE_LIKELY(p == 2), BoxMinkowskiDistP2)
+        HANDLE(p == 1, BoxMinkowskiDistP1)
+        HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
+        HANDLE(1, BoxMinkowskiDistPp)
+        {}
     }
+    return 0;
 }
diff --git a/scipy/spatial/ckdtree/src/query_pairs.cxx b/scipy/spatial/ckdtree/src/query_pairs.cxx
index 0ae54f8741f1..dd5dab0b9c9d 100644
--- a/scipy/spatial/ckdtree/src/query_pairs.cxx
+++ b/scipy/spatial/ckdtree/src/query_pairs.cxx
@@ -1,6 +1,3 @@
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -13,11 +10,8 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
 #include ""ordered_pair.h""
-#include ""ckdtree_methods.h""
-#include ""cpp_exc.h""
 #include ""rectangle.h""
 
 
@@ -28,8 +22,8 @@ traverse_no_checking(const ckdtree *self,
 {
     const ckdtreenode *lnode1;
     const ckdtreenode *lnode2;
-    npy_intp i, j, min_j;
-    const npy_intp *indices = self->raw_indices;
+    ckdtree_intp_t i, j, min_j;
+    const ckdtree_intp_t *indices = self->raw_indices;
 
     if (node1->split_dim == -1) { /* leaf node */
         lnode1 = node1;
@@ -37,10 +31,10 @@ traverse_no_checking(const ckdtree *self,
         if (node2->split_dim == -1) { /* leaf node */
             lnode2 = node2;
 
-            const npy_intp start1 = lnode1->start_idx;
-            const npy_intp start2 = lnode2->start_idx;
-            const npy_intp end1 = lnode1->end_idx;
-            const npy_intp end2 = lnode2->end_idx;
+            const ckdtree_intp_t start1 = lnode1->start_idx;
+            const ckdtree_intp_t start2 = lnode2->start_idx;
+            const ckdtree_intp_t end1 = lnode1->end_idx;
+            const ckdtree_intp_t end2 = lnode2->end_idx;
 
             for (i = start1; i < end1; ++i) {
 
@@ -87,8 +81,8 @@ traverse_checking(const ckdtree *self,
 {
     const ckdtreenode *lnode1;
     const ckdtreenode *lnode2;
-    npy_float64 d;
-    npy_intp i, j, min_j;
+    double d;
+    ckdtree_intp_t i, j, min_j;
 
     if (tracker->min_distance > tracker->upper_bound * tracker->epsfac)
         return;
@@ -101,24 +95,24 @@ traverse_checking(const ckdtree *self,
             lnode2 = node2;
 
             /* brute-force */
-            const npy_float64 p = tracker->p;
-            const npy_float64 tub = tracker->upper_bound;
-            const npy_float64 *data = self->raw_data;
-            const npy_intp *indices = self->raw_indices;
-            const npy_intp m = self->m;
-            const npy_intp start1 = lnode1->start_idx;
-            const npy_intp start2 = lnode2->start_idx;
-            const npy_intp end1 = lnode1->end_idx;
-            const npy_intp end2 = lnode2->end_idx;
-
-            prefetch_datapoint(data+indices[start1]*m, m);
+            const double p = tracker->p;
+            const double tub = tracker->upper_bound;
+            const double *data = self->raw_data;
+            const ckdtree_intp_t *indices = self->raw_indices;
+            const ckdtree_intp_t m = self->m;
+            const ckdtree_intp_t start1 = lnode1->start_idx;
+            const ckdtree_intp_t start2 = lnode2->start_idx;
+            const ckdtree_intp_t end1 = lnode1->end_idx;
+            const ckdtree_intp_t end2 = lnode2->end_idx;
+
+            CKDTREE_PREFETCH(data+indices[start1]*m, 0, m);
             if (start1 < end1 - 1)
-               prefetch_datapoint(data+indices[start1+1]*m, m);
+               CKDTREE_PREFETCH(data+indices[start1+1]*m, 0, m);
 
             for(i = start1; i < end1; ++i) {
 
                 if (i < end1 - 2)
-                     prefetch_datapoint(data+indices[i+2]*m, m);
+                     CKDTREE_PREFETCH(data+indices[i+2]*m, 0, m);
 
                 /* Special care here to avoid duplicate pairs */
                 if (node1 == node2)
@@ -127,14 +121,14 @@ traverse_checking(const ckdtree *self,
                     min_j = start2;
 
                 if (min_j < end2)
-                    prefetch_datapoint(data+indices[min_j]*m, m);
+                    CKDTREE_PREFETCH(data+indices[min_j]*m, 0, m);
                 if (min_j < end2 - 1)
-                    prefetch_datapoint(data+indices[min_j+1]*m, m);
+                    CKDTREE_PREFETCH(data+indices[min_j+1]*m, 0, m);
 
                 for (j = min_j; j < end2; ++j) {
 
                     if (j < end2 - 2)
-                        prefetch_datapoint(data+indices[j+2]*m, m);
+                        CKDTREE_PREFETCH(data+indices[j+2]*m, 0, m);
 
                     d = MinMaxDist::point_point_p(
                             self,
@@ -204,9 +198,9 @@ traverse_checking(const ckdtree *self,
 
 #include <iostream>
 
-extern ""C"" PyObject*
+int
 query_pairs(const ckdtree *self,
-            const npy_float64 r, const npy_float64 p, const npy_float64 eps,
+            const double r, const double p, const double eps,
             std::vector<ordered_pair> *results)
 {
 
@@ -217,42 +211,23 @@ query_pairs(const ckdtree *self,
             &tracker); \
     } else
 
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-
-            Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
-            Rectangle r2(self->m, self->raw_mins, self->raw_maxes);
-
-            if(NPY_LIKELY(self->raw_boxsize_data == NULL)) {
-                HANDLE(NPY_LIKELY(p == 2), MinkowskiDistP2)
-                HANDLE(p == 1, MinkowskiDistP1)
-                HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
-                HANDLE(1, MinkowskiDistPp)
-                {}
-            } else {
-                HANDLE(NPY_LIKELY(p == 2), BoxMinkowskiDistP2)
-                HANDLE(p == 1, BoxMinkowskiDistP1)
-                HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
-                HANDLE(1, BoxMinkowskiDistPp)
-                {}
-            }
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
+    Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
+    Rectangle r2(self->m, self->raw_mins, self->raw_maxes);
+
+    if(CKDTREE_LIKELY(self->raw_boxsize_data == NULL)) {
+        HANDLE(CKDTREE_LIKELY(p == 2), MinkowskiDistP2)
+        HANDLE(p == 1, MinkowskiDistP1)
+        HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
+        HANDLE(1, MinkowskiDistPp)
+        {}
+    } else {
+        HANDLE(CKDTREE_LIKELY(p == 2), BoxMinkowskiDistP2)
+        HANDLE(p == 1, BoxMinkowskiDistP1)
+        HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
+        HANDLE(1, BoxMinkowskiDistPp)
+        {}
     }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
 
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
-    }
+    return 0;
 }
 
diff --git a/scipy/spatial/ckdtree/src/rectangle.h b/scipy/spatial/ckdtree/src/rectangle.h
index 92bfce3472cc..0a9c46b4b5bd 100644
--- a/scipy/spatial/ckdtree/src/rectangle.h
+++ b/scipy/spatial/ckdtree/src/rectangle.h
@@ -10,46 +10,36 @@
 #include <cstring>
 
 
-#ifndef NPY_UNLIKELY
-#define NPY_UNLIKELY(x) (x)
-#endif
-
-#ifndef NPY_LIKELY
-#define NPY_LIKELY(x) (x)
-#endif
-
-
 /* Interval arithmetic
  * ===================
  */
 
 struct Rectangle {
 
-    const npy_intp m;
+    const ckdtree_intp_t m;
 
     /* the last const is to allow const Rectangle to use these functions;
      * also notice we had to mark buf mutable to avoid writing non const version
      * of the same accessors. */
-    npy_float64 * const maxes() const { return &buf[0]; }
-    npy_float64 * const mins() const { return &buf[0] + m; }
+    double * const maxes() const { return &buf[0]; }
+    double * const mins() const { return &buf[0] + m; }
 
-    Rectangle(const npy_intp _m,
-              const npy_float64 *_mins,
-              const npy_float64 *_maxes) : m(_m), buf(2 * m) {
+    Rectangle(const ckdtree_intp_t _m,
+              const double *_mins,
+              const double *_maxes) : m(_m), buf(2 * m) {
 
         /* copy array data */
         /* FIXME: use std::vector ? */
-        std::memcpy((void*)mins(), (void*)_mins, m*sizeof(npy_float64));
-        std::memcpy((void*)maxes(), (void*)_maxes, m*sizeof(npy_float64));
+        std::memcpy((void*)mins(), (void*)_mins, m*sizeof(double));
+        std::memcpy((void*)maxes(), (void*)_maxes, m*sizeof(double));
     };
 
     Rectangle(const Rectangle& rect) : m(rect.m), buf(rect.buf) {};
 
     private:
-        mutable std::vector<npy_float64> buf;
+        mutable std::vector<double> buf;
 };
 
-#include ""ckdtree_methods.h""
 #include ""distance.h""
 
 /*
@@ -86,16 +76,16 @@ struct Rectangle {
  */
 
 struct RR_stack_item {
-    npy_intp    which;
-    npy_intp    split_dim;
-    npy_float64 min_along_dim;
-    npy_float64 max_along_dim;
-    npy_float64 min_distance;
-    npy_float64 max_distance;
+    ckdtree_intp_t    which;
+    ckdtree_intp_t    split_dim;
+    double min_along_dim;
+    double max_along_dim;
+    double min_distance;
+    double max_distance;
 };
 
-const npy_intp LESS = 1;
-const npy_intp GREATER = 2;
+const ckdtree_intp_t LESS = 1;
+const ckdtree_intp_t GREATER = 2;
 
 template<typename MinMaxDist>
     struct RectRectDistanceTracker {
@@ -103,22 +93,22 @@ template<typename MinMaxDist>
     const ckdtree * tree;
     Rectangle rect1;
     Rectangle rect2;
-    npy_float64 p;
-    npy_float64 epsfac;
-    npy_float64 upper_bound;
-    npy_float64 min_distance;
-    npy_float64 max_distance;
-
-    npy_intp stack_size;
-    npy_intp stack_max_size;
+    double p;
+    double epsfac;
+    double upper_bound;
+    double min_distance;
+    double max_distance;
+
+    ckdtree_intp_t stack_size;
+    ckdtree_intp_t stack_max_size;
     std::vector<RR_stack_item> stack_arr;
     RR_stack_item *stack;
 
     /* if min/max distance / adjustment is less than this,
      * we believe the incremental tracking is inaccurate */
-    npy_float64 inaccurate_distance_limit;
+    double inaccurate_distance_limit;
 
-    void _resize_stack(const npy_intp new_max_size) {
+    void _resize_stack(const ckdtree_intp_t new_max_size) {
         stack_arr.resize(new_max_size);
         stack = &stack_arr[0];
         stack_max_size = new_max_size;
@@ -126,8 +116,8 @@ template<typename MinMaxDist>
 
     RectRectDistanceTracker(const ckdtree *_tree,
                  const Rectangle& _rect1, const Rectangle& _rect2,
-                 const npy_float64 _p, const npy_float64 eps,
-                 const npy_float64 _upper_bound)
+                 const double _p, const double eps,
+                 const double _upper_bound)
         : tree(_tree), rect1(_rect1), rect2(_rect2), stack_arr(8) {
 
         if (rect1.m != rect2.m) {
@@ -138,16 +128,16 @@ template<typename MinMaxDist>
         p = _p;
 
         /* internally we represent all distances as distance ** p */
-        if (NPY_LIKELY(p == 2.0))
+        if (CKDTREE_LIKELY(p == 2.0))
             upper_bound = _upper_bound * _upper_bound;
-        else if ((!ckdtree_isinf(p)) && (!ckdtree_isinf(_upper_bound)))
+        else if ((!ckdtree_isinf(p)) && (!isinf(_upper_bound)))
             upper_bound = std::pow(_upper_bound,p);
         else
             upper_bound = _upper_bound;
 
         /* fiddle approximation factor */
-        if (NPY_LIKELY(p == 2.0)) {
-            npy_float64 tmp = 1. + eps;
+        if (CKDTREE_LIKELY(p == 2.0)) {
+            double tmp = 1. + eps;
             epsfac = 1. / (tmp*tmp);
         }
         else if (eps == 0.)
@@ -173,10 +163,10 @@ template<typename MinMaxDist>
     };
 
 
-    void push(const npy_intp which, const npy_intp direction,
-              const npy_intp split_dim, const npy_float64 split_val) {
+    void push(const ckdtree_intp_t which, const intptr_t direction,
+              const ckdtree_intp_t split_dim, const double split_val) {
 
-        const npy_float64 p = this->p;
+        const double p = this->p;
         /* subnomial is 1 if round-off is expected to taint the incremental distance tracking.
          * in that case we always recompute the distances.
          * Recomputing costs more calls to pow, thus if the round-off error does not seem
@@ -204,8 +194,8 @@ template<typename MinMaxDist>
         item->max_along_dim = rect->maxes()[split_dim];
 
         /* update min/max distances */
-        npy_float64 min1, max1;
-        npy_float64 min2, max2;
+        double min1, max1;
+        double min2, max2;
 
         MinMaxDist::interval_interval_p(tree, rect1, rect2, split_dim, p, &min1, &max1);
 
@@ -222,7 +212,7 @@ template<typename MinMaxDist>
         subnomial = subnomial || ((min2 != 0 && min2 < inaccurate_distance_limit) || max2 < inaccurate_distance_limit);
         subnomial = subnomial || (min_distance < inaccurate_distance_limit || max_distance < inaccurate_distance_limit);
 
-        if (NPY_UNLIKELY(subnomial)) {
+        if (CKDTREE_UNLIKELY(subnomial)) {
             MinMaxDist::rect_rect_p(tree, rect1, rect2, p, &min_distance, &max_distance);
         } else {
             min_distance += (min2 - min1);
@@ -230,12 +220,12 @@ template<typename MinMaxDist>
         }
     };
 
-    inline void push_less_of(const npy_intp which,
+    inline void push_less_of(const ckdtree_intp_t which,
                                  const ckdtreenode *node) {
         push(which, LESS, node->split_dim, node->split);
     };
 
-    inline void push_greater_of(const npy_intp which,
+    inline void push_greater_of(const ckdtree_intp_t which,
                                     const ckdtreenode *node) {
         push(which, GREATER, node->split_dim, node->split);
     };
@@ -245,7 +235,7 @@ template<typename MinMaxDist>
         --stack_size;
 
         /* assert stack_size >= 0 */
-        if (NPY_UNLIKELY(stack_size < 0)) {
+        if (CKDTREE_UNLIKELY(stack_size < 0)) {
             const char *msg = ""Bad stack size. This error should never occur."";
             throw std::logic_error(msg);
         }
diff --git a/scipy/spatial/ckdtree/src/sparse_distances.cxx b/scipy/spatial/ckdtree/src/sparse_distances.cxx
index 6441f4cbe446..6c455b628d61 100644
--- a/scipy/spatial/ckdtree/src/sparse_distances.cxx
+++ b/scipy/spatial/ckdtree/src/sparse_distances.cxx
@@ -1,7 +1,3 @@
-
-#include <Python.h>
-#include ""numpy/arrayobject.h""
-
 #include <cmath>
 #include <cstdlib>
 #include <cstring>
@@ -14,10 +10,7 @@
 #include <stdexcept>
 #include <ios>
 
-#define CKDTREE_METHODS_IMPL
 #include ""ckdtree_decl.h""
-#include ""ckdtree_methods.h""
-#include ""cpp_exc.h""
 #include ""rectangle.h""
 #include ""coo_entries.h""
 
@@ -34,44 +27,44 @@ traverse(const ckdtree *self, const ckdtree *other,
 
         if (node2->split_dim == -1) {  /* 1 & 2 are leaves */
             /* brute-force */
-            const npy_float64 p = tracker->p;
-            const npy_float64 tub = tracker->upper_bound;
-            const npy_float64 *sdata = self->raw_data;
-            const npy_intp *sindices = self->raw_indices;
-            const npy_float64 *odata = other->raw_data;
-            const npy_intp *oindices = other->raw_indices;
-            const npy_intp m = self->m;
-            const npy_intp start1 = node1->start_idx;
-            const npy_intp start2 = node2->start_idx;
-            const npy_intp end1 = node1->end_idx;
-            const npy_intp end2 = node2->end_idx;
-
-            prefetch_datapoint(sdata + sindices[start1] * m, m);
+            const double p = tracker->p;
+            const double tub = tracker->upper_bound;
+            const double *sdata = self->raw_data;
+            const ckdtree_intp_t *sindices = self->raw_indices;
+            const double *odata = other->raw_data;
+            const ckdtree_intp_t *oindices = other->raw_indices;
+            const ckdtree_intp_t m = self->m;
+            const ckdtree_intp_t start1 = node1->start_idx;
+            const ckdtree_intp_t start2 = node2->start_idx;
+            const ckdtree_intp_t end1 = node1->end_idx;
+            const ckdtree_intp_t end2 = node2->end_idx;
+
+            CKDTREE_PREFETCH(sdata + sindices[start1] * m, 0, m);
             if (start1 < end1 - 1)
-               prefetch_datapoint(sdata + sindices[start1+1] * m, m);
+               CKDTREE_PREFETCH(sdata + sindices[start1+1] * m, 0, m);
 
-            for (npy_intp i = start1; i < end1; ++i) {
+            for (ckdtree_intp_t i = start1; i < end1; ++i) {
 
                 if (i < end1 - 2)
-                     prefetch_datapoint(sdata + sindices[i+2] * m, m);
+                     CKDTREE_PREFETCH(sdata + sindices[i+2] * m, 0, m);
 
-                prefetch_datapoint(odata + oindices[start2] * m, m);
+                CKDTREE_PREFETCH(odata + oindices[start2] * m, 0, m);
                 if (start2 < end2 - 1)
-                    prefetch_datapoint(sdata + oindices[start2+1] * m, m);
+                    CKDTREE_PREFETCH(sdata + oindices[start2+1] * m, 0, m);
 
-                for (npy_intp j = start2; j < end2; ++j) {
+                for (ckdtree_intp_t j = start2; j < end2; ++j) {
 
                     if (j < end2 - 2)
-                        prefetch_datapoint(odata + oindices[j+2] * m, m);
+                        CKDTREE_PREFETCH(odata + oindices[j+2] * m, 0, m);
 
-                    npy_float64 d = MinMaxDist::point_point_p(
+                    double d = MinMaxDist::point_point_p(
                             self,
                             sdata + sindices[i] * m,
                             odata + oindices[j] * m,
                             p, m, tub);
 
                     if (d <= tub) {
-                        if (NPY_LIKELY(p == 2.0))
+                        if (CKDTREE_LIKELY(p == 2.0))
                             d = std::sqrt(d);
                         else if ((p != 1) && (!ckdtree_isinf(p)))
                             d = std::pow(d, 1. / p);
@@ -129,10 +122,10 @@ traverse(const ckdtree *self, const ckdtree *other,
 }
 
 
-extern ""C"" PyObject*
+int
 sparse_distance_matrix(const ckdtree *self, const ckdtree *other,
-                       const npy_float64 p,
-                       const npy_float64 max_distance,
+                       const double p,
+                       const double max_distance,
                        std::vector<coo_entry> *results)
 {
 #define HANDLE(cond, kls) \
@@ -141,39 +134,21 @@ sparse_distance_matrix(const ckdtree *self, const ckdtree *other,
         traverse(self, other, results, self->ctree, other->ctree, &tracker); \
     } else
 
-    /* release the GIL */
-    NPY_BEGIN_ALLOW_THREADS
-    {
-        try {
-
-            Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
-            Rectangle r2(other->m, other->raw_mins, other->raw_maxes);
-            if(NPY_LIKELY(self->raw_boxsize_data == NULL)) {
-                HANDLE(NPY_LIKELY(p == 2), MinkowskiDistP2)
-                HANDLE(p == 1, MinkowskiDistP1)
-                HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
-                HANDLE(1, MinkowskiDistPp)
-                {}
-            } else {
-                HANDLE(NPY_LIKELY(p == 2), BoxMinkowskiDistP2)
-                HANDLE(p == 1, BoxMinkowskiDistP1)
-                HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
-                HANDLE(1, BoxMinkowskiDistPp)
-                {}
-            }
-        }
-        catch(...) {
-            translate_cpp_exception_with_gil();
-        }
-    }
-    /* reacquire the GIL */
-    NPY_END_ALLOW_THREADS
-
-    if (PyErr_Occurred())
-        /* true if a C++ exception was translated */
-        return NULL;
-    else {
-        /* return None if there were no errors */
-        Py_RETURN_NONE;
+    Rectangle r1(self->m, self->raw_mins, self->raw_maxes);
+    Rectangle r2(other->m, other->raw_mins, other->raw_maxes);
+    if(CKDTREE_LIKELY(self->raw_boxsize_data == NULL)) {
+        HANDLE(CKDTREE_LIKELY(p == 2), MinkowskiDistP2)
+        HANDLE(p == 1, MinkowskiDistP1)
+        HANDLE(ckdtree_isinf(p), MinkowskiDistPinf)
+        HANDLE(1, MinkowskiDistPp)
+        {}
+    } else {
+        HANDLE(CKDTREE_LIKELY(p == 2), BoxMinkowskiDistP2)
+        HANDLE(p == 1, BoxMinkowskiDistP1)
+        HANDLE(ckdtree_isinf(p), BoxMinkowskiDistPinf)
+        HANDLE(1, BoxMinkowskiDistPp)
+        {}
     }
+
+    return 0;
 }
diff --git a/scipy/spatial/setup.py b/scipy/spatial/setup.py
index 9736a541428a..5a6222831115 100644
--- a/scipy/spatial/setup.py
+++ b/scipy/spatial/setup.py
@@ -36,8 +36,6 @@ def configuration(parent_package='', top_path=None):
     # cKDTree
     ckdtree_src = ['query.cxx',
                    'build.cxx',
-                   'globals.cxx',
-                   'cpp_exc.cxx',
                    'query_pairs.cxx',
                    'count_neighbors.cxx',
                    'query_ball_point.cxx',
@@ -47,10 +45,7 @@ def configuration(parent_package='', top_path=None):
     ckdtree_src = [join('ckdtree', 'src', x) for x in ckdtree_src]
 
     ckdtree_headers = ['ckdtree_decl.h',
-                       'ckdtree_methods.h',
                        'coo_entries.h',
-                       'cpp_exc.h',
-                       'cpp_utils.h',
                        'distance_base.h',
                        'distance.h',
                        'ordered_pair.h',
"
"Initialize origin with {NULL, 0} when it is freed in exit; add test to make sure non-boolean brute force works",ed6c5062d070d417820cdf71b42d8e8494e6b71d,"diff --git a/scipy/ndimage/morphology.py b/scipy/ndimage/morphology.py
index 3ffe78898eb4..3a44b3c830ae 100644
--- a/scipy/ndimage/morphology.py
+++ b/scipy/ndimage/morphology.py
@@ -246,7 +246,6 @@ def _binary_erosion(input, structure, iterations, mask, output,
         output = bool
     output = _ni_support._get_output(output, input)
 
-    iterations = operator.index(iterations)
     if iterations == 1:
         _nd_image.binary_erosion(input, structure, mask, output,
                                  border_value, origin, invert, cit, 0)
diff --git a/scipy/ndimage/src/nd_image.c b/scipy/ndimage/src/nd_image.c
index 2dff102a7c87..13455cfa27cd 100644
--- a/scipy/ndimage/src/nd_image.c
+++ b/scipy/ndimage/src/nd_image.c
@@ -212,7 +212,7 @@ static PyObject *Py_Correlate1D(PyObject *obj, PyObject *args)
 static PyObject *Py_Correlate(PyObject *obj, PyObject *args)
 {
     PyArrayObject *input = NULL, *output = NULL, *weights = NULL;
-    PyArray_Dims origin;
+    PyArray_Dims origin = {NULL, 0};
     int mode;
     double cval;
 
@@ -297,7 +297,7 @@ static PyObject *Py_MinOrMaxFilter(PyObject *obj, PyObject *args)
 {
     PyArrayObject *input = NULL, *output = NULL, *footprint = NULL;
     PyArrayObject *structure = NULL;
-    PyArray_Dims origin;
+    PyArray_Dims origin = {NULL, 0};
     int mode, minimum;
     double cval;
 
@@ -333,7 +333,7 @@ static PyObject *Py_MinOrMaxFilter(PyObject *obj, PyObject *args)
 static PyObject *Py_RankFilter(PyObject *obj, PyObject *args)
 {
     PyArrayObject *input = NULL, *output = NULL, *footprint = NULL;
-    PyArray_Dims origin;
+    PyArray_Dims origin = {NULL, 0};
     int mode, rank;
     double cval;
 
@@ -528,7 +528,7 @@ static PyObject *Py_GenericFilter(PyObject *obj, PyObject *args)
     void *func = NULL, *data = NULL;
     NI_PythonCallbackData cbdata;
     int mode;
-    PyArray_Dims origin;
+    PyArray_Dims origin = {NULL, 0};
     double cval;
     ccallback_t callback;
     static ccallback_signature_t callback_signatures[] = {
@@ -1063,7 +1063,7 @@ static PyObject *Py_BinaryErosion(PyObject *obj, PyObject *args)
     int border_value, invert, center_is_true;
     int changed = 0, return_coordinates;
     NI_CoordinateList *coordinate_list = NULL;
-    PyArray_Dims origin;
+    PyArray_Dims origin = {NULL, 0};
 
     if (!PyArg_ParseTuple(args, ""O&O&O&O&iO&iii"",
                           NI_ObjectToInputArray, &input,
@@ -1113,7 +1113,7 @@ static PyObject *Py_BinaryErosion2(PyObject *obj, PyObject *args)
     PyArrayObject *array = NULL, *strct = NULL, *mask = NULL;
     PyObject *cobj = NULL;
     int invert, niter;
-    PyArray_Dims origin;
+    PyArray_Dims origin = {NULL, 0};
 
     if (!PyArg_ParseTuple(args, ""O&O&O&iO&iO"",
                           NI_ObjectToInputOutputArray, &array,
diff --git a/scipy/ndimage/tests/test_morphology.py b/scipy/ndimage/tests/test_morphology.py
index 58e75f0407c3..8a0fe5008d12 100644
--- a/scipy/ndimage/tests/test_morphology.py
+++ b/scipy/ndimage/tests/test_morphology.py
@@ -9,6 +9,7 @@ def test_binary_erosion_noninteger_iterations():
     # non integer iterations
     data = numpy.ones([1])
     assert_raises(TypeError, sndi.binary_erosion, data, iterations=0.5)
+    assert_raises(TypeError, sndi.binary_erosion, data, iterations=1.5)
 
 
 def test_binary_dilation_noninteger_iterations():
@@ -16,6 +17,7 @@ def test_binary_dilation_noninteger_iterations():
     # non integer iterations
     data = numpy.ones([1])
     assert_raises(TypeError, sndi.binary_dilation, data, iterations=0.5)
+    assert_raises(TypeError, sndi.binary_dilation, data, iterations=1.5)
 
 
 def test_binary_opening_noninteger_iterations():
@@ -23,6 +25,7 @@ def test_binary_opening_noninteger_iterations():
     # non integer iterations
     data = numpy.ones([1])
     assert_raises(TypeError, sndi.binary_opening, data, iterations=0.5)
+    assert_raises(TypeError, sndi.binary_opening, data, iterations=1.5)
 
 
 def test_binary_closing_noninteger_iterations():
@@ -30,3 +33,17 @@ def test_binary_closing_noninteger_iterations():
     # non integer iterations
     data = numpy.ones([1])
     assert_raises(TypeError, sndi.binary_closing, data, iterations=0.5)
+    assert_raises(TypeError, sndi.binary_closing, data, iterations=1.5)
+
+
+def test_binary_closing_noninteger_brute_force_passes_when_true():
+    # regression test for gh-9905, gh-9909: ValueError for
+    # non integer iterations
+    data = numpy.ones([1])
+
+    assert sndi.binary_erosion(
+        data, iterations=2, brute_force=1.5
+    ) == sndi.binary_erosion(data, iterations=2, brute_force=bool(1.5))
+    assert sndi.binary_erosion(
+        data, iterations=2, brute_force=0.0
+    ) == sndi.binary_erosion(data, iterations=2, brute_force=bool(0.0))
"
Updated the error handling based on the PR feedback,9d2c0d4caecb26d26040c25b42450bc19ea49fc3,"diff --git a/scipy/ndimage/morphology.py b/scipy/ndimage/morphology.py
index 7181c4607274..3ffe78898eb4 100644
--- a/scipy/ndimage/morphology.py
+++ b/scipy/ndimage/morphology.py
@@ -215,7 +215,11 @@ def generate_binary_structure(rank, connectivity):
 
 def _binary_erosion(input, structure, iterations, mask, output,
                     border_value, origin, invert, brute_force):
-    iterations = operator.index(iterations)
+    try:
+        iterations = operator.index(iterations)
+    except TypeError:
+        raise TypeError('iterations parameter should be an integer')
+
     input = numpy.asarray(input)
     if numpy.iscomplexobj(input):
         raise TypeError('Complex type not supported')
"
"Make sure that _binary_erosion only accepts an integer number of iterations.

* Addresses the resulting memory error by raising on non-integer inputs by using operator.index",03f7d6819989e8a184b45de07193f404a193b250,"diff --git a/scipy/ndimage/morphology.py b/scipy/ndimage/morphology.py
index 513f2eed3bb4..7181c4607274 100644
--- a/scipy/ndimage/morphology.py
+++ b/scipy/ndimage/morphology.py
@@ -215,6 +215,7 @@ def generate_binary_structure(rank, connectivity):
 
 def _binary_erosion(input, structure, iterations, mask, output,
                     border_value, origin, invert, brute_force):
+    iterations = operator.index(iterations)
     input = numpy.asarray(input)
     if numpy.iscomplexobj(input):
         raise TypeError('Complex type not supported')
@@ -396,7 +397,8 @@ def binary_dilation(input, structure=None, iterations=1, mask=None,
     iterations : int, optional
         The dilation is repeated `iterations` times (one, by default).
         If iterations is less than 1, the dilation is repeated until the
-        result does not change anymore.
+        result does not change anymore. Only an integer of iterations is
+        accepted.
     mask : array_like, optional
         If a mask is given, only those elements with a True value at
         the corresponding mask element are modified at each iteration.
@@ -528,11 +530,11 @@ def binary_opening(input, structure=None, iterations=1, output=None,
         is generated with a square connectivity equal to one (i.e., only
         nearest neighbors are connected to the center, diagonally-connected
         elements are not considered neighbors).
-    iterations : {int, float}, optional
+    iterations : int, optional
         The erosion step of the opening, then the dilation step are each
         repeated `iterations` times (one, by default). If `iterations` is
         less than 1, each operation is repeated until the result does
-        not change anymore.
+        not change anymore. Only an integer of iterations is accepted.
     output : ndarray, optional
         Array of the same shape as input, into which the output is placed.
         By default, a new array is created.
@@ -655,7 +657,7 @@ def binary_closing(input, structure=None, iterations=1, output=None,
         The dilation step of the closing, then the erosion step are each
         repeated `iterations` times (one, by default). If iterations is
         less than 1, each operations is repeated until the result does
-        not change anymore.
+        not change anymore. Only an integer of iterations is accepted.
     output : ndarray, optional
         Array of the same shape as input, into which the output is placed.
         By default, a new array is created.
diff --git a/scipy/ndimage/tests/test_morphology.py b/scipy/ndimage/tests/test_morphology.py
new file mode 100644
index 000000000000..58e75f0407c3
--- /dev/null
+++ b/scipy/ndimage/tests/test_morphology.py
@@ -0,0 +1,32 @@
+import numpy
+from pytest import raises as assert_raises
+
+import scipy.ndimage as sndi
+
+
+def test_binary_erosion_noninteger_iterations():
+    # regression test for gh-9905, gh-9909: ValueError for
+    # non integer iterations
+    data = numpy.ones([1])
+    assert_raises(TypeError, sndi.binary_erosion, data, iterations=0.5)
+
+
+def test_binary_dilation_noninteger_iterations():
+    # regression test for gh-9905, gh-9909: ValueError for
+    # non integer iterations
+    data = numpy.ones([1])
+    assert_raises(TypeError, sndi.binary_dilation, data, iterations=0.5)
+
+
+def test_binary_opening_noninteger_iterations():
+    # regression test for gh-9905, gh-9909: ValueError for
+    # non integer iterations
+    data = numpy.ones([1])
+    assert_raises(TypeError, sndi.binary_opening, data, iterations=0.5)
+
+
+def test_binary_closing_noninteger_iterations():
+    # regression test for gh-9905, gh-9909: ValueError for
+    # non integer iterations
+    data = numpy.ones([1])
+    assert_raises(TypeError, sndi.binary_closing, data, iterations=0.5)
"
"BUG: stats: Fix boxcox_llf to avoid loss of precision.

This change reformulates the expression for the log-likelihood
function computed by boxcox_llf in a way that is mathematically
equivalent to the old version but avoids the loss of precision
that can occur in the subtraction y** - 1.

For conciseness, let T(y; ) be the Box-Cox transformation

    T(y; ) = { (y** - 1)/  if   0
              { ln(y)         if  = 0

As explained in a comment in gh-6873, a problem arises if y
is sufficiently large and  is sufficiently negative (e.g.
5000**-5 is 3.2e-19).  When y** approaches the floating point
epsilon, the subtraction y** - 1 suffers catastrophic loss of
precision.  When this occurs in the log-likelihood function,
it results in the optimizer returning garbage.

The log-likelihood function (for a vector Y) is

    L(Y; ) = -n*ln(var(T(Y; )))/2 + ( - 1)*sum(ln(Y))

where n is the length of Y.  The Box-Cox transformation T only
appears as the argument to var; we only use the transform to
compute the variance of the transformed data.  The variance is
invariant with respect to a constant shift, so, assuming   0,

    var(T(y; )) = var(Y**/ - 1/) = var(Y**/)

That is, we can compute var(T(y; )) without the subtraction
in the Box-Cox transformation.

Closes gh-6873.",2cb929d0eb70c1a70a29007d4f9cc968b45c4c50,"diff --git a/scipy/stats/morestats.py b/scipy/stats/morestats.py
index 23c0ab14b0ac..c59e2c74ae5e 100644
--- a/scipy/stats/morestats.py
+++ b/scipy/stats/morestats.py
@@ -896,11 +896,18 @@ def boxcox_llf(lmb, data):
     if N == 0:
         return np.nan
 
-    y = boxcox(data, lmb)
-    y_mean = np.mean(y, axis=0)
-    llf = (lmb - 1) * np.sum(np.log(data), axis=0)
-    llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))
-    return llf
+    logdata = np.log(data)
+
+    # Compute the variance of the transformed data.
+    if lmb == 0:
+        variance = np.var(logdata, axis=0)
+    else:
+        # Transform without the constant offset 1/lmb.  The offset does
+        # not effect the variance, and the subtraction of the offset can
+        # lead to loss of precision.
+        variance = np.var(data**lmb / lmb, axis=0)
+
+    return (lmb - 1) * np.sum(logdata, axis=0) - N/2 * np.log(variance)
 
 
 def _boxcox_conf_interval(x, lmax, alpha):
diff --git a/scipy/stats/tests/test_morestats.py b/scipy/stats/tests/test_morestats.py
index 84ae99c7a6cd..4d8f3ac9147c 100644
--- a/scipy/stats/tests/test_morestats.py
+++ b/scipy/stats/tests/test_morestats.py
@@ -1211,6 +1211,66 @@ def test_2d_input(self):
     def test_empty(self):
         assert_(np.isnan(stats.boxcox_llf(1, [])))
 
+    def test_gh_6873(self):
+        # Regression test for gh-6873.
+        # This example was taken from gh-7534, a duplicate of gh-6873.
+        data = [198.0, 233.0, 233.0, 392.0]
+        llf = stats.boxcox_llf(-8, data)
+        # The expected value was computed with mpmath.
+        assert_allclose(llf, -17.93934208579061)
+
+
+# This is the data from github user Qukaiyi, given as an example
+# of a data set that caused boxcox to fail.
+_boxcox_data = [
+    15957, 112079, 1039553, 711775, 173111, 307382, 183155, 53366, 760875,
+    207500, 160045, 473714, 40194, 440319, 133261, 265444, 155590, 36660,
+    904939, 55108, 138391, 339146, 458053, 63324, 1377727, 1342632, 41575,
+    68685, 172755, 63323, 368161, 199695, 538214, 167760, 388610, 398855,
+    1001873, 364591, 1320518, 194060, 194324, 2318551, 196114, 64225, 272000,
+    198668, 123585, 86420, 1925556, 695798, 88664, 46199, 759135, 28051,
+    345094, 1977752, 51778, 82746, 638126, 2560910, 45830, 140576, 1603787,
+    57371, 548730, 5343629, 2298913, 998813, 2156812, 423966, 68350, 145237,
+    131935, 1600305, 342359, 111398, 1409144, 281007, 60314, 242004, 113418,
+    246211, 61940, 95858, 957805, 40909, 307955, 174159, 124278, 241193,
+    872614, 304180, 146719, 64361, 87478, 509360, 167169, 933479, 620561,
+    483333, 97416, 143518, 286905, 597837, 2556043, 89065, 69944, 196858,
+    88883, 49379, 916265, 1527392, 626954, 54415, 89013, 2883386, 106096,
+    402697, 45578, 349852, 140379, 34648, 757343, 1305442, 2054757, 121232,
+    606048, 101492, 51426, 1820833, 83412, 136349, 1379924, 505977, 1303486,
+    95853, 146451, 285422, 2205423, 259020, 45864, 684547, 182014, 784334,
+    174793, 563068, 170745, 1195531, 63337, 71833, 199978, 2330904, 227335,
+    898280, 75294, 2011361, 116771, 157489, 807147, 1321443, 1148635, 2456524,
+    81839, 1228251, 97488, 1051892, 75397, 3009923, 2732230, 90923, 39735,
+    132433, 225033, 337555, 1204092, 686588, 1062402, 40362, 1361829, 1497217,
+    150074, 551459, 2019128, 39581, 45349, 1117187, 87845, 1877288, 164448,
+    10338362, 24942, 64737, 769946, 2469124, 2366997, 259124, 2667585, 29175,
+    56250, 74450, 96697, 5920978, 838375, 225914, 119494, 206004, 430907,
+    244083, 219495, 322239, 407426, 618748, 2087536, 2242124, 4736149, 124624,
+    406305, 240921, 2675273, 4425340, 821457, 578467, 28040, 348943, 48795,
+    145531, 52110, 1645730, 1768364, 348363, 85042, 2673847, 81935, 169075,
+    367733, 135474, 383327, 1207018, 93481, 5934183, 352190, 636533, 145870,
+    55659, 146215, 73191, 248681, 376907, 1606620, 169381, 81164, 246390,
+    236093, 885778, 335969, 49266, 381430, 307437, 350077, 34346, 49340,
+    84715, 527120, 40163, 46898, 4609439, 617038, 2239574, 159905, 118337,
+    120357, 430778, 3799158, 3516745, 54198, 2970796, 729239, 97848, 6317375,
+    887345, 58198, 88111, 867595, 210136, 1572103, 1420760, 574046, 845988,
+    509743, 397927, 1119016, 189955, 3883644, 291051, 126467, 1239907, 2556229,
+    411058, 657444, 2025234, 1211368, 93151, 577594, 4842264, 1531713, 305084,
+    479251, 20591, 1466166, 137417, 897756, 594767, 3606337, 32844, 82426,
+    1294831, 57174, 290167, 322066, 813146, 5671804, 4425684, 895607, 450598,
+    1048958, 232844, 56871, 46113, 70366, 701618, 97739, 157113, 865047,
+    194810, 1501615, 1765727, 38125, 2733376, 40642, 437590, 127337, 106310,
+    4167579, 665303, 809250, 1210317, 45750, 1853687, 348954, 156786, 90793,
+    1885504, 281501, 3902273, 359546, 797540, 623508, 3672775, 55330, 648221,
+    266831, 90030, 7118372, 735521, 1009925, 283901, 806005, 2434897, 94321,
+    309571, 4213597, 2213280, 120339, 64403, 8155209, 1686948, 4327743,
+    1868312, 135670, 3189615, 1569446, 706058, 58056, 2438625, 520619, 105201,
+    141961, 179990, 1351440, 3148662, 2804457, 2760144, 70775, 33807, 1926518,
+    2362142, 186761, 240941, 97860, 1040429, 1431035, 78892, 484039, 57845,
+    724126, 3166209, 175913, 159211, 1182095, 86734, 1921472, 513546, 326016,
+    1891609
+]
 
 class TestBoxcox(object):
 
@@ -1266,6 +1326,14 @@ def test_boxcox_bad_arg(self):
     def test_empty(self):
         assert_(stats.boxcox([]).shape == (0,))
 
+    def test_gh_6873(self):
+        # Regression test for gh-6873.
+        y, lam = stats.boxcox(_boxcox_data)
+        # The expected value of lam was computed with the function
+        # powerTransform in the R library 'car'.  I trust that value
+        # to only about five significant digits.
+        assert_allclose(lam, -0.051654, rtol=1e-5)
+
 
 class TestBoxcoxNormmax(object):
     def setup_method(self):
"
fix flake8.,d8991b783af5481bcf7bb8cedfb4ad2d8d1d624a,"diff --git a/scipy/spatial/tests/test_kdtree.py b/scipy/spatial/tests/test_kdtree.py
index 6f7389313ea7..c57517a8db9c 100644
--- a/scipy/spatial/tests/test_kdtree.py
+++ b/scipy/spatial/tests/test_kdtree.py
@@ -1369,7 +1369,7 @@ def test_query_ball_point_vector_r():
     d = np.random.uniform(0, 0.3, size=len(query))
 
     rvector = tree.query_ball_point(query, d)
-    rscalar = [ tree.query_ball_point(qi, di) for qi, di in zip(query, d) ]
+    rscalar = [tree.query_ball_point(qi, di) for qi, di in zip(query, d)]
     for a, b in zip(rvector, rscalar):
         assert_array_equal(sorted(a), sorted(b))
 
"
"Add return_length.

return_length avoids making a large memory allocation
for the full indices lists.

This can be useful in cases such as determining a locally
adaptive bandwidth of a kernel density estimation; or as a
simple approximation to determine the kernel scaling in
smoothed particle dynamics.",f8d893b1ac16c2fdf04b9c67f7eca898164fcb0a,"diff --git a/scipy/spatial/ckdtree.pyx b/scipy/spatial/ckdtree.pyx
index cf7a3f9be4c2..863137b9bc73 100644
--- a/scipy/spatial/ckdtree.pyx
+++ b/scipy/spatial/ckdtree.pyx
@@ -397,7 +397,8 @@ cdef extern from ""ckdtree_methods.h"":
                             const np.float64_t p,
                             const np.float64_t eps,
                             const np.intp_t n_queries,
-                            vector[np.intp_t] **results)
+                            vector[np.intp_t] **results,
+                            const int return_length)
 
     object query_ball_tree(const ckdtree *self,
                            const ckdtree *other,
@@ -858,7 +859,8 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
     def query_ball_point(cKDTree self, object x, object r,
                          np.float64_t p=2., np.float64_t eps=0, n_jobs=1,
-                         return_sorted=None):
+                         return_sorted=None,
+                         return_length=False):
         """"""
         query_ball_point(self, x, r, p=2., eps=0)
         
@@ -888,6 +890,10 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             was added.
 
             .. versionadded:: 1.2.0
+        return_length: bool, optional
+            Return the number of points inside the radius instead of a list
+            of the indices.
+            .. versionadded:: 1.3.0
 
         Returns
         -------
@@ -921,6 +927,7 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
             np.float64_t[::1] vrr
             np.float64_t[:, ::1] vxx
             object[::1] vout
+            np.intp_t[::1] vlen
             np.uintp_t vvres_uintp
             np.intp_t *cur
             list tmp
@@ -942,12 +949,17 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                 rr = r
                 vres = new vector[np.intp_t]()
                 xx = np.ascontiguousarray(x, dtype=np.float64)
-                query_ball_point(<ckdtree*> self, &xx[0], &rr, p, eps, 1, &vres)
+                query_ball_point(<ckdtree*> self, &xx[0], &rr, p, eps, 1, &vres, return_length)
+
+                cur = npy_intp_vector_buf(vres)
+
+                if return_length:
+                    return cur[0]
 
                 n = <np.intp_t> vres.size()
+
                 tmp = n * [None]
                 if NPY_LIKELY(n > 0):
-                    cur = npy_intp_vector_buf(vres)
                     for i in range(n):
                         tmp[i] = cur[0]
                         cur += 1
@@ -966,9 +978,13 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
         # allocate an array of std::vector<npy_intp>
         n = np.prod(retshape)
-        result = np.empty(retshape, dtype=object)
 
-        vout = result.reshape(-1)
+        if return_length:
+            result = np.empty(retshape, dtype=np.intp)
+            vlen = result.reshape(-1)
+        else:
+            result = np.empty(retshape, dtype=object)
+            vout = result.reshape(-1)
 
         vxx = np.reshape(x, (-1, x.shape[-1]))
         vrr = np.reshape(r, (-1))
@@ -992,11 +1008,15 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                     vvres[i] = new vector[np.intp_t]()
 
                 query_ball_point(<ckdtree*>self, &vxx[start, 0],
-                    &vrr[start + 0], p, eps, stop - start, vvres)
+                    &vrr[start + 0], p, eps, stop - start, vvres, return_length)
 
                 for i in range(stop - start):
-                    m = <np.intp_t> (vvres[i].size())
                     cur = npy_intp_vector_buf(vvres[i])
+                    if return_length:
+                        vlen[start + i] = cur[0]
+                        continue
+
+                    m = <np.intp_t> (vvres[i].size())
                     tmp = m * [None]
                     for j in range(m):
                         tmp[j] = cur[0]
diff --git a/scipy/spatial/ckdtree/src/ckdtree_methods.h b/scipy/spatial/ckdtree/src/ckdtree_methods.h
index 2a2a179e6cbd..0f3755efed51 100644
--- a/scipy/spatial/ckdtree/src/ckdtree_methods.h
+++ b/scipy/spatial/ckdtree/src/ckdtree_methods.h
@@ -193,7 +193,8 @@ query_ball_point(const ckdtree *self,
                  const npy_float64 p,
                  const npy_float64 eps,
                  const npy_intp n_queries,
-                 std::vector<npy_intp> **results);
+                 std::vector<npy_intp> **results,
+                 const int return_length);
 
 CKDTREE_EXTERN PyObject*
 query_ball_tree(const ckdtree *self,
@@ -201,7 +202,8 @@ query_ball_tree(const ckdtree *self,
                 const npy_float64 r,
                 const npy_float64 p,
                 const npy_float64 eps,
-                std::vector<npy_intp> **results);
+                std::vector<npy_intp> **results
+                );
 
 CKDTREE_EXTERN PyObject*
 sparse_distance_matrix(const ckdtree *self,
diff --git a/scipy/spatial/ckdtree/src/query_ball_point.cxx b/scipy/spatial/ckdtree/src/query_ball_point.cxx
index 9893e7446e7d..528a0c6c4e4b 100644
--- a/scipy/spatial/ckdtree/src/query_ball_point.cxx
+++ b/scipy/spatial/ckdtree/src/query_ball_point.cxx
@@ -22,6 +22,7 @@
 
 static void
 traverse_no_checking(const ckdtree *self,
+                     const int return_length,
                      std::vector<npy_intp> *results,
                      const ckdtreenode *node)
 {
@@ -34,21 +35,27 @@ traverse_no_checking(const ckdtree *self,
         const npy_intp start = lnode->start_idx;
         const npy_intp end = lnode->end_idx;
         for (i = start; i < end; ++i) {
-            results->push_back(indices[i]);
+            if (return_length) {
+                (*results)[0] ++;
+            } else {
+                results->push_back(indices[i]);
+            }
         }
     }
     else {
-        traverse_no_checking(self, results, node->less);
-        traverse_no_checking(self, results, node->greater);
+        traverse_no_checking(self, return_length, results, node->less);
+        traverse_no_checking(self, return_length, results, node->greater);
     }
 }
 
 
 template <typename MinMaxDist> static void
 traverse_checking(const ckdtree *self,
+                  const int return_length,
                   std::vector<npy_intp> *results,
                   const ckdtreenode *node,
-                  RectRectDistanceTracker<MinMaxDist> *tracker)
+                  RectRectDistanceTracker<MinMaxDist> *tracker
+)
 {
     const ckdtreenode *lnode;
     npy_float64 d;
@@ -58,7 +65,7 @@ traverse_checking(const ckdtree *self,
         return;
     }
     else if (tracker->max_distance < tracker->upper_bound / tracker->epsfac) {
-        traverse_no_checking(self, results, node);
+        traverse_no_checking(self, return_length, results, node);
     }
     else if (node->split_dim == -1)  { /* leaf node */
 
@@ -85,17 +92,21 @@ traverse_checking(const ckdtree *self,
             d = MinMaxDist::point_point_p(self, data + indices[i] * m, tpt, p, m, tub);
 
             if (d <= tub) {
-                results->push_back((npy_intp) indices[i]);
+                if(return_length) {
+                    (*results)[0] ++;
+                } else {
+                    results->push_back((npy_intp) indices[i]);
+                }
             }
         }
     }
     else {
         tracker->push_less_of(2, node);
-        traverse_checking(self, results, node->less, tracker);
+        traverse_checking(self, return_length, results, node->less, tracker);
         tracker->pop();
 
         tracker->push_greater_of(2, node);
-        traverse_checking(self, results, node->greater, tracker);
+        traverse_checking(self, return_length, results, node->greater, tracker);
         tracker->pop();
     }
 }
@@ -104,12 +115,14 @@ traverse_checking(const ckdtree *self,
 extern ""C"" PyObject*
 query_ball_point(const ckdtree *self, const npy_float64 *x,
                  const npy_float64 *r, const npy_float64 p, const npy_float64 eps,
-                 const npy_intp n_queries, std::vector<npy_intp> **results)
+                 const npy_intp n_queries,
+                 std::vector<npy_intp> **results, const int return_length)
 {
 #define HANDLE(cond, kls) \
     if(cond) { \
+        if(return_length) results[i]->push_back(0); \
         RectRectDistanceTracker<kls> tracker(self, point, rect, p, eps, r[i]); \
-        traverse_checking(self, results[i], self->ctree, &tracker); \
+        traverse_checking(self, return_length, results[i], self->ctree, &tracker); \
     } else
 
     /* release the GIL */
diff --git a/scipy/spatial/tests/test_kdtree.py b/scipy/spatial/tests/test_kdtree.py
index 6b4b0c2f0b3a..6f7389313ea7 100644
--- a/scipy/spatial/tests/test_kdtree.py
+++ b/scipy/spatial/tests/test_kdtree.py
@@ -1373,6 +1373,22 @@ def test_query_ball_point_vector_r():
     for a, b in zip(rvector, rscalar):
         assert_array_equal(sorted(a), sorted(b))
 
+def test_query_ball_point_length():
+
+    np.random.seed(1234)
+    data = np.random.normal(size=(100, 3))
+    query = np.random.normal(size=(100, 3))
+    tree = cKDTree(data)
+    d = 0.3
+
+    length = tree.query_ball_point(query, d, return_length=True)
+    length2 = [len(ind) for ind in tree.query_ball_point(query, d, return_length=False)]
+    length3 = [len(tree.query_ball_point(qi, d)) for qi in query]
+    length4 = [tree.query_ball_point(qi, d, return_length=True) for qi in query]
+    assert_array_equal(length, length2)
+    assert_array_equal(length, length3)
+    assert_array_equal(length, length4)
+
 class Test_sorted_query_ball_point(object):
 
     def setup_method(self):
"
"Clean up the multi-threading code in query_ball_point.


The new version of code is a lot less verbose.
C memory allocation is moved inside threads, the idea is
to keep them as localized as possible.",bfcb302ceeb863dec549a8ffceb3683488ea4b00,"diff --git a/scipy/spatial/ckdtree.pyx b/scipy/spatial/ckdtree.pyx
index fac52c3157cd..cf7a3f9be4c2 100644
--- a/scipy/spatial/ckdtree.pyx
+++ b/scipy/spatial/ckdtree.pyx
@@ -920,14 +920,13 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
 
             np.float64_t[::1] vrr
             np.float64_t[:, ::1] vxx
-            vector[np.intp_t] **vvres
+            object[::1] vout
             np.uintp_t vvres_uintp
             np.intp_t *cur
             list tmp
             np.intp_t i, j, n, m
 
         vres = NULL
-        vvres = NULL
 
         x = np.asarray(x, dtype=np.float64)
         if x.shape[-1] != self.m:
@@ -962,89 +961,73 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                 if vres != NULL:
                     del vres
 
-        try:
-            # query many points
-            retshape = x.shape[:-1]
+        # query many points
+        retshape = x.shape[:-1]
 
-            # allocate an array of std::vector<npy_intp>
-            n = np.prod(retshape)
-            vvres = (<vector[np.intp_t] **>
-                PyMem_Malloc(n * sizeof(intvector_ptr_t)))
-            if vvres == NULL:
-                raise MemoryError()
+        # allocate an array of std::vector<npy_intp>
+        n = np.prod(retshape)
+        result = np.empty(retshape, dtype=object)
 
-            memset(<void*> vvres, 0, n * sizeof(intvector_ptr_t))
+        vout = result.reshape(-1)
 
-            for i in range(n):
-                vvres[i] = new vector[np.intp_t]()
+        vxx = np.reshape(x, (-1, x.shape[-1]))
+        vrr = np.reshape(r, (-1))
 
-            result = np.empty(retshape, dtype=object)
-
-            vxx = np.reshape(x, (-1, x.shape[-1]))
-            vrr = np.reshape(r, (-1))
-
-            # multithreading logic is similar to cKDTree.query
-            if (n_jobs == -1): 
-                n_jobs = number_of_processors
-
-            if n_jobs > 1:
-                CHUNK = n//n_jobs if n//n_jobs else n
-
-                def _thread_func(self, np.intp_t j,
-                        np.float64_t[:, ::1] vxx,
-                        np.float64_t[::1] vrr,
-                        p, eps, _vvres, CHUNK):
-                    cdef:
-                        vector[np.intp_t] **vvres
-                        np.intp_t start = j * CHUNK
-                        np.intp_t stop = start + CHUNK
-                    stop = n if stop > n else stop
-                    vvres = (<vector[np.intp_t] **>
-                              (<void*> (<np.uintp_t> _vvres)))
-                    if start < n:
-                        query_ball_point(<ckdtree*>self, &vxx[start, 0],
-                            &vrr[start], p, eps, stop - start, vvres + start)
-
-                vvres_uintp = <np.uintp_t> (<void*> vvres)
-                threads = [threading.Thread(target=_thread_func,
-                           args=(self, j, vxx, vrr, p, eps, vvres_uintp, CHUNK))
-                           for j in range(1+(n//CHUNK))]
-                for t in threads:
-                    t.daemon = True
-                    t.start()
-                for t in threads:
-                    t.join()
+        # multithreading logic is similar to cKDTree.query
+        if (n_jobs == -1):
+            n_jobs = number_of_processors
 
-            else:
-                query_ball_point(<ckdtree*>self, &vxx[0,0], &vrr[0], p, eps,
-                    n, vvres)
+        def _thread_func(np.intp_t start, np.intp_t stop):
+            cdef vector[np.intp_t] **vvres
 
-            i = 0
-            for c in np.ndindex(retshape):
-                m = <np.intp_t> (vvres[i].size())
-                if NPY_LIKELY(m > 0):
-                    tmp = m * [None]
+            try:
+                vvres = (<vector[np.intp_t] **>
+                    PyMem_Malloc((stop-start) * sizeof(intvector_ptr_t)))
+                if vvres == NULL:
+                    raise MemoryError()
+
+                memset(<void*> vvres, 0, (stop-start) * sizeof(intvector_ptr_t))
+
+                for i in range(stop - start):
+                    vvres[i] = new vector[np.intp_t]()
+
+                query_ball_point(<ckdtree*>self, &vxx[start, 0],
+                    &vrr[start + 0], p, eps, stop - start, vvres)
+
+                for i in range(stop - start):
+                    m = <np.intp_t> (vvres[i].size())
                     cur = npy_intp_vector_buf(vvres[i])
+                    tmp = m * [None]
                     for j in range(m):
                         tmp[j] = cur[0]
                         cur += 1
                     if return_sorted or return_sorted is None:
-                        result[c] = sorted(tmp)
-                    else:
-                        result[c] = tmp
-                else:
-                    result[c] = []
-                i += 1
+                        tmp = sorted(tmp)
+                    vout[start + i] = tmp
+            finally:
+                if vvres != NULL:
+                    for i in range(stop-start):
+                        if vvres[i] != NULL:
+                            del vvres[i]
+                    PyMem_Free(vvres)
 
-            return result
+        if n_jobs > 1:
+            ranges = [(j * n // n_jobs, (j + 1) * n // n_jobs)
+                            for j in range(n_jobs)]
 
-        finally:
-            if vvres != NULL:
-                for i in range(n):
-                    if vvres[i] != NULL:
-                        del vvres[i]
-                PyMem_Free(vvres)
+            threads = [threading.Thread(target=_thread_func,
+                       args=(start, end))
+                       for start, end in ranges]
+            for t in threads:
+                t.daemon = True
+                t.start()
+            for t in threads:
+                t.join()
+
+        else:
+            _thread_func(0, n)
 
+        return result
 
     # ---------------
     # query_ball_tree
"
"Fix a bug in return_sorted.

When a return_sorted is True and a single query is made, the
old routine produces an error.",a4131404d9a6f5f694e6ae72d60a8bf4072c6afc,"diff --git a/scipy/spatial/ckdtree.pyx b/scipy/spatial/ckdtree.pyx
index 3a5b01446007..fac52c3157cd 100644
--- a/scipy/spatial/ckdtree.pyx
+++ b/scipy/spatial/ckdtree.pyx
@@ -944,18 +944,17 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                 vres = new vector[np.intp_t]()
                 xx = np.ascontiguousarray(x, dtype=np.float64)
                 query_ball_point(<ckdtree*> self, &xx[0], &rr, p, eps, 1, &vres)
+
                 n = <np.intp_t> vres.size()
                 tmp = n * [None]
-                # FIXME: this does not seem to be doing any sorting, cur[0] is
-                # a scalar.
                 if NPY_LIKELY(n > 0):
                     cur = npy_intp_vector_buf(vres)
                     for i in range(n):
-                        if return_sorted:
-                            tmp[i] = sorted(cur[0])
-                        else:
-                            tmp[i] = cur[0]
+                        tmp[i] = cur[0]
                         cur += 1
+                if return_sorted:
+                    tmp = sorted(tmp)
+
                 result = tmp
 
                 return result
diff --git a/scipy/spatial/tests/test_kdtree.py b/scipy/spatial/tests/test_kdtree.py
index f0ae663711d8..6b4b0c2f0b3a 100644
--- a/scipy/spatial/tests/test_kdtree.py
+++ b/scipy/spatial/tests/test_kdtree.py
@@ -1385,6 +1385,10 @@ def test_return_sorted_True(self):
         for idxs in idxs_list:
             assert_array_equal(idxs, sorted(idxs))
 
+        for xi in self.x:
+            idxs = self.ckdt.query_ball_point(xi, 1., return_sorted=True)
+            assert_array_equal(idxs, sorted(idxs))
+
     def test_return_sorted_None(self):
         """"""Previous behavior was to sort the returned indices if there were
         multiple points per query but not sort them if there was a single point
"
"ENH: vector radius in cKDTree.query_ball_point

This PR supports vectorized radius queries of query_ball_point.",81b2ac99f863bec19ee7ee22ac630be2927f6432,"diff --git a/scipy/spatial/ckdtree.pyx b/scipy/spatial/ckdtree.pyx
index 3f5cfebd8b07..3a5b01446007 100644
--- a/scipy/spatial/ckdtree.pyx
+++ b/scipy/spatial/ckdtree.pyx
@@ -393,7 +393,7 @@ cdef extern from ""ckdtree_methods.h"":
 
     object query_ball_point(const ckdtree *self,
                             const np.float64_t *x,
-                            const np.float64_t r,
+                            const np.float64_t *r,
                             const np.float64_t p,
                             const np.float64_t eps,
                             const np.intp_t n_queries,
@@ -856,7 +856,7 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
     # query_ball_point
     # ----------------
 
-    def query_ball_point(cKDTree self, object x, np.float64_t r,
+    def query_ball_point(cKDTree self, object x, object r,
                          np.float64_t p=2., np.float64_t eps=0, n_jobs=1,
                          return_sorted=None):
         """"""
@@ -868,8 +868,8 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         ----------
         x : array_like, shape tuple + (self.m,)
             The point or points to search for neighbors of.
-        r : positive float
-            The radius of points to return.
+        r : array_like, float
+            The radius of points to return, shall broadcast to the length of x.
         p : float, optional
             Which Minkowski p-norm to use.  Should be in the range [1, inf].
             A finite large p may cause a ValueError if overflow can occur.
@@ -912,33 +912,42 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
         [4, 8, 9, 12]
 
         """"""
-        
+
         cdef:
-            np.ndarray[np.float64_t, ndim=1, mode=""c""] xx
-            np.ndarray[np.float64_t, ndim=2, mode=""c""] vxx
+            np.float64_t[::1] xx
+            np.float64_t rr
             vector[np.intp_t] *vres
+
+            np.float64_t[::1] vrr
+            np.float64_t[:, ::1] vxx
             vector[np.intp_t] **vvres
             np.uintp_t vvres_uintp
             np.intp_t *cur
             list tmp
             np.intp_t i, j, n, m
-        
+
         vres = NULL
         vvres = NULL
-        
-        try:
-               
-            x = np.asarray(x, dtype=np.float64)
-            if x.shape[-1] != self.m:
-                raise ValueError(""Searching for a %d-dimensional point in a ""
-                                 ""%d-dimensional KDTree"" % 
-                                     (int(x.shape[-1]), int(self.m)))
-            if len(x.shape) == 1:
+
+        x = np.asarray(x, dtype=np.float64)
+        if x.shape[-1] != self.m:
+            raise ValueError(""Searching for a %d-dimensional point in a ""
+                             ""%d-dimensional KDTree"" % 
+                                 (int(x.shape[-1]), int(self.m)))
+
+        r = np.array(np.broadcast_to(r, x.shape[:-1]), order='C', dtype=np.float64)
+
+        if len(x.shape) == 1:
+            try:
+                # special case: query a single point
+                rr = r
                 vres = new vector[np.intp_t]()
                 xx = np.ascontiguousarray(x, dtype=np.float64)
-                query_ball_point(<ckdtree*> self, &xx[0], r, p, eps, 1, &vres)
+                query_ball_point(<ckdtree*> self, &xx[0], &rr, p, eps, 1, &vres)
                 n = <np.intp_t> vres.size()
                 tmp = n * [None]
+                # FIXME: this does not seem to be doing any sorting, cur[0] is
+                # a scalar.
                 if NPY_LIKELY(n > 0):
                     cur = npy_intp_vector_buf(vres)
                     for i in range(n):
@@ -948,97 +957,95 @@ cdef public class cKDTree [object ckdtree, type ckdtree_type]:
                             tmp[i] = cur[0]
                         cur += 1
                 result = tmp
-            
+
+                return result
+            finally:
+                if vres != NULL:
+                    del vres
+
+        try:
+            # query many points
+            retshape = x.shape[:-1]
+
+            # allocate an array of std::vector<npy_intp>
+            n = np.prod(retshape)
+            vvres = (<vector[np.intp_t] **>
+                PyMem_Malloc(n * sizeof(intvector_ptr_t)))
+            if vvres == NULL:
+                raise MemoryError()
+
+            memset(<void*> vvres, 0, n * sizeof(intvector_ptr_t))
+
+            for i in range(n):
+                vvres[i] = new vector[np.intp_t]()
+
+            result = np.empty(retshape, dtype=object)
+
+            vxx = np.reshape(x, (-1, x.shape[-1]))
+            vrr = np.reshape(r, (-1))
+
+            # multithreading logic is similar to cKDTree.query
+            if (n_jobs == -1): 
+                n_jobs = number_of_processors
+
+            if n_jobs > 1:
+                CHUNK = n//n_jobs if n//n_jobs else n
+
+                def _thread_func(self, np.intp_t j,
+                        np.float64_t[:, ::1] vxx,
+                        np.float64_t[::1] vrr,
+                        p, eps, _vvres, CHUNK):
+                    cdef:
+                        vector[np.intp_t] **vvres
+                        np.intp_t start = j * CHUNK
+                        np.intp_t stop = start + CHUNK
+                    stop = n if stop > n else stop
+                    vvres = (<vector[np.intp_t] **>
+                              (<void*> (<np.uintp_t> _vvres)))
+                    if start < n:
+                        query_ball_point(<ckdtree*>self, &vxx[start, 0],
+                            &vrr[start], p, eps, stop - start, vvres + start)
+
+                vvres_uintp = <np.uintp_t> (<void*> vvres)
+                threads = [threading.Thread(target=_thread_func,
+                           args=(self, j, vxx, vrr, p, eps, vvres_uintp, CHUNK))
+                           for j in range(1+(n//CHUNK))]
+                for t in threads:
+                    t.daemon = True
+                    t.start()
+                for t in threads:
+                    t.join()
+
             else:
-                retshape = x.shape[:-1]
-                
-                # allocate an array of std::vector<npy_intp>
-                n = np.prod(retshape)
-                vvres = (<vector[np.intp_t] **> 
-                    PyMem_Malloc(n * sizeof(intvector_ptr_t)))
-                if vvres == NULL:
-                    raise MemoryError()
-                
-                memset(<void*> vvres, 0, n * sizeof(intvector_ptr_t))      
-            
-                for i in range(n):
-                    vvres[i] = new vector[np.intp_t]()
-                
-                result = np.empty(retshape, dtype=object)
-                
-                vxx = np.zeros((n,self.m), dtype=np.float64)
-                i = 0
-                for c in np.ndindex(retshape):
-                    vxx[i,:] = x[c]
-                    i += 1
-                    
-                # multithreading logic is similar to cKDTree.query
-                                        
-                if (n_jobs == -1): 
-                    n_jobs = number_of_processors
-        
-                if n_jobs > 1:
-                
-                    CHUNK = n//n_jobs if n//n_jobs else n
-                             
-                    def _thread_func(self, _j, _vxx, r, p, eps, _vvres, CHUNK): 
-                        cdef: 
-                            np.intp_t j = _j
-                            np.ndarray[np.float64_t,ndim=2] vxx = _vxx
-                            vector[np.intp_t] **vvres                   
-                            np.intp_t start = j*CHUNK
-                            np.intp_t stop = start + CHUNK
-                        stop = n if stop > n else stop
-                        vvres = (<vector[np.intp_t] **> 
-                                  (<void*> (<np.uintp_t> _vvres)))                                    
-                        if start < n:
-                            query_ball_point(<ckdtree*>self, &vxx[start,0], 
-                                r, p, eps, stop-start, vvres+start)
-                                
-                    vvres_uintp = <np.uintp_t> (<void*> vvres)
-                    threads = [threading.Thread(target=_thread_func,
-                               args=(self, j, vxx, r, p, eps,vvres_uintp,CHUNK))
-                                  for j in range(1+(n//CHUNK))]
-                    for t in threads:
-                        t.daemon = True
-                        t.start()
-                    for t in threads: 
-                        t.join()
-                                                                
-                else:
-                
-                    query_ball_point(<ckdtree*>self, &vxx[0,0], r, p, eps, 
-                        n, vvres)
-                
-                i = 0
-                for c in np.ndindex(retshape):
-                    m = <np.intp_t> (vvres[i].size())
-                    if NPY_LIKELY(m > 0):
-                        tmp = m * [None]
-                        cur = npy_intp_vector_buf(vvres[i])
-                        for j in range(m):
-                            tmp[j] = cur[0]
-                            cur += 1
-                        if return_sorted or return_sorted is None:
-                            result[c] = sorted(tmp)
-                        else:
-                            result[c] = tmp
+                query_ball_point(<ckdtree*>self, &vxx[0,0], &vrr[0], p, eps,
+                    n, vvres)
+
+            i = 0
+            for c in np.ndindex(retshape):
+                m = <np.intp_t> (vvres[i].size())
+                if NPY_LIKELY(m > 0):
+                    tmp = m * [None]
+                    cur = npy_intp_vector_buf(vvres[i])
+                    for j in range(m):
+                        tmp[j] = cur[0]
+                        cur += 1
+                    if return_sorted or return_sorted is None:
+                        result[c] = sorted(tmp)
                     else:
-                        result[c] = []
-                    i += 1
-        
+                        result[c] = tmp
+                else:
+                    result[c] = []
+                i += 1
+
+            return result
+
         finally:
-            if vres != NULL: 
-                del vres
-                
             if vvres != NULL:
                 for i in range(n):
                     if vvres[i] != NULL:
-                        del vvres[i]     
+                        del vvres[i]
                 PyMem_Free(vvres)
-                
-        return result   
-            
+
 
     # ---------------
     # query_ball_tree
diff --git a/scipy/spatial/ckdtree/src/ckdtree_methods.h b/scipy/spatial/ckdtree/src/ckdtree_methods.h
index 04c7c8833074..2a2a179e6cbd 100644
--- a/scipy/spatial/ckdtree/src/ckdtree_methods.h
+++ b/scipy/spatial/ckdtree/src/ckdtree_methods.h
@@ -189,7 +189,7 @@ count_neighbors_weighted(const ckdtree *self,
 CKDTREE_EXTERN PyObject*
 query_ball_point(const ckdtree *self,
                  const npy_float64 *x,
-                 const npy_float64 r,
+                 const npy_float64 *r,
                  const npy_float64 p,
                  const npy_float64 eps,
                  const npy_intp n_queries,
diff --git a/scipy/spatial/ckdtree/src/query_ball_point.cxx b/scipy/spatial/ckdtree/src/query_ball_point.cxx
index d48f058e4610..9893e7446e7d 100644
--- a/scipy/spatial/ckdtree/src/query_ball_point.cxx
+++ b/scipy/spatial/ckdtree/src/query_ball_point.cxx
@@ -103,12 +103,12 @@ traverse_checking(const ckdtree *self,
 
 extern ""C"" PyObject*
 query_ball_point(const ckdtree *self, const npy_float64 *x,
-                 const npy_float64 r, const npy_float64 p, const npy_float64 eps,
+                 const npy_float64 *r, const npy_float64 p, const npy_float64 eps,
                  const npy_intp n_queries, std::vector<npy_intp> **results)
 {
 #define HANDLE(cond, kls) \
     if(cond) { \
-        RectRectDistanceTracker<kls> tracker(self, point, rect, p, eps, r); \
+        RectRectDistanceTracker<kls> tracker(self, point, rect, p, eps, r[i]); \
         traverse_checking(self, results[i], self->ctree, &tracker); \
     } else
 
diff --git a/scipy/spatial/tests/test_kdtree.py b/scipy/spatial/tests/test_kdtree.py
index a9737cbc8701..f0ae663711d8 100644
--- a/scipy/spatial/tests/test_kdtree.py
+++ b/scipy/spatial/tests/test_kdtree.py
@@ -1360,6 +1360,19 @@ def test_short_knn():
             [0., 0.01, np.inf, np.inf],
             [0., np.inf, np.inf, np.inf]])
 
+def test_query_ball_point_vector_r():
+
+    np.random.seed(1234)
+    data = np.random.normal(size=(100, 3))
+    query = np.random.normal(size=(100, 3))
+    tree = cKDTree(data)
+    d = np.random.uniform(0, 0.3, size=len(query))
+
+    rvector = tree.query_ball_point(query, d)
+    rscalar = [ tree.query_ball_point(qi, di) for qi, di in zip(query, d) ]
+    for a, b in zip(rvector, rscalar):
+        assert_array_equal(sorted(a), sorted(b))
+
 class Test_sorted_query_ball_point(object):
 
     def setup_method(self):
"
